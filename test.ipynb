{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "writer_dir_name = 'data/geolife/runs'\n",
    "log_dir_name = '[segment_time-hetnet]_20240318-054205'\n",
    "log_folder = writer_dir_name + '/' + log_dir_name\n",
    "best_model_path = log_folder + '/best_model.pth'\n",
    "\n",
    "config_df = pd.read_csv(log_folder + '/configuration.csv')\n",
    "config_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = config_df['model_type'][0]\n",
    "\n",
    "data_dir = \"data/geolife/Data/\"\n",
    "label_attribute = 2\n",
    "\n",
    "sample_s = config_df['sample_s'][0]\n",
    "sample_q = config_df['sample_q'][0]\n",
    "\n",
    "args_epoch = config_df['epoch'][0]\n",
    "args_patience = config_df['patience'][0]\n",
    "\n",
    "gap_min = 12 # 1 min\n",
    "gap = gap_min\n",
    "\n",
    "hidden_layer = config_df['hidden_layer'][0]\n",
    "cell = 256#config_df['cell'][0]\n",
    "\n",
    "loss_method = 'mse'\n",
    "# loss_method = 'cross'\n",
    "\n",
    "day = config_df['day'][0]\n",
    "# week = config_df['week'][0]\n",
    "x_attribute = config_df['x_attribute'][0]\n",
    "y_timestep = config_df['y_timestep'][0] \n",
    "length = config_df['length'][0]\n",
    "\n",
    "file_mode = config_df['file_mode'][0]\n",
    "round_min = config_df['round_min'][0]\n",
    "round_sec = config_df['round_sec'][0] # (seconds) per 10s\n",
    "time_delta = 20 # (minutes) 1 segment length\n",
    "\n",
    "train_list = config_df['train_list'][0]\n",
    "validation_list = config_df['val_list'][0]\n",
    "test_list = config_df['test_list'][0]\n",
    "\n",
    "train_size = 0.4\n",
    "validation_size = 0.1\n",
    "batch_size = config_df['batch_size'][0] # each user\n",
    "batch_size = 3\n",
    "\n",
    "device = \"cpu\" #config_df['device'][0]\n",
    "\n",
    "## Test Phase\n",
    "is_train = False\n",
    "\n",
    "print(f\"day:{day}, y_timestep:{y_timestep}, length:{length}, model_type:{model_type}\")\n",
    "print(f\"train_columns: {config_df['train_columns'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard 설정\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch_mlp import MLP\n",
    "from torch_mlp_dataset import MlpDataset\n",
    "\n",
    "data_dir = \"data/geolife/Data/\"\n",
    "\n",
    "train_list = config_df['train_list'][0]\n",
    "validation_list = config_df['val_list'][0]\n",
    "test_list = config_df['val_list'][0]#, '078']\n",
    "\n",
    "test_list = ['035']\n",
    "\n",
    "print(f\"train_list:      {train_list}\")\n",
    "print(f\"validation_list: {validation_list}\")\n",
    "print(f\"test_list:       {test_list}\")\n",
    "\n",
    "test_data         = MlpDataset(data_dir, test_list, y_timestep, day, round_min, round_sec, time_delta, label_attribute, length, device, file_mode)\n",
    "test_dataloader   = DataLoader(test_data, batch_size, shuffle=False)\n",
    "        \n",
    "best_model = MLP(input_shape=[length, x_attribute], y_timestep = y_timestep, loss_fn=loss_method, label_attribute=label_attribute, cell=cell, hidden_layer=hidden_layer)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MLP graph\n",
    "# https://jimmy-ai.tistory.com/30\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def metricMenhattan(y_true, y_pred):\n",
    "    row = torch.abs(y_pred[:,:,:,0] - y_true[:,:,:,0])\n",
    "    col = torch.abs(y_pred[:,:,:,1] - y_true[:,:,:,1])\n",
    "    return row + col\n",
    "\n",
    "def mlp_metricMenhattan(y_true, y_pred):\n",
    "    row = torch.abs(y_pred[:,:,0] - y_true[:,:,0])\n",
    "    col = torch.abs(y_pred[:,:,1] - y_true[:,:,1])\n",
    "    return row + col\n",
    "\n",
    "def metricEuclidean(y_true, y_pred):\n",
    "    row = (y_pred[:,:,0] - y_true[:,:,0])**2\n",
    "    col = (y_pred[:,:,1] - y_true[:,:,1])**2\n",
    "    return (row + col)** 0.5\n",
    "\n",
    "with torch.no_grad():\n",
    "    MASK = 0\n",
    "    X = 1\n",
    "    Y = 2\n",
    "    time = np.arange(y_timestep)\n",
    "    zero_line = np.zeros(y_timestep)\n",
    "    print(f\"time len: {len(time)}\")\n",
    "    print(f\"test_dataloader: {len(test_dataloader.dataset)}\")\n",
    "    for idx, test_data in enumerate(test_dataloader, 0):\n",
    "        test_X, test_y = test_data\n",
    "        test_y_mask = (test_y[:, :, MASK] == 1)\n",
    "\n",
    "        # mlp\n",
    "        output = best_model(test_X)\n",
    "        output = torch.concat([torch.unsqueeze(test_y[:,:,MASK], -1), output], axis=-1)\n",
    "\n",
    "        criterion = metricEuclidean\n",
    "        loss = criterion(test_y, output)\n",
    "\n",
    "        if idx % 5 != 1:\n",
    "            continue\n",
    "\n",
    "        padding = 500\n",
    "        for batch_id in range(test_y.shape[0]-1):\n",
    "            if test_y[batch_id, test_y_mask[batch_id], X].shape[0] <= 0:\n",
    "                break\n",
    "\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            # 3row, 1col\n",
    "            plt.subplot(3, 1, 1)\n",
    "\n",
    "            plt.title('X graph')\n",
    "            ymax, _ = torch.max(test_y[batch_id, test_y_mask[batch_id], X], dim=-1)\n",
    "            ymin, _ = torch.min(test_y[batch_id, test_y_mask[batch_id], X], dim=-1)\n",
    "            plt.ylim(ymin - padding, ymax + padding)\n",
    "            # plt.axis([xmin, xmax, ymin, ymax])\n",
    "            plt.plot(time, output[batch_id, :, X] , color='r', alpha=0.3)\n",
    "            plt.scatter(time[test_y_mask[batch_id]], output[batch_id, test_y_mask[batch_id], X], color='r', alpha = 0.5)\n",
    "            plt.scatter(time[test_y_mask[batch_id]], test_y[batch_id, test_y_mask[batch_id], X], color='b', alpha = 0.5)\n",
    "            plt.xlabel('time (hour)')\n",
    "            plt.ylabel('X (m)')\n",
    "\n",
    "            plt.subplot(3, 1, 2)\n",
    "            plt.title('Y graph')\n",
    "            ymax = test_y[batch_id, test_y_mask[batch_id], Y].max()\n",
    "            ymin = test_y[batch_id, test_y_mask[batch_id], Y].min()\n",
    "            plt.ylim(ymin - padding, ymax + padding)\n",
    "            plt.plot(time, output[batch_id, :, Y] , color='r', alpha=0.3)\n",
    "            plt.scatter(time[test_y_mask[batch_id]], output[batch_id, test_y_mask[batch_id], Y], color='r', alpha = 0.5)\n",
    "            plt.scatter(time[test_y_mask[batch_id]], test_y[batch_id, test_y_mask[batch_id], Y], color='b', alpha = 0.5)\n",
    "            plt.xlabel('time (hour)')\n",
    "            plt.ylabel('Y (m)')\n",
    "\n",
    "            plt.subplot(3, 1, 3)\n",
    "            plt.title('Euclidean (m)')\n",
    "            plt.ylim(0, 100)\n",
    "            plt.plot(time, zero_line, color='b', alpha=0.1)\n",
    "            plt.scatter(time[test_y_mask[batch_id]], loss[batch_id, test_y_mask[batch_id]], color='r', alpha = 0.5)\n",
    "            plt.xlabel('time (per hour)')\n",
    "            plt.ylabel('Loss')\n",
    "\n",
    "            plt.subplots_adjust(bottom=0.1, top=0.9, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-hetnet graph\n",
    "# https://jimmy-ai.tistory.com/30\n",
    "\n",
    "# TensorBoard 설정\n",
    "import ast\n",
    "from torch_time_het import TimeHetNet\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch_segment_dataset import SegmentDataset\n",
    "\n",
    "data_dir = \"data/geolife/Data/\"\n",
    "\n",
    "\n",
    "train_list = config_df['train_list'][0]\n",
    "validation_list = config_df['val_list'][0]\n",
    "test_list = config_df['val_list'][0]#, '078']\n",
    "\n",
    "test_list = ['035']\n",
    "\n",
    "print(f\"train_list:      {train_list}\")\n",
    "print(f\"validation_list: {validation_list}\")\n",
    "print(f\"test_list:       {test_list}\")\n",
    "\n",
    "test_data               = SegmentDataset(model_type, data_dir, test_list, device, day, round_min, round_sec, time_delta, y_timestep, length, label_attribute, sample_s, sample_q, file_mode)\n",
    "test_dataloader         = DataLoader(test_data, batch_size, shuffle=False)    \n",
    "    \n",
    "best_model = TimeHetNet(dims_inf = ast.literal_eval(\"[32,32,32]\"),\n",
    "                    dims_pred = ast.literal_eval(\"[32,32,32]\"), \n",
    "                    activation=\"relu\", \n",
    "                    time=100,\n",
    "                    batchnorm=False, \n",
    "                    block = str(\"gru,conv,conv,gru\").split(\",\"),\n",
    "                    output_shape=[y_timestep, 2],\n",
    "                    length=length)\n",
    "\n",
    "best_model.load_state_dict(torch.load(best_model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def metricMenhattan(y_true, y_pred):\n",
    "    row = torch.abs(y_pred[:,:,:,0] - y_true[:,:,:,0])\n",
    "    col = torch.abs(y_pred[:,:,:,1] - y_true[:,:,:,1])\n",
    "    return row + col\n",
    "\n",
    "def metricEuclidean(y_true, y_pred):\n",
    "    row = (y_pred[:,:,:,1] - y_true[:,:,:,1])**2\n",
    "    col = (y_pred[:,:,:,2] - y_true[:,:,:,2])**2\n",
    "    result = (row+col)**0.5\n",
    "    return result\n",
    "\n",
    "with torch.no_grad():\n",
    "    # MASK = 0\n",
    "    X = 1\n",
    "    Y = 2\n",
    "    time = np.arange(y_timestep)\n",
    "    zero_line = np.zeros(y_timestep)\n",
    "\n",
    "    for idx, test_data in enumerate(test_dataloader, 0):\n",
    "        test_X, test_y = test_data\n",
    "        \n",
    "        output = best_model(test_X)\n",
    "        \n",
    "        mask, y_true = test_y\n",
    "        output = torch.cat([mask[:, :, :].unsqueeze(-1), output], axis=-1)\n",
    "        y_true = torch.cat([mask[:, :, :].unsqueeze(-1), y_true], axis=-1)\n",
    "\n",
    "        loss = metricEuclidean(y_true, output)\n",
    "        print(torch.sum(loss))\n",
    "        test_loss = torch.unsqueeze(loss, -1)\n",
    "\n",
    "        # if idx % 10 != 1:\n",
    "        #     continue\n",
    "\n",
    "        # print(f\"y_true shape: {y_true.shape}\")\n",
    "        padding = 500\n",
    "        for batch_idx in range(y_true.shape[0]):\n",
    "            # if batch_idx != 0:\n",
    "            #     continue\n",
    "            for query_idx in range(y_true.shape[1]):\n",
    "                plt.figure(figsize=(10, 8))\n",
    "\n",
    "                plt.subplot(3, 1, 1)\n",
    "                plt.title('X graph')\n",
    "                \n",
    "                test_y_mask = (output[batch_idx, query_idx, :, 0] > 0.5)\n",
    "                if test_y_mask.sum() == 0:\n",
    "                    continue\n",
    "                ymax, _ = torch.max(output[batch_idx, query_idx, test_y_mask, X], dim=-1)\n",
    "                ymin, _ = torch.min(output[batch_idx, query_idx, test_y_mask, X], dim=-1)\n",
    "\n",
    "                plt.ylim(ymin - padding, ymax + padding)\n",
    "                plt.plot(time, output[batch_idx, query_idx, :, X] , color='r', alpha=0.3)\n",
    "                plt.scatter(time[test_y_mask], output[batch_idx, query_idx, test_y_mask, X], color='r', alpha = 0.5)\n",
    "                plt.scatter(time[test_y_mask], y_true[batch_idx, query_idx, test_y_mask, X], color='b', alpha = 0.5)\n",
    "                plt.xlabel('time (per hour)')\n",
    "                plt.ylabel('X (m)')\n",
    "                \n",
    "                ## y\n",
    "                plt.subplot(3, 1, 2)\n",
    "                plt.title('Y graph')\n",
    "                \n",
    "                test_y_mask = (output[batch_idx, query_idx, :, 0] > 0.5)\n",
    "                ymax, _ = torch.max(output[batch_idx, query_idx, test_y_mask, Y], dim=-1)\n",
    "                ymin, _ = torch.min(output[batch_idx, query_idx, test_y_mask, Y], dim=-1)\n",
    "\n",
    "                plt.ylim(int(ymin - padding), int(ymax + padding))\n",
    "                plt.plot(time, output[batch_idx, query_idx, :, Y] , color='r', alpha=0.3)\n",
    "                plt.scatter(time[test_y_mask], output[batch_idx, query_idx, test_y_mask, Y], color='r', alpha = 0.5)\n",
    "                plt.scatter(time[test_y_mask], y_true[batch_idx, query_idx, test_y_mask, Y], color='b', alpha = 0.5)\n",
    "                plt.xlabel('time (per hour)')\n",
    "                plt.ylabel('Y (m)')\n",
    "                \n",
    "                plt.subplot(3, 1, 3)\n",
    "                plt.title('Euclidean (m)')\n",
    "                # plt.ylim(0, 100)\n",
    "                plt.scatter(time, zero_line, color='b', alpha=0.1)\n",
    "                plt.scatter(time[test_y_mask], loss[batch_idx, query_idx, test_y_mask], color='r', alpha = 0.5)\n",
    "                plt.xlabel('time (per hour)')\n",
    "                plt.ylabel('Loss')\n",
    "    \n",
    "                plt.subplots_adjust(bottom=0.1, top=0.9, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x축 범위 설정 (0부터 10까지)\n",
    "x_values = [i for i in range(11)]\n",
    "\n",
    "# y축 범위 설정 (1km에서 2km까지)\n",
    "y_values = [1000 + i * 100 for i in range(11)]\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(x_values, y_values, marker='o', markersize=8, label=\"(5, 100m)\", color='r')\n",
    "plt.xlabel(\"x (0 ~ 10)\")\n",
    "plt.ylabel(\"y (1km ~ 2km)\")\n",
    "plt.title(\"1km ~ 2km 범위 그래프\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jimmy-ai.tistory.com/30\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for idx in range(test_label.shape[0]):\n",
    "    df = pd.DataFrame(data=test_que_x[idx][0], columns=['Time'])\n",
    "    df_norm = MinMaxScaler().fit_transform(df)\n",
    "\n",
    "    fig_row = plt.figure(figsize=(9, 6))\n",
    "    ax_row = fig_row.add_subplot(111)\n",
    "    ax_row.plot(df_norm, test_label[idx][0][:, 0] , color='r', alpha=0.5)\n",
    "    ax_row.plot(df_norm, test_probs[idx][0][:, 0], color='g', alpha=0.3)\n",
    "    ax_row.set_xlabel('time')\n",
    "    ax_row.set_ylabel('grid_row')\n",
    "    \n",
    "    ax_col = fig_row.add_subplot(222)\n",
    "    ax_col.plot(df_norm, test_label[idx][0][:, 1] , color='r', alpha=0.5)\n",
    "    ax_col.plot(df_norm, test_probs[idx][0][:, 1], color='g', alpha=0.3)\n",
    "    ax_col.set_xlabel('time')\n",
    "    ax_col.set_ylabel('grid_col')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jimmy-ai.tistory.com/30\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fig = plt.figure(figsize=(9, 6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# ax.scatter(x, y, z, color = 'r', alpha = 0.5)\n",
    "# ax.scatter(x, z, y, color = 'g', alpha = 0.5) # y와 z축 swap\n",
    "\n",
    "for idx in range(test_label.shape[0]):\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(elev=10, azim=-50)\n",
    "    df = pd.DataFrame(data=test_que_x[idx][0], columns=['Time'])\n",
    "    df_norm = MinMaxScaler().fit_transform(df)\n",
    "    ax.scatter(test_label[idx][0][:, 0], test_label[idx][0][:, 1], df_norm,\n",
    "               color='r', alpha=0.5)\n",
    "    ax.scatter(test_probs[idx][0][:, 0], test_probs[idx][0][:, 1], df_norm, \n",
    "               color='g', alpha=0.5)\n",
    "    print(df_norm)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 헬퍼 함수\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    0부터 9까지의 \"class_index\"를 가져온 후 해당 정밀도-재현율(precision-recall)\n",
    "    곡선을 그립니다\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# 모든 정밀도-재현율(precision-recall; pr) 곡선을 그립니다\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class My_Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, device=None, name=None):\n",
    "        super(My_Linear, self).__init__()\n",
    "        self.Linear = nn.Linear(in_features, out_features, bias, device)\n",
    "        self.name = name\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(f\"My_Linear - X.shape: {x.shape}, name: {self.name}\")\n",
    "        x = self.Linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/geolife/Data/000/csv/000.csv')\n",
    "df.head(1)\n",
    "df_test = df.iloc[:, :-2].copy()\n",
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    device = get_device()\n",
    "    return torch.from_numpy(df.values).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['latitude', 'longitude', 'altitude', 'days']\n",
    "df_x = df_test[X].head(10).copy()\n",
    "df_x = df_to_tensor(df_x)\n",
    "print(df_x)\n",
    "df_x = df_x.unsqueeze(axis=-1)\n",
    "print(df_x)\n",
    "df_x = df_x.sum(axis=2)\n",
    "print(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(df_test, train_size=0.7, random_state=123)\n",
    "\n",
    "X = ['latitude', 'longitude', 'altitude', 'days']\n",
    "y = ['latitude', 'longitude']\n",
    "\n",
    "row = 10\n",
    "train_set = train_set.iloc[:row, :].copy()\n",
    "\n",
    "train_X = df_to_tensor(train_set[X])\n",
    "train_y = df_to_tensor(train_set[y])\n",
    "\n",
    "model = My_Linear(4, 2)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "out_list = []\n",
    "loss_train = 0.0\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for input in train_X:\n",
    "        outputs = model(input)\n",
    "        print(outputs)\n",
    "        loss = loss_fn(outputs, train_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_train += loss.item()\n",
    "    \n",
    "    print(f\"epoch:{epoch}, loss:{loss_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
