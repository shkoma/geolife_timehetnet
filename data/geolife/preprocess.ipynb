{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 114, 39.98715717254236, 117.4918228913047, 1475)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gps_grid_map_creator import GPSGridMapCreator\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "grid_size_meter = 500  # Size of each grid in meters\n",
    "\n",
    "mapCreator = GPSGridMapCreator(grid_size_meter)\n",
    "mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "print(mapCreator.find_grid_number(39.99, 117.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_644/3142186472.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from convert_minmax_location import LocationPreprocessor\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "id = 68\n",
    "\n",
    "gap = 10\n",
    "round_min = str(gap) + 'min'\n",
    "round_sec = str(gap) + 's'\n",
    "round_time = round_sec\n",
    "\n",
    "user_id = locationPreprocessor.getUserId(id)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "seg_file = './Data/' + user_id + '/csv/' + user_id + '_segment.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df['datetime'] = pd.to_datetime(df['date'] + \" \" + df['time'])\n",
    "df['datetime'] = df['datetime'].dt.round(round_time)\n",
    "\n",
    "df = df.set_index('datetime').reset_index()\n",
    "user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
    "\n",
    "# 시간 간격 계산\n",
    "user_df['time_diff'] = user_df['datetime'].diff()\n",
    "\n",
    "# 1분 이상인 경우 세그먼트로 분류\n",
    "threshold = pd.Timedelta(minutes=1)\n",
    "user_df['segment'] = (user_df['time_diff'] > threshold).cumsum()\n",
    "user_df = user_df.drop(columns=['time_diff'])\n",
    "user_df.to_csv(seg_file, index=False)\n",
    "# user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>what</th>\n",
       "      <th>altitude</th>\n",
       "      <th>days</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-09-14 13:03:10</td>\n",
       "      <td>39.972909</td>\n",
       "      <td>116.418298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.543872</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-09-14 13:03:20</td>\n",
       "      <td>39.972923</td>\n",
       "      <td>116.418236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.543987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-14 13:03:30</td>\n",
       "      <td>39.972791</td>\n",
       "      <td>116.418186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.544103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-09-14 13:03:40</td>\n",
       "      <td>39.972548</td>\n",
       "      <td>116.418203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.544219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-09-14 13:03:50</td>\n",
       "      <td>39.972287</td>\n",
       "      <td>116.418196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.544334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime   latitude   longitude  what  altitude          days  \\\n",
       "0 2008-09-14 13:03:10  39.972909  116.418298   0.0       0.0  39705.543872   \n",
       "1 2008-09-14 13:03:20  39.972923  116.418236   0.0       0.0  39705.543987   \n",
       "2 2008-09-14 13:03:30  39.972791  116.418186   0.0       0.0  39705.544103   \n",
       "3 2008-09-14 13:03:40  39.972548  116.418203   0.0       0.0  39705.544219   \n",
       "4 2008-09-14 13:03:50  39.972287  116.418196   0.0       0.0  39705.544334   \n",
       "\n",
       "   segment  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = pd.read_csv(seg_file)\n",
    "user_df['datetime'] = pd.to_datetime(user_df['datetime'])\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>days</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>weekend</th>\n",
       "      <th>...</th>\n",
       "      <th>grid_row_1500m</th>\n",
       "      <th>grid_col_1500m</th>\n",
       "      <th>grid_row_2000m</th>\n",
       "      <th>grid_col_2000m</th>\n",
       "      <th>grid_row_3000m</th>\n",
       "      <th>grid_col_3000m</th>\n",
       "      <th>grid_row_500m</th>\n",
       "      <th>grid_col_500m</th>\n",
       "      <th>grid_row_100m</th>\n",
       "      <th>grid_col_100m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-09-14 13:03:10</td>\n",
       "      <td>39.972909</td>\n",
       "      <td>116.418298</td>\n",
       "      <td>39705.543872</td>\n",
       "      <td>-58774.467688</td>\n",
       "      <td>913530.593053</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-09-14 13:03:20</td>\n",
       "      <td>39.972923</td>\n",
       "      <td>116.418236</td>\n",
       "      <td>39705.543987</td>\n",
       "      <td>-58779.739348</td>\n",
       "      <td>913532.094184</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-14 13:03:30</td>\n",
       "      <td>39.972791</td>\n",
       "      <td>116.418186</td>\n",
       "      <td>39705.544103</td>\n",
       "      <td>-58784.113148</td>\n",
       "      <td>913517.472051</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-09-14 13:03:40</td>\n",
       "      <td>39.972548</td>\n",
       "      <td>116.418203</td>\n",
       "      <td>39705.544219</td>\n",
       "      <td>-58782.916105</td>\n",
       "      <td>913490.451684</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-09-14 13:03:50</td>\n",
       "      <td>39.972287</td>\n",
       "      <td>116.418196</td>\n",
       "      <td>39705.544334</td>\n",
       "      <td>-58783.651864</td>\n",
       "      <td>913461.429808</td>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime   latitude   longitude          days             x  \\\n",
       "0  2008-09-14 13:03:10  39.972909  116.418298  39705.543872 -58774.467688   \n",
       "1  2008-09-14 13:03:20  39.972923  116.418236  39705.543987 -58779.739348   \n",
       "2  2008-09-14 13:03:30  39.972791  116.418186  39705.544103 -58784.113148   \n",
       "3  2008-09-14 13:03:40  39.972548  116.418203  39705.544219 -58782.916105   \n",
       "4  2008-09-14 13:03:50  39.972287  116.418196  39705.544334 -58783.651864   \n",
       "\n",
       "               y  year  month  week  weekend  ...  grid_row_1500m  \\\n",
       "0  913530.593053  2008      9     6        1  ...               0   \n",
       "1  913532.094184  2008      9     6        1  ...               0   \n",
       "2  913517.472051  2008      9     6        1  ...               0   \n",
       "3  913490.451684  2008      9     6        1  ...               0   \n",
       "4  913461.429808  2008      9     6        1  ...               0   \n",
       "\n",
       "   grid_col_1500m  grid_row_2000m  grid_col_2000m  grid_row_3000m  \\\n",
       "0               1               0               0               0   \n",
       "1               1               0               0               0   \n",
       "2               1               0               0               0   \n",
       "3               1               0               0               0   \n",
       "4               1               0               0               0   \n",
       "\n",
       "   grid_col_3000m  grid_row_500m  grid_col_500m  grid_row_100m  grid_col_100m  \n",
       "0               0              0              3              2             18  \n",
       "1               0              0              3              2             18  \n",
       "2               0              0              3              2             18  \n",
       "3               0              0              3              2             18  \n",
       "4               0              0              3              2             18  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/068/csv/068_origin_grid_10s.csv')\n",
    "df.head()\n",
    "df_1 = df[df.columns[0:13].to_list()].copy()\n",
    "# df_1 = pd.concat([df_1, df.iloc[:, 6:13]], axis=1) # ~ Hour + 100m\n",
    "# # df_1 = pd.get_dummies(df_1, columns=['hour'], drop_first=True)\n",
    "\n",
    "df_1 = pd.concat([df_1, df.iloc[:, 13:15]], axis=1) # 100m\n",
    "df_1 = pd.concat([df_1, df.iloc[:, 21:]], axis=1) # 2000m\n",
    "df_1 = pd.concat([df_1, df.iloc[:, 17:19]], axis=1) # 1000m\n",
    "df_1 = pd.concat([df_1, df.iloc[:, 15:17]], axis=1) # 500m\n",
    "df_1.head()\n",
    "# df_1.columns.shape\n",
    "# df.columns[0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SegmentDataset(Dataset):\n",
    "    def __init__(self, data_dir, user_list, device, time_delta, y_timestep, length, label_attribute, sample_s, replace=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.user_list = user_list\n",
    "        self.device = device\n",
    "        self.time_delta = time_delta\n",
    "        self.y_timestep = y_timestep\n",
    "        self.length = length\n",
    "        self.label_attribute = label_attribute\n",
    "        self.sample_s = sample_s\n",
    "        self.replace = replace\n",
    "\n",
    "        self.csv_file = '_origin_grid_10s.csv'\n",
    "    \n",
    "    def sampleSet(self, dataset):\n",
    "        user_df = dataset.copy()\n",
    "        user_df['datetime'] = pd.to_datetime(user_df['datetime'])\n",
    "    \n",
    "        # 세그먼트별 시작 시간과 끝 시간 추출 그리고, 시간 간격별 segment list 추출\n",
    "        segment_info = user_df.groupby('segment')['datetime'].agg(['min', 'max'])\n",
    "        segment_info = segment_info.reset_index()\n",
    "        segment_info['time_gap'] = segment_info['max'] - segment_info['min']\n",
    "        segment_info['over_time_delta'] = segment_info['time_gap'] >= pd.Timedelta(minutes=self.time_delta)\n",
    "        segment_info = segment_info.loc[segment_info['over_time_delta'] == True, :]\n",
    "        segment_list = segment_info['segment'].to_list()\n",
    "\n",
    "        user_df = user_df.drop(columns=['datetime'])\n",
    "\n",
    "        # segment_list 기반, sample 추출하여 mini-batch 형성\n",
    "        mini_batch = []\n",
    "\n",
    "        segment_list = np.random.choice(segment_list, size=self.sample_s, replace=self.replace)\n",
    "\n",
    "        for seg_num in segment_list:\n",
    "            seg_df = user_df.loc[user_df['segment'] == seg_num, :]\n",
    "            if seg_df.shape[0] < length:\n",
    "                # segment 길이가 짧다면, zero padding 진행\n",
    "                fill_quota  = np.abs(length - seg_df.shape[0])\n",
    "                zeros_r     = np.zeros([fill_quota, seg_df.shape[1]])\n",
    "                cur_sample  = seg_df.copy()\n",
    "                cur_sample  = np.concatenate([zeros_r, seg_df], axis = 0)\n",
    "                mini_batch.append(cur_sample)\n",
    "            else:\n",
    "                # segment 에서 요구된 길이만큼 추출\n",
    "                cur_sample = seg_df.iloc[:length, :]\n",
    "                mini_batch.append(cur_sample)\n",
    "\n",
    "        return np.array(mini_batch)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        csv_file = str(self.data_dir) + str(self.user_list[index]) + '/csv/' + str(self.user_list[index]) + self.csv_file\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        df_1 = df[df.columns[0:13].to_list()].copy()\n",
    "        # df_1 = pd.concat([df_1, df.iloc[:, 6:13]], axis=1) # ~ Hour + 100m\n",
    "        # df_1 = pd.get_dummies(df_1, columns=['hour'], drop_first=True)\n",
    "\n",
    "        df_1 = pd.concat([df_1, df.iloc[:, 13:15]], axis=1) # 100m\n",
    "        df_1 = pd.concat([df_1, df.iloc[:, 21:]], axis=1) # 2000m\n",
    "        df_1 = pd.concat([df_1, df.iloc[:, 17:19]], axis=1) # 1000m\n",
    "        df_1 = pd.concat([df_1, df.iloc[:, 15:17]], axis=1) # 500m\n",
    "        \n",
    "        samples = self.sampleSet(df_1)\n",
    "        \n",
    "        # task_X, task_y 준비\n",
    "        task_X = np.array(samples[:, :-self.y_timestep, 4:])\n",
    "        task_y = np.array(samples[:, -self.y_timestep:, -self.label_attribute:])\n",
    "\n",
    "        task_X = torch.from_numpy(task_X).double()\n",
    "        task_y = torch.from_numpy(task_y).double()\n",
    "\n",
    "        return task_X, task_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        # batch를 구성할 수 있는 총 수\n",
    "        # 이 수에서 batch를 조정할 수 있다.\n",
    "        # 몇 명의 user 로 나눠서 할 지\n",
    "        return len(self.user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seg_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m replace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m attribute \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m user_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(seg_file)\n\u001b[1;32m     19\u001b[0m user_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(user_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 세그먼트별 시작 시간과 끝 시간 추출 그리고, 시간 간격별 segment list 추출\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seg_file' is not defined"
     ]
    }
   ],
   "source": [
    "# segment 기반, user별 mini-batch 를 추출\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "min_length = 6\n",
    "time_delta = 60\n",
    "length = min_length * time_delta\n",
    "\n",
    "y_timestep = min_length * 2\n",
    "label_attribute = 2\n",
    "\n",
    "samples_s = 10\n",
    "replace = False\n",
    "attribute = ['days','latitude', 'longitude']\n",
    "\n",
    "user_df = pd.read_csv(seg_file)\n",
    "user_df['datetime'] = pd.to_datetime(user_df['datetime'])\n",
    "\n",
    "# 세그먼트별 시작 시간과 끝 시간 추출 그리고, 시간 간격별 segment list 추출\n",
    "segment_info = user_df.groupby('segment')['datetime'].agg(['min', 'max'])\n",
    "segment_info = segment_info.reset_index()\n",
    "segment_info['time_gap'] = segment_info['max'] - segment_info['min']\n",
    "segment_info['over_time_delta'] = segment_info['time_gap'] >= pd.Timedelta(minutes=time_delta)\n",
    "segment_info = segment_info.loc[segment_info['over_time_delta'] == True, :]\n",
    "segment_list = segment_info['segment'].to_list()\n",
    "print(len(segment_list))\n",
    "\n",
    "# segment_list 기반, sample 추출하여 mini-batch 형성\n",
    "mini_batch = []\n",
    "\n",
    "segment_list = np.random.choice(segment_list, size=samples_s, replace=replace)\n",
    "\n",
    "for seg_num in segment_list:\n",
    "    seg_df = user_df.loc[user_df['segment'] == seg_num, attribute]\n",
    "    if seg_df.shape[0] < length:\n",
    "        # segment 길이가 짧다면, zero padding 진행\n",
    "        fill_quota  = np.abs(length - seg_df.shape[0])\n",
    "        zeros_r     = np.zeros([fill_quota, seg_df.shape[1]])\n",
    "        cur_sample  = seg_df.copy()\n",
    "        cur_sample  = np.concatenate([zeros_r, seg_df], axis = 0)\n",
    "        mini_batch.append(cur_sample)\n",
    "    else:\n",
    "        # segment 에서 요구된 길이만큼 추출\n",
    "        cur_sample = seg_df.iloc[:length, :]\n",
    "        mini_batch.append(cur_sample)\n",
    "\n",
    "samples = np.array(mini_batch)\n",
    "# samples = torch.from_numpy(samples).double()\n",
    "print(f\"samples.shape: {samples.shape}\")\n",
    "# samples[:2, :5, :]\n",
    "# 8분의 data를 input 으로 넣고, 2분의 data를 output 으로 내는 ?\n",
    "# or 5분의 data를 input 으로 넣고, 5분의 data를 output으로 내는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_x: torch.Size([1, 10, 348, 3]), task_y: torch.Size([1, 10, 12, 2])\n"
     ]
    }
   ],
   "source": [
    "# task_X, task_y 준비\n",
    "task_X = np.array(samples[:, :-y_timestep, :])\n",
    "task_y = np.array(samples[:, -y_timestep:, -label_attribute:])\n",
    "\n",
    "task_X = torch.from_numpy(task_X).double()\n",
    "task_y = torch.from_numpy(task_y).double()\n",
    "\n",
    "# batch 를 만들기위한 임시 코드, data_loader 에서는 이 부분 주석처리\n",
    "task_X = torch.unsqueeze(task_X, axis = 0)\n",
    "task_y = torch.unsqueeze(task_y, axis = 0)\n",
    "print(f\"task_x: {task_X.shape}, task_y: {task_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# MLP 모델\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_shape, y_timestep, label_attribute):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape[-2] * input_shape[-1]\n",
    "        self.y_timestep = y_timestep\n",
    "        self.label_attribute = label_attribute\n",
    "        self.output_shape = y_timestep * label_attribute\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.input_shape, 256, dtype=torch.double)\n",
    "        self.fc2 = nn.Linear(256, 256, dtype=torch.double)\n",
    "        self.fc3 = nn.Linear(256, self.output_shape, dtype=torch.double)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch = torch._shape_as_tensor(x)[0]\n",
    "        mini_batch = torch._shape_as_tensor(x)[1]\n",
    "        time_step = torch._shape_as_tensor(x)[2]\n",
    "        attribute = torch._shape_as_tensor(x)[3]\n",
    "\n",
    "        in_shape_new = [-1] + [time_step * attribute]\n",
    "        x = torch.reshape(x, in_shape_new)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        out_shape_new = [batch] + [-1] + [self.y_timestep] + [self.label_attribute]\n",
    "        out = torch.reshape(x, out_shape_new)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target latitude, longitude: tensor([[[[  13.,   68.],\n",
      "          [  13.,   68.],\n",
      "          [  13.,   67.],\n",
      "          [  13.,   67.],\n",
      "          [  13.,   67.],\n",
      "          [  13.,   67.],\n",
      "          [  13.,   67.],\n",
      "          [  13.,   66.],\n",
      "          [  13.,   66.],\n",
      "          [  13.,   66.],\n",
      "          [  13.,   66.],\n",
      "          [  13.,   66.]],\n",
      "\n",
      "         [[ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.],\n",
      "          [ 862., 2797.]],\n",
      "\n",
      "         [[  11.,   37.],\n",
      "          [  11.,   37.],\n",
      "          [  11.,   37.],\n",
      "          [  11.,   37.],\n",
      "          [  11.,   37.],\n",
      "          [  11.,   37.],\n",
      "          [  11.,   37.],\n",
      "          [  11.,   37.],\n",
      "          [  11.,   36.],\n",
      "          [  11.,   36.],\n",
      "          [  11.,   36.],\n",
      "          [  11.,   36.]],\n",
      "\n",
      "         [[  18.,   69.],\n",
      "          [  18.,   68.],\n",
      "          [  19.,   68.],\n",
      "          [  19.,   68.],\n",
      "          [  19.,   68.],\n",
      "          [  20.,   68.],\n",
      "          [  20.,   68.],\n",
      "          [  20.,   68.],\n",
      "          [  20.,   68.],\n",
      "          [  20.,   68.],\n",
      "          [  20.,   68.],\n",
      "          [  20.,   68.]],\n",
      "\n",
      "         [[  27.,   70.],\n",
      "          [  28.,   70.],\n",
      "          [  28.,   70.],\n",
      "          [  28.,   70.],\n",
      "          [  28.,   70.],\n",
      "          [  28.,   70.],\n",
      "          [  28.,   70.],\n",
      "          [  28.,   70.],\n",
      "          [  28.,   70.],\n",
      "          [  28.,   71.],\n",
      "          [  29.,   71.],\n",
      "          [  29.,   71.]],\n",
      "\n",
      "         [[  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.],\n",
      "          [  33.,   14.]],\n",
      "\n",
      "         [[  13.,   70.],\n",
      "          [  13.,   70.],\n",
      "          [  13.,   70.],\n",
      "          [  13.,   70.],\n",
      "          [  13.,   70.],\n",
      "          [  13.,   70.],\n",
      "          [  13.,   70.],\n",
      "          [  13.,   70.],\n",
      "          [  13.,   70.],\n",
      "          [  14.,   70.],\n",
      "          [  14.,   70.],\n",
      "          [  14.,   70.]],\n",
      "\n",
      "         [[  21.,   65.],\n",
      "          [  21.,   65.],\n",
      "          [  20.,   65.],\n",
      "          [  20.,   65.],\n",
      "          [  20.,   66.],\n",
      "          [  20.,   66.],\n",
      "          [  19.,   66.],\n",
      "          [  19.,   66.],\n",
      "          [  19.,   66.],\n",
      "          [  19.,   66.],\n",
      "          [  18.,   66.],\n",
      "          [  18.,   66.]],\n",
      "\n",
      "         [[ 899., 2801.],\n",
      "          [ 899., 2801.],\n",
      "          [ 899., 2801.],\n",
      "          [ 899., 2801.],\n",
      "          [ 899., 2801.],\n",
      "          [ 899., 2801.],\n",
      "          [ 899., 2801.],\n",
      "          [ 899., 2801.],\n",
      "          [ 898., 2802.],\n",
      "          [ 898., 2802.],\n",
      "          [ 898., 2802.],\n",
      "          [ 897., 2802.]],\n",
      "\n",
      "         [[  23.,   70.],\n",
      "          [  23.,   70.],\n",
      "          [  23.,   70.],\n",
      "          [  23.,   70.],\n",
      "          [  23.,   70.],\n",
      "          [  24.,   70.],\n",
      "          [  24.,   70.],\n",
      "          [  24.,   70.],\n",
      "          [  24.,   70.],\n",
      "          [  24.,   70.],\n",
      "          [  24.,   70.],\n",
      "          [  24.,   70.]]]], dtype=torch.float64)\n",
      "Predicted latitude, longitude: tensor([[[[ 1139.8978, -1563.4630],\n",
      "          [ 1596.8670,  -285.6593],\n",
      "          [ -577.1257,  -342.0255],\n",
      "          [  231.9504,  1286.2138],\n",
      "          [ 1582.3191,    91.5040],\n",
      "          [ 2105.5717,   888.3638],\n",
      "          [ -111.9224,  2024.9236],\n",
      "          [ -479.8259,  3406.8447],\n",
      "          [  -17.5509,  -230.4828],\n",
      "          [  -76.0643,   908.6109],\n",
      "          [ -278.8427,  3437.8614],\n",
      "          [ -639.7457,   772.2007]],\n",
      "\n",
      "         [[ 1454.7118, -1062.4345],\n",
      "          [ 1905.5401,  -124.5075],\n",
      "          [  133.1062,   146.7700],\n",
      "          [  907.3946,  1608.1331],\n",
      "          [ 1997.3770,  -131.7750],\n",
      "          [ 1836.3553,   991.8040],\n",
      "          [ -706.7487,  2082.3948],\n",
      "          [   62.4473,  2857.8199],\n",
      "          [   63.7217,   230.0280],\n",
      "          [  210.4570,   462.4295],\n",
      "          [  675.5379,  3069.8162],\n",
      "          [ -159.6143,   896.8684]],\n",
      "\n",
      "         [[ 1121.8929, -1573.8409],\n",
      "          [ 1592.9255,  -291.4912],\n",
      "          [ -586.0424,  -349.0130],\n",
      "          [  223.8693,  1273.4539],\n",
      "          [ 1558.1118,    98.4952],\n",
      "          [ 2098.7898,   890.8487],\n",
      "          [  -99.0660,  2021.7702],\n",
      "          [ -491.9622,  3411.9313],\n",
      "          [  -18.1542,  -248.3579],\n",
      "          [  -64.3684,   909.9877],\n",
      "          [ -294.1420,  3427.3749],\n",
      "          [ -645.2452,   778.6892]],\n",
      "\n",
      "         [[ 1130.7664, -1569.9552],\n",
      "          [ 1600.3296,  -293.9562],\n",
      "          [ -578.8146,  -345.9677],\n",
      "          [  234.4200,  1280.7063],\n",
      "          [ 1567.3683,    95.8968],\n",
      "          [ 2093.8767,   897.0373],\n",
      "          [ -107.3402,  2027.3377],\n",
      "          [ -488.2109,  3416.5454],\n",
      "          [  -18.3942,  -247.0435],\n",
      "          [  -58.7325,   910.8674],\n",
      "          [ -282.4689,  3427.5179],\n",
      "          [ -642.7631,   785.5704]],\n",
      "\n",
      "         [[ 1141.4822, -1567.8731],\n",
      "          [ 1605.3239,  -295.9939],\n",
      "          [ -576.0623,  -346.1865],\n",
      "          [  241.7225,  1288.2255],\n",
      "          [ 1577.5332,    93.6210],\n",
      "          [ 2094.5551,   899.0242],\n",
      "          [ -111.5606,  2029.0282],\n",
      "          [ -484.0043,  3426.0688],\n",
      "          [  -15.8918,  -245.3437],\n",
      "          [  -56.1293,   915.8056],\n",
      "          [ -275.2328,  3429.4681],\n",
      "          [ -641.6407,   786.0525]],\n",
      "\n",
      "         [[ 1127.9239, -1558.5440],\n",
      "          [ 1583.1413,  -286.8679],\n",
      "          [ -577.6558,  -346.5107],\n",
      "          [  229.2251,  1272.6399],\n",
      "          [ 1560.2147,    94.7727],\n",
      "          [ 2089.7425,   883.2323],\n",
      "          [ -102.1540,  2005.9792],\n",
      "          [ -482.3420,  3395.5798],\n",
      "          [  -15.1192,  -240.3111],\n",
      "          [  -62.7883,   909.2709],\n",
      "          [ -283.7435,  3403.4267],\n",
      "          [ -637.4124,   769.3810]],\n",
      "\n",
      "         [[ 1133.8051, -1569.9817],\n",
      "          [ 1595.8561,  -287.7129],\n",
      "          [ -576.0086,  -340.9397],\n",
      "          [  229.1176,  1282.4928],\n",
      "          [ 1573.1829,    94.9260],\n",
      "          [ 2105.7764,   886.5355],\n",
      "          [ -108.6666,  2025.6585],\n",
      "          [ -483.0974,  3409.2543],\n",
      "          [  -14.0403,  -234.8235],\n",
      "          [  -73.0945,   905.1884],\n",
      "          [ -283.1477,  3435.4574],\n",
      "          [ -639.7572,   771.1532]],\n",
      "\n",
      "         [[ 1139.0663, -1565.9021],\n",
      "          [ 1600.0339,  -286.6528],\n",
      "          [ -578.2456,  -342.6299],\n",
      "          [  235.3277,  1287.0115],\n",
      "          [ 1582.2940,    92.2780],\n",
      "          [ 2106.6818,   891.4113],\n",
      "          [ -111.6991,  2026.2956],\n",
      "          [ -482.9292,  3413.0648],\n",
      "          [  -18.8804,  -234.3859],\n",
      "          [  -70.2646,   913.1913],\n",
      "          [ -278.8663,  3439.7999],\n",
      "          [ -638.5513,   776.8952]],\n",
      "\n",
      "         [[ 1450.8285, -1048.2721],\n",
      "          [ 1918.3415,  -130.3548],\n",
      "          [  145.3930,   151.2403],\n",
      "          [  930.5428,  1603.9820],\n",
      "          [ 1984.5210,  -131.2810],\n",
      "          [ 1822.2055,   993.0060],\n",
      "          [ -708.1668,  2069.6340],\n",
      "          [   65.8183,  2852.6950],\n",
      "          [   72.5036,   223.7900],\n",
      "          [  244.6848,   458.7344],\n",
      "          [  690.7440,  3034.1453],\n",
      "          [ -148.1384,   906.1694]],\n",
      "\n",
      "         [[ 1227.7513, -1515.0832],\n",
      "          [ 1607.0130,  -290.4548],\n",
      "          [ -550.2863,  -333.5812],\n",
      "          [  273.3056,  1341.7726],\n",
      "          [ 1678.9141,    65.4324],\n",
      "          [ 2107.8545,   884.0837],\n",
      "          [ -154.9167,  2019.4580],\n",
      "          [ -442.1790,  3429.9818],\n",
      "          [   -5.0046,  -187.0729],\n",
      "          [ -104.3101,   945.8847],\n",
      "          [ -220.3291,  3457.0450],\n",
      "          [ -628.3001,   746.9984]]]], dtype=torch.float64)\n",
      "loss: 2034.0332300075954\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# input_data = torch.tensor(input_data.values, dtype=torch.float32)\n",
    "# target_data = torch.tensor(output_data.values, dtype=torch.float32)\n",
    "\n",
    "def metricDist(y_true, y_pred):\n",
    "    row = (y_pred[:,:,:,0] - y_true[:,:,:,0])**2\n",
    "    col = (y_pred[:,:,:,1] - y_true[:,:,:,1])**2\n",
    "    return torch.mean(row + col) ** 0.5\n",
    "\n",
    "# args\n",
    "data_dir = \"Data/\"#\"data/geolife/Data/\"\n",
    "user_list = [\"068\", \"003\", \"004\"]\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "min_length = 6\n",
    "time_delta = 10 # the length of segment is 10mins\n",
    "length = min_length * time_delta\n",
    "\n",
    "y_timestep = min_length * 2\n",
    "x_attribute = 20\n",
    "label_attribute = 2\n",
    "sample_s = 10\n",
    "replace = False\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "# Dataset\n",
    "training_data    = SegmentDataset(data_dir, user_list, device, time_delta, y_timestep, length, label_attribute, sample_s, replace)\n",
    "train_dataloader = DataLoader(training_data, batch_size, shuffle=False)\n",
    "\n",
    "# Model 훈련 진행\n",
    "model = MLP(input_shape=[(length-y_timestep), x_attribute], y_timestep = y_timestep, label_attribute=label_attribute)\n",
    "\n",
    "model = model.to(torch.double)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for train_idx, train_data in enumerate(train_dataloader, 0):\n",
    "        task_X, task_y = train_data\n",
    "        optimizer.zero_grad()\n",
    "        output = model(task_X)\n",
    "        loss = criterion(output, task_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 예측\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predicted = model(task_X)\n",
    "    loss = metricDist(task_y, predicted)\n",
    "    print(\"target latitude, longitude:\", task_y)\n",
    "    print(\"Predicted latitude, longitude:\", predicted)\n",
    "    print(f'loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment  what\n",
       "0        0.0      True\n",
       "182      0.0     False\n",
       "193      0.0     False\n",
       "200      0.0     False\n",
       "207      0.0     False\n",
       "                 ...  \n",
       "980204   0.0     False\n",
       "980214   0.0      True\n",
       "980218   0.0     False\n",
       "980228   0.0      True\n",
       "980229   0.0      True\n",
       "Name: what, Length: 4041, dtype: bool"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment = user_df['segment'].unique()\n",
    "user_df.groupby('segment')['what'].value_counts() > 20\n",
    "\n",
    "# user_df.loc[user_df['segment'] == segment[3], :]\n",
    "\n",
    "# 39.968885\t116.419843\n",
    "# 39.969592\t116.418630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = user_df.copy()\n",
    "df = df.fillna(np.nan)\n",
    "if str(df.iloc[11, -2]) == 'nan':\n",
    "    print('true')\n",
    "else:\n",
    "    print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 68\n",
      "(937876, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_407/1380622558.py:52: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 3\n",
      "(485226, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_407/1380622558.py:52: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 4\n",
      "(439397, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_407/1380622558.py:52: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# csv 파일 5분 단위로 전처리하기 (rounded)\n",
    "# round_min 을 조절하여 round_min 간격으로 data를 전처리\n",
    "\n",
    "from convert_minmax_location import LocationPreprocessor\n",
    "from gps_grid_map_creator import GPSGridMapCreator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "\n",
    "days_min = 0.000696\n",
    "gap = 10\n",
    "round_min = str(gap) + 'min'\n",
    "round_sec = str(gap) + 's'\n",
    "\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "\n",
    "# origin_grid_10min = just add grid in original csv file\n",
    "# grid_10min        = from begin to end full data with fillna(ffill)\n",
    "round_csv = '_origin_round_' + round_sec + '.csv'\n",
    "grid_csv = '_origin_grid_' + round_sec + '.csv'\n",
    "grid_list = [50, 100, 500, 1000, 1500, 2000, 3000]\n",
    "\n",
    "# for id in valid_user_list['valid_user_list']:\n",
    "for id in [68, 3, 4]:\n",
    "    print(f\"user_id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    rounded_file = './Data/' + user_id + '/csv/' + user_id + round_csv\n",
    "    grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(df.shape)\n",
    "    df['datetime'] = pd.to_datetime(df['date'] + \" \" + df['time'])\n",
    "    df['datetime'] = df['datetime'].dt.round(round_sec)\n",
    "\n",
    "    df = df.set_index('datetime').reset_index()\n",
    "    user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
    "    user_df = locationPreprocessor.convert_coord_for_blender_for_user(user_df)\n",
    "\n",
    "    user_df['datetime'] = pd.to_datetime(user_df['datetime'])\n",
    "    \n",
    "    # begin = user_df['datetime'][0]\n",
    "    # end = user_df['datetime'][user_df.shape[0]-1]\n",
    "\n",
    "    # print(f'begin: {begin}')\n",
    "    # print(f'end: {end}')\n",
    "\n",
    "    # date_df = pd.DataFrame({'datetime':pd.date_range(begin, end, freq=round_min)})\n",
    "    # user_df = pd.merge(date_df, user_df, how='outer', on='datetime')\n",
    "    \n",
    "    # # add days \n",
    "    # start_days = user_df['days'][0]\n",
    "    # end_days = start_days + (date_df.shape[0] * (days_min * gap))\n",
    "    # days_list = np.arange(start_days, end_days, (days_min * gap))\n",
    "\n",
    "    # user_df['days'] = days_list[:user_df.shape[0]]\n",
    "    user_df['year'] = user_df['datetime'].dt.year\n",
    "    user_df['month'] = user_df['datetime'].dt.month\n",
    "    user_df['week'] = user_df['datetime'].dt.weekday\n",
    "    user_df['weekend'] = np.where(user_df['week'] < 5, 0, 1)\n",
    "    user_df['hour'] = user_df['datetime'].dt.hour\n",
    "    user_df['day'] = user_df['datetime'].dt.day\n",
    "    # user_df = user_df.fillna(method='ffill')\n",
    "\n",
    "    # 시간 간격 계산\n",
    "    user_df['time_diff'] = user_df['datetime'].diff()\n",
    "\n",
    "    # 1분 이상인 경우 세그먼트로 분류\n",
    "    threshold = pd.Timedelta(minutes=1)\n",
    "    user_df['segment'] = (user_df['time_diff'] > threshold).cumsum()\n",
    "    user_df = user_df.drop(columns=['time_diff'])\n",
    "\n",
    "    # save rounded file\n",
    "    # user_df.to_csv(rounded_file, index=False)\n",
    "\n",
    "    # grid process\n",
    "    user_df = user_df.drop(columns=['altitude', 'what'])\n",
    "    for grid_len in grid_list:\n",
    "        mapCreator = GPSGridMapCreator(grid_len)\n",
    "        mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "        grid_row = 'grid_row_' + str(grid_len) + 'm' # row\n",
    "        grid_col = 'grid_col_' + str(grid_len) + 'm' # column\n",
    "        grid_lat = 'grid_lat_' + str(grid_len) + 'm' # lat\n",
    "        grid_lon = 'grid_lon_' + str(grid_len) + 'm' # lon\n",
    "        grid_num = 'grid_num_' + str(grid_len) + 'm' # num      \n",
    "        user_df[grid_row], user_df[grid_col],_,_,_ = mapCreator.find_grid_number(user_df['latitude'], user_df['longitude'])\n",
    "    # save grid file\n",
    "    user_df.to_csv(grid_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_row_50m</th>\n",
       "      <th>grid_col_50m</th>\n",
       "      <th>grid_row_100m</th>\n",
       "      <th>grid_col_100m</th>\n",
       "      <th>grid_row_500m</th>\n",
       "      <th>grid_col_500m</th>\n",
       "      <th>grid_row_1000m</th>\n",
       "      <th>grid_col_1000m</th>\n",
       "      <th>grid_row_1500m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>147</td>\n",
       "      <td>17</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>163</td>\n",
       "      <td>32</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>171</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>170</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>160</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_row_50m  grid_col_50m  grid_row_100m  grid_col_100m  grid_row_500m  \\\n",
       "0            17           139              8             69              1   \n",
       "1            25           134             12             67              2   \n",
       "2            25           134             12             67              2   \n",
       "3            34           147             17             73              3   \n",
       "4            65           163             32             81              6   \n",
       "5            64           171             32             85              6   \n",
       "6            64           170             32             85              6   \n",
       "7            60           160             30             80              6   \n",
       "8            17           149              8             74              1   \n",
       "9            20           145             10             72              2   \n",
       "\n",
       "   grid_col_500m  grid_row_1000m  grid_col_1000m  grid_row_1500m  \n",
       "0             13               0               6               0  \n",
       "1             13               1               6               0  \n",
       "2             13               1               6               0  \n",
       "3             14               1               7               1  \n",
       "4             16               3               8               2  \n",
       "5             17               3               8               2  \n",
       "6             17               3               8               2  \n",
       "7             16               3               8               2  \n",
       "8             14               0               7               0  \n",
       "9             14               1               7               0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = '035'\n",
    "grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "\n",
    "df = pd.read_csv(grid_file)\n",
    "df.iloc[:10, 11:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.csv 파일의 column 확인 코드\n",
    "import pandas as pd\n",
    "\n",
    "user_id = '067'\n",
    "\n",
    "gap = 10\n",
    "round_min = str(gap) + 'min'\n",
    "grid_csv = '_grid_' + round_min + '.csv'\n",
    "grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "\n",
    "train_file = './Data/' + user_id + '/csv/' + user_id + '_train_set.csv'\n",
    "valid_file = './Data/' + user_id + '/csv/' + user_id + '_valid_set.csv'\n",
    "test_file = './Data/' + user_id + '/csv/' + user_id + '_test_set.csv'\n",
    "\n",
    "df = pd.read_csv(grid_file)\n",
    "print(df.info())\n",
    "# print(df.tail())\n",
    "\n",
    "# columns = df.loc[:, :'grid_col_50m'].columns.to_list() #df.columns[:'grid_col_50m'].to_list() #+ df.columns[58:60].to_list()\n",
    "columns = df.columns[2:11].to_list() #+ df.columns[15:17].to_list()\n",
    "df_1 = df[columns].copy()\n",
    "df_1 = pd.get_dummies(df_1, columns=['hour'], drop_first=True)\n",
    "df_1 = pd.concat([df_1, df.iloc[:, 15:17]], axis=1)\n",
    "print(df_1.columns)\n",
    "print(df_1.tail())\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_valid = pd.read_csv(valid_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "print(f\"train: {df_train.shape[0]}\")\n",
    "print(f\"valid: {df_valid.shape[0]}\")\n",
    "print(f\"test: {df_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 0\n",
      "user_id: 1\n",
      "user_id: 3\n",
      "user_id: 4\n",
      "user_id: 5\n",
      "user_id: 6\n",
      "user_id: 7\n",
      "user_id: 8\n",
      "user_id: 9\n",
      "user_id: 11\n",
      "user_id: 13\n",
      "user_id: 14\n",
      "user_id: 15\n",
      "user_id: 16\n",
      "user_id: 18\n",
      "user_id: 19\n",
      "user_id: 21\n",
      "user_id: 24\n",
      "user_id: 26\n",
      "user_id: 27\n",
      "user_id: 29\n",
      "user_id: 30\n",
      "user_id: 31\n",
      "user_id: 32\n",
      "user_id: 33\n",
      "user_id: 34\n",
      "user_id: 35\n",
      "user_id: 36\n",
      "user_id: 37\n",
      "user_id: 38\n",
      "user_id: 39\n",
      "user_id: 40\n",
      "user_id: 43\n",
      "user_id: 44\n",
      "user_id: 45\n",
      "user_id: 46\n",
      "user_id: 47\n",
      "user_id: 48\n",
      "user_id: 49\n",
      "user_id: 50\n",
      "user_id: 51\n",
      "user_id: 54\n",
      "user_id: 55\n",
      "user_id: 56\n",
      "user_id: 57\n",
      "user_id: 58\n",
      "user_id: 59\n",
      "user_id: 61\n",
      "user_id: 63\n",
      "user_id: 64\n",
      "user_id: 65\n",
      "user_id: 66\n",
      "user_id: 67\n",
      "user_id: 68\n",
      "user_id: 69\n",
      "user_id: 70\n",
      "user_id: 73\n",
      "user_id: 74\n",
      "user_id: 75\n",
      "user_id: 76\n",
      "user_id: 77\n",
      "user_id: 78\n",
      "user_id: 79\n",
      "user_id: 80\n",
      "user_id: 81\n",
      "user_id: 85\n",
      "user_id: 86\n",
      "user_id: 88\n",
      "user_id: 93\n",
      "user_id: 94\n",
      "user_id: 95\n",
      "user_id: 96\n",
      "user_id: 97\n",
      "user_id: 98\n",
      "user_id: 100\n",
      "user_id: 101\n",
      "user_id: 102\n",
      "user_id: 103\n",
      "user_id: 104\n",
      "user_id: 105\n",
      "user_id: 106\n",
      "user_id: 109\n",
      "user_id: 110\n",
      "user_id: 112\n",
      "user_id: 113\n",
      "user_id: 114\n",
      "user_id: 116\n",
      "user_id: 119\n",
      "user_id: 121\n",
      "user_id: 122\n",
      "user_id: 125\n",
      "user_id: 129\n",
      "user_id: 130\n",
      "user_id: 131\n",
      "user_id: 133\n",
      "user_id: 134\n",
      "user_id: 135\n",
      "user_id: 136\n",
      "user_id: 137\n",
      "user_id: 138\n",
      "user_id: 141\n",
      "user_id: 143\n",
      "user_id: 145\n",
      "user_id: 147\n",
      "user_id: 148\n",
      "user_id: 149\n",
      "user_id: 150\n",
      "user_id: 151\n",
      "user_id: 152\n",
      "user_id: 154\n",
      "user_id: 155\n",
      "user_id: 156\n",
      "user_id: 157\n",
      "user_id: 158\n",
      "user_id: 159\n",
      "user_id: 161\n",
      "user_id: 165\n",
      "user_id: 166\n",
      "user_id: 169\n",
      "user_id: 170\n",
      "user_id: 173\n",
      "user_id: 174\n",
      "user_id: 177\n",
      "user_id: 179\n",
      "user_id: 180\n",
      "user_id: 181\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>original_len</th>\n",
       "      <th>rounded_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>2008-10-23 02:53:04</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>173870</td>\n",
       "      <td>2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>2008-10-23 05:53:05</td>\n",
       "      <td>2008-12-15 00:31:18</td>\n",
       "      <td>108607</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>2008-10-23 17:58:54</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>485226</td>\n",
       "      <td>5969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>2008-10-23 17:58:52</td>\n",
       "      <td>2009-07-29 06:16:11</td>\n",
       "      <td>439397</td>\n",
       "      <td>5671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>2008-10-24 04:12:30</td>\n",
       "      <td>2009-03-19 05:46:37</td>\n",
       "      <td>109046</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id          begin_date            end_date  original_len  rounded_len\n",
       "0     000 2008-10-23 02:53:04 2009-07-05 07:45:15        173870         2286\n",
       "1     001 2008-10-23 05:53:05 2008-12-15 00:31:18        108607          940\n",
       "2     003 2008-10-23 17:58:54 2009-07-05 07:45:15        485226         5969\n",
       "3     004 2008-10-23 17:58:52 2009-07-29 06:16:11        439397         5671\n",
       "4     005 2008-10-24 04:12:30 2009-03-19 05:46:37        109046         1249"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import numpy as np\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "user_id_list = []\n",
    "df_len_list = []\n",
    "ori_len_list = []\n",
    "begin_day_list = []\n",
    "end_day_list = []\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"user_id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_origin_round_10min.csv'\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    user_df = pd.read_csv(csv_convert_file)\n",
    "    orig_df = pd.read_csv(csv_file)\n",
    "    orig_df['datetime'] = pd.to_datetime(orig_df['date'] + \" \" + orig_df['time'])\n",
    "\n",
    "    user_id_list += [user_id]\n",
    "    df_len_list += [user_df.shape[0]]\n",
    "    ori_len_list += [orig_df.shape[0]]\n",
    "\n",
    "    begin_day_list += [orig_df.iloc[0, -1]]\n",
    "    end_day_list += [orig_df.iloc[-1, -1]]\n",
    "\n",
    "user_df = pd.DataFrame({'user_id':user_id_list,\n",
    "                        'begin_date':begin_day_list,\n",
    "                        'end_date':end_day_list,\n",
    "                        'original_len':ori_len_list,\n",
    "                        'rounded_len':df_len_list})\n",
    "user_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 100 일 이상 좌표 수집한 user 45명\n",
    "# user_df.to_csv('origin_round_10min_user_list.csv', index=False)\n",
    "\n",
    "df_1 = pd.read_csv('origin_round_10min_user_list.csv')\n",
    "df = pd.read_csv('round_10min_user_list.csv')\n",
    "\n",
    "df = df.merge(df_1, how='inner', on = 'user_id')\n",
    "df = df.loc[df['rounded_len_y'] > 2000, :]\n",
    "df['extra_ratio'] = round(df['rounded_len_x'] / df['rounded_len_y'], 1)\n",
    "\n",
    "df = df.sort_values(['extra_ratio'], ascending=True)\n",
    "\n",
    "df = df.rename(columns = {'rounded_len_y':'rounded_10min_len',\n",
    "                          'rounded_len_x':'date_rounded',\n",
    "                          'original_len_x':'original_len'})\n",
    "df = df[['user_id','begin_date','end_date','date_rounded','original_len', 'rounded_10min_len', 'extra_ratio']]\n",
    "df.head()\n",
    "df.to_csv('extra_ratio.csv', index=False)\n",
    "\n",
    "# df = df.loc[df['rounded_len'] >= 14400, :]\n",
    "# df['user_id'].to_list()\n",
    "# df.head(20)\n",
    "# df.sort_values('rounded_len', ascending=False)\n",
    "# ['068', '030', '085', '003', '004']\",\"['065', '067']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>date_rounded</th>\n",
       "      <th>original_len</th>\n",
       "      <th>rounded_10min_len</th>\n",
       "      <th>extra_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>2009-02-09 10:48:38</td>\n",
       "      <td>2009-04-27 06:14:45</td>\n",
       "      <td>11061</td>\n",
       "      <td>312042</td>\n",
       "      <td>3162</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-10-23 17:58:54</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>36660</td>\n",
       "      <td>485226</td>\n",
       "      <td>5969</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>2009-01-13 02:32:22</td>\n",
       "      <td>2009-07-29 01:40:07</td>\n",
       "      <td>28364</td>\n",
       "      <td>615948</td>\n",
       "      <td>4320</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-10-23 17:58:52</td>\n",
       "      <td>2009-07-29 06:16:11</td>\n",
       "      <td>40107</td>\n",
       "      <td>439397</td>\n",
       "      <td>5671</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>2009-02-11 09:59:38</td>\n",
       "      <td>2009-07-15 00:56:11</td>\n",
       "      <td>22123</td>\n",
       "      <td>267737</td>\n",
       "      <td>3098</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>2008-12-16 01:00:33</td>\n",
       "      <td>2009-05-26 10:51:12</td>\n",
       "      <td>23244</td>\n",
       "      <td>263482</td>\n",
       "      <td>2648</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>2008-09-14 13:03:08</td>\n",
       "      <td>2009-09-13 12:51:15</td>\n",
       "      <td>52416</td>\n",
       "      <td>937876</td>\n",
       "      <td>5073</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>2009-02-06 12:11:02</td>\n",
       "      <td>2009-07-23 18:13:12</td>\n",
       "      <td>24085</td>\n",
       "      <td>250393</td>\n",
       "      <td>2069</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>2008-10-20 05:45:00</td>\n",
       "      <td>2009-04-17 01:50:18</td>\n",
       "      <td>25754</td>\n",
       "      <td>388213</td>\n",
       "      <td>2136</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 02:53:04</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>36751</td>\n",
       "      <td>173870</td>\n",
       "      <td>2286</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id           begin_date             end_date  date_rounded  \\\n",
       "0       35  2009-02-09 10:48:38  2009-04-27 06:14:45         11061   \n",
       "1        3  2008-10-23 17:58:54  2009-07-05 07:45:15         36660   \n",
       "2       30  2009-01-13 02:32:22  2009-07-29 01:40:07         28364   \n",
       "3        4  2008-10-23 17:58:52  2009-07-29 06:16:11         40107   \n",
       "4       39  2009-02-11 09:59:38  2009-07-15 00:56:11         22123   \n",
       "5       24  2008-12-16 01:00:33  2009-05-26 10:51:12         23244   \n",
       "6       68  2008-09-14 13:03:08  2009-09-13 12:51:15         52416   \n",
       "7       38  2009-02-06 12:11:02  2009-07-23 18:13:12         24085   \n",
       "8       14  2008-10-20 05:45:00  2009-04-17 01:50:18         25754   \n",
       "9        0  2008-10-23 02:53:04  2009-07-05 07:45:15         36751   \n",
       "\n",
       "   original_len  rounded_10min_len  extra_ratio  \n",
       "0        312042               3162          3.5  \n",
       "1        485226               5969          6.1  \n",
       "2        615948               4320          6.6  \n",
       "3        439397               5671          7.1  \n",
       "4        267737               3098          7.1  \n",
       "5        263482               2648          8.8  \n",
       "6        937876               5073         10.3  \n",
       "7        250393               2069         11.6  \n",
       "8        388213               2136         12.1  \n",
       "9        173870               2286         16.1  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "user = pd.read_csv('extra_ratio.csv')\n",
    "user.head(10)\n",
    "# user = user.sort_values('original_len', ascending=False)\n",
    "# user = user[['user_id', 'original_len', 'extra_rounded', 'rounded_10min', 'extra_ratio']]\n",
    "# user.rename(columns={'extra_rounded':'rounded_10min',\n",
    "#                      'rounded_10min':'rounded_len'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_id = '085'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user_df = pd.read_csv(csv_convert_file)\n",
    "user_df.head(1)\n",
    "\n",
    "# user_df = user_df[['days','month','week','weekend','hour','day','x','y']]\n",
    "# user_df = pd.get_dummies(user_df, columns=['week','month'], drop_first=True)\n",
    "# user_xy = user_df.loc[:, ['x', 'y']]\n",
    "# user_df = user_df.drop(columns=['x', 'y'])\n",
    "# pd.concat([user_df, user_xy], axis=1)\n",
    "\n",
    "df_1 = user_df[['days','month','week','weekend','hour','day','x','y']]\n",
    "df_1 = pd.get_dummies(df_1, columns=['week','month'], drop_first=True)\n",
    "df_xy = df_1.loc[:, ['x', 'y']]\n",
    "df_1 = df_1.drop(columns=['x', 'y'])\n",
    "df_1 = pd.concat([df_1, df_xy], axis=1)\n",
    "df_1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame({\"user_id\":user_id_list,\n",
    "                        \"data_vol\":df_len_list})\n",
    "user_df = user_df.sort_values(['data_vol'], ascending=False)\n",
    "user_df.to_csv('user_data_volumn.csv', index=False)\n",
    "\n",
    "print(user_df.head(5))\n",
    "user_df.iloc[:5, 0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_s = 1\n",
    "sample_q = 1\n",
    "\n",
    "args_epoch = 1200\n",
    "args_patience = 300\n",
    "\n",
    "gap_min = 12 # 1 min\n",
    "gap = gap_min\n",
    "\n",
    "y_timestep = 100 # must be less than length\n",
    "length = 15000\n",
    "\n",
    "train_list      = ['068', '030', '085', '004']#, '085']\n",
    "validation_list = ['067']#, '085']\n",
    "test_list       = ['067']#, '085']\n",
    "\n",
    "conf_df = pd.DataFrame({'sample_s':[sample_s],\n",
    "                        'sample_q':[sample_q],\n",
    "                        'epoch':[args_epoch],\n",
    "                        'patience':[args_patience],\n",
    "                        'gap':[gap],\n",
    "                        'y_timestep':[y_timestep],\n",
    "                        'length':[length],\n",
    "                        'train_list':[train_list],\n",
    "                        'val_list':[validation_list],\n",
    "                        'test_list':[test_list]})\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.loc[user_df['user_id'] == '001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df_pre = user_location_df.copy()\n",
    "user_location_df_pre = user_location_df_pre.set_index('user_id', drop=True).copy()\n",
    "user_location_df_pre.head(2)\n",
    "\n",
    "X = ['min_lat', 'min_lon', 'max_lat', 'max_lon']\n",
    "q1 = user_location_df_pre[X].quantile(0.25)\n",
    "q3 = user_location_df_pre[X].quantile(0.75)\n",
    "iqr = (q3-q1) * 1.5\n",
    "\n",
    "cond1 = user_location_df_pre[X] >= (q1 - iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond1].dropna().copy()\n",
    "print(user_location_df_pre.shape)\n",
    "\n",
    "cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond2].dropna().copy()\n",
    "print(user_location_df_pre.shape)\n",
    "user_location_df_pre.min()\n",
    "user_location_df_pre.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "PI = 3.14159265358979323846\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2, unit):\n",
    "    deg2rad_multiplier = PI / 180\n",
    "    lat1 = lat1 * deg2rad_multiplier\n",
    "    lon1 = lon1 * deg2rad_multiplier\n",
    "    lat2 = lat2 * deg2rad_multiplier\n",
    "    lon2 = lon2 * deg2rad_multiplier\n",
    "\n",
    "    radius = 6378.137  # Earth mean radius defined by WGS84\n",
    "    dlon = lon2 - lon1\n",
    "    distance = math.acos(math.sin(lat1) * math.sin(lat2) + math.cos(lat1) * math.cos(lat2) * math.cos(dlon)) * radius\n",
    "    \n",
    "    # (kilometers, miles, nautical miles)\n",
    "    if unit == 'K':\n",
    "        return distance\n",
    "    elif unit == 'M':\n",
    "        return distance * 0.621371192\n",
    "    elif unit == 'N':\n",
    "        return distance * 0.539956803\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Example usage:\n",
    "result = distance(37.7749, -122.4194, 34.0522, -118.2437, 'K') * 1000\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 39.975300\n",
    "min_lon = 116.452488\n",
    "max_lat = 41.367085\n",
    "max_lon = 122.651456\n",
    "\n",
    "width = round(distance(39.975300, 122.651456, 41.367085, 122.651456, 'K'), 3)\n",
    "height = round(distance(41.367085, 116.452488, 41.367085, 122.651456, 'K'), 3)\n",
    "print(width)\n",
    "print(height)\n",
    "# up_width = 154.933\n",
    "# down_width = 154.933\n",
    "# left_height = 528.706\n",
    "# right_hegith = 517.778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class GPSGridMapCreator():\n",
    "    def __init__(self, grid_size_meter):\n",
    "        self.grid_size_meter = grid_size_meter\n",
    "        self.lat1 = 0\n",
    "        self.lon1 = 0\n",
    "        self.grid_numbers = 0\n",
    "        self.lat_degrees = 0\n",
    "        self.long_degrees = 0\n",
    "        self.num_lat = 0\n",
    "        self.num_lon = 0\n",
    "        \n",
    "    def km_to_degrees(self, latitude, kilometers):\n",
    "        # Earth's radius in kilometers\n",
    "        earth_radius_km = 6371.0\n",
    "\n",
    "        # Convert kilometers to radians\n",
    "        angle_rad = kilometers / earth_radius_km\n",
    "\n",
    "        # Convert radians to degrees\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "        # Correction factor for latitude\n",
    "        lat_correction = np.cos(np.radians(latitude))\n",
    "\n",
    "        # Convert degrees to adjusted degrees\n",
    "        adjusted_degrees = angle_deg / lat_correction\n",
    "\n",
    "        return adjusted_degrees\n",
    "\n",
    "    def meter_to_degrees(self, latitude, meters):\n",
    "        # Convert meters to kilometers\n",
    "        kilometers = meters / 1000\n",
    "\n",
    "        # Convert kilometers to degrees using the km_to_degrees function\n",
    "        degrees = self.km_to_degrees(latitude, kilometers)\n",
    "\n",
    "        return degrees\n",
    "\n",
    "    def create_grid_map(self, lat1, lon1, lat2, lon2):\n",
    "        self.lat1 = lat1\n",
    "        self.lon1 = lon1\n",
    "        # Convert grid size from meters to degrees\n",
    "        self.lat_degrees = self.meter_to_degrees((lat1 + lat2) / 2, self.grid_size_meter)\n",
    "        self.lon_degrees = self.meter_to_degrees((lon1 + lon2) / 2, self.grid_size_meter)\n",
    "\n",
    "        # print(f\"lat_degrees: {self.lat_degrees}, lon_degree: {self.lon_degrees}\")\n",
    "        # Calculate the number of grid points in latitude and longitude directions\n",
    "        self.num_lat = int(np.abs(lat2 - lat1) / np.abs(self.lat_degrees))\n",
    "        self.num_lon = int(np.abs(lon2 - lon1) / np.abs(self.lon_degrees))\n",
    "        # print(f\"lon2 - lon1: {np.abs(lon2 - lon1)}\")\n",
    "        # print(f\"num_lat: {self.num_lat}, num_lon: {self.num_lon}\")\n",
    "\n",
    "        # Generate latitude and longitude grid points\n",
    "        latitudes = np.linspace(lat1, lat2, self.num_lat)\n",
    "        longitudes = np.linspace(lon1, lon2, self.num_lon)\n",
    "\n",
    "        # print(f\"the num of latitudes: {len(latitudes)}\")\n",
    "        # print(f\"the num of longitude: {len(longitudes)}\")\n",
    "        # print(latitudes)\n",
    "        # print(longitudes)\n",
    "        # Create a 2D grid for numbering\n",
    "        self.grid_numbers = np.arange(0, (self.num_lat + 1) * (self.num_lon + 1)).reshape(self.num_lat + 1, self.num_lon + 1)\n",
    "        print(f\"gird_number: {self.grid_numbers.shape[0] * self.grid_numbers.shape[1]}\")\n",
    "\n",
    "    def find_grid_number(self, lat, lon):\n",
    "        grid_lat = int((lat - self.lat1) / np.abs(self.lat_degrees))\n",
    "        grid_lon = int((lon - self.lon1) / np.abs(self.lon_degrees))\n",
    "        gird_number = grid_lat * (self.num_lon + 1) + grid_lon + 1\n",
    "        return gird_number, grid_lat, grid_lon\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "grid_size_meter = 100  # Size of each grid in meters\n",
    "\n",
    "mapCreator = GPSGridMapCreator(grid_size_meter)\n",
    "mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "print(mapCreator.find_grid_number(39.99, 117.5))\n",
    "print(\"done\")\n",
    "# 3991600\n",
    "# 15966400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def km_to_degrees(latitude, kilometers):\n",
    "    # Earth's radius in kilometers\n",
    "    earth_radius_km = 6371.0\n",
    "\n",
    "    # Convert kilometers to radians\n",
    "    angle_rad = kilometers / earth_radius_km\n",
    "\n",
    "    # Convert radians to degrees\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    # Correction factor for latitude\n",
    "    lat_correction = np.cos(np.radians(latitude))\n",
    "\n",
    "    # Convert degrees to adjusted degrees\n",
    "    adjusted_degrees = angle_deg / lat_correction\n",
    "\n",
    "    return adjusted_degrees\n",
    "\n",
    "def meter_to_degrees(latitude, meters):\n",
    "    # Convert meters to kilometers\n",
    "    kilometers = meters / 1000\n",
    "\n",
    "    # Convert kilometers to degrees using the km_to_degrees function\n",
    "    degrees = km_to_degrees(latitude, kilometers)\n",
    "\n",
    "    return degrees\n",
    "\n",
    "def create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter):\n",
    "    # Convert grid size from meters to degrees\n",
    "    lat_degrees = meter_to_degrees((lat1 + lat2) / 2, grid_size_meter)\n",
    "    lon_degrees = meter_to_degrees((lon1 + lon2) / 2, grid_size_meter)\n",
    "\n",
    "    print(f\"lat_degrees: {lat_degrees}, lon_degree: {lon_degrees}\")\n",
    "    # Calculate the number of grid points in latitude and longitude directions\n",
    "    num_lat = int(np.abs(lat2 - lat1) / np.abs(lat_degrees))\n",
    "    num_lon = int(np.abs(lon2 - lon1) / np.abs(lon_degrees))\n",
    "    print(f\"lon2 - lon1: {np.abs(lon2 - lon1)}\")\n",
    "    print(f\"num_lat: {num_lat}, num_lon: {num_lon}\")\n",
    "\n",
    "    # Calculate the latitude and longitude increments\n",
    "    # lat_increment = (lat2 - lat1) / num_lat\n",
    "    # lon_increment = (lon2 - lon1) / num_lon\n",
    "\n",
    "    # Generate latitude and longitude grid points\n",
    "    latitudes = np.linspace(lat1, lat2, num_lat)\n",
    "    longitudes = np.linspace(lon1, lon2, num_lon)\n",
    "\n",
    "    print(f\"the num of latitudes: {len(latitudes)}\")\n",
    "    print(f\"the num of longitude: {len(longitudes)}\")\n",
    "    print(longitudes)\n",
    "    # Create a 2D grid for numbering\n",
    "    grid_numbers = np.arange(0, (num_lat + 1) * (num_lon + 1)).reshape(num_lat + 1, num_lon + 1)\n",
    "\n",
    "    # # Plot the grid lines\n",
    "    # for lat in latitudes:\n",
    "    #     ax.plot([lon1, lon2], [lat, lat], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "    # for lon in longitudes:\n",
    "    #     ax.plot([lon, lon], [lat1, lat2], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Plot the numbers on the grid\n",
    "    # for i in range(num_lat + 1):\n",
    "    #     for j in range(num_lon + 1):\n",
    "    #         ax.text(lon1 + j * lon_increment, lat1 + i * lat_increment, str(grid_numbers[i, j]),\n",
    "    #                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # ax.coastlines()\n",
    "    # plt.show()\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 37.0, -122.0  # Lower-left corner\n",
    "lat2, lon2 = 38.0, -121.0  # Upper-right corner\n",
    "grid_size_meter = 1000  # Size of each grid in meters\n",
    "\n",
    "create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def km_to_degrees(latitude, kilometers):\n",
    "    earth_radius_km = 6371.0\n",
    "    angle_rad = kilometers / earth_radius_km\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    lat_correction = np.cos(np.radians(latitude))\n",
    "    adjusted_degrees = angle_deg / lat_correction\n",
    "    return adjusted_degrees\n",
    "\n",
    "def meter_to_degrees(latitude, meters):\n",
    "    kilometers = meters / 1000\n",
    "    degrees = km_to_degrees(latitude, kilometers)\n",
    "    return degrees\n",
    "\n",
    "def find_grid_number(lat, lon, lat1, lon1, lat_degrees, lon_degrees):\n",
    "    grid_lat = int((lat - lat1) / lat_degrees)\n",
    "    grid_lon = int((lon - lon1) / lon_degrees)\n",
    "    return grid_lat, grid_lon\n",
    "\n",
    "def create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter):\n",
    "    lat_degrees = meter_to_degrees((lat1 + lat2) / 2, grid_size_meter)\n",
    "    lon_degrees = meter_to_degrees((lon1 + lon2) / 2, grid_size_meter)\n",
    "\n",
    "    num_lat = int(np.abs(lat2 - lat1) / lat_degrees)\n",
    "    num_lon = int(np.abs(lon2 - lon1) / lon_degrees)\n",
    "\n",
    "    lat_increment = (lat2 - lat1) / num_lat\n",
    "    lon_increment = (lon2 - lon1) / num_lon\n",
    "\n",
    "    latitudes = np.linspace(lat1, lat2, num_lat)\n",
    "    longitudes = np.linspace(lon1, lon2, num_lon)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.stock_img()\n",
    "\n",
    "    for lat in latitudes:\n",
    "        ax.plot([lon1, lon2], [lat, lat], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "    for lon in longitudes:\n",
    "        ax.plot([lon, lon], [lat1, lat2], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "    for i in range(num_lat + 1):\n",
    "        for j in range(num_lon + 1):\n",
    "            ax.text(lon1 + j * lon_increment, lat1 + i * lat_increment, str(i * (num_lon + 1) + j + 1),\n",
    "                    horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Example input coordinates\n",
    "    input_coordinates = [(37.5, -121.5), (37.3, -122.3), (37.7, -122.7)]\n",
    "    for lat, lon in input_coordinates:\n",
    "        grid_lat, grid_lon = find_grid_number(lat, lon, lat1, lon1, lat_degrees, lon_degrees)\n",
    "        ax.text(lon, lat, f\"{grid_lat * (num_lon + 1) + grid_lon + 1} ({grid_lat},{grid_lon})\",\n",
    "                horizontalalignment='center', verticalalignment='center', color='red', fontsize=8, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 37.0, -122.0  # Lower-left corner\n",
    "lat2, lon2 = 38.0, -121.0  # Upper-right corner\n",
    "grid_size_meter = 1000  # Size of each grid in meters\n",
    "\n",
    "create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user_list = user_location_df_pre.index\n",
    "valid_user_list = pd.DataFrame({'valid_user_list':user_location_df_pre.index})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "X = ['latitude', 'longitude', 'x', 'y']\n",
    "user_min_df = pd.DataFrame(columns=X)\n",
    "user_max_df = pd.DataFrame(columns=X)\n",
    "for user_id in valid_user_list['valid_user_list']:\n",
    "    # user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "    user0 = pd.read_csv(csv_file)\n",
    "    min_df = pd.DataFrame(data=user0[X].min()).transpose()\n",
    "    max_df = pd.DataFrame(data=user0[X].max()).transpose()\n",
    "    \n",
    "    user_min_df = pd.concat([user_min_df, min_df])\n",
    "    user_max_df = pd.concat([user_max_df, max_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_min_df[['x', 'y']].min())\n",
    "print(user_max_df[['x', 'y']].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = pd.DataFrame(user_min_df.min()).transpose()\n",
    "df_max = pd.DataFrame(user_min_df.max()).transpose()\n",
    "df_max_min = pd.DataFrame(user_min_df.max()-user_min_df.min()).transpose()\n",
    "df_diff = pd.concat([df_min, df_max, df_max_min])\n",
    "df_diff['label'] = ['min', 'max', 'max-min']\n",
    "\n",
    "round(df_diff.set_index('label'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "\n",
    "user_df = user[['latitude', 'longitude', 'x', 'y', 'days', 'time']].copy()\n",
    "\n",
    "idx_list = []\n",
    "for idx in range(user_df.shape[0]):\n",
    "    if idx % 60 == 0: # 5 mins\n",
    "        idx_list += [idx]\n",
    "len(idx_list)\n",
    "\n",
    "idx_list_partial = idx_list[-200:]\n",
    "user_df_1 = user_df.iloc[idx_list_partial, :].copy()\n",
    "\n",
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "# axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=20)\n",
    "# axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'], s=20)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'])\n",
    "\n",
    "axes.set_xlabel('time')\n",
    "# axes.set_ylabel('X')\n",
    "# axes.set_zlabel('Y')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')\n",
    "\n",
    "user_df_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df\n",
    "task_X = user_df.copy()\n",
    "task_y = task_X.iloc[-5:, -2:].copy()\n",
    "\n",
    "task_y.iloc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geopandas: https://datascientyst.com/plot-latitude-longitude-pandas-dataframe-python/\n",
    "# pip install geopandas\n",
    "# pip install Shapely\n",
    "\n",
    "# folium: https://aboutnlp.tistory.com/33\n",
    "\n",
    "import pandas as pd\n",
    "from convert_minmax_location import LocationPreprocessor\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folium\n",
    "from branca.element import Figure\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "\n",
    "fig = Figure(width=550, height=350)\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "    user = pd.read_csv(csv_file)\n",
    "    user_location_list = user[['latitude', 'longitude']].values.tolist()\n",
    "    center = user_location_list[0]\n",
    "    \n",
    "    map = folium.Map(location=center,\n",
    "                     zoom_start=10)\n",
    "    fig.add_child(map)\n",
    "    folium.PolyLine(locations = user_location_list,).add_to(map)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://anweh.tistory.com/17\n",
    "\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.head())\n",
    "user_coords = user[['latitude', 'longitude']].values.tolist()\n",
    "lat = user['latitude'].mean()\n",
    "lon = user['longitude'].mean()\n",
    "center = [lat, lon]\n",
    "\n",
    "map = folium.Map(location=center,\n",
    "                    zoom_start=9)\n",
    "k = 0\n",
    "for i in range(len(user_coords)):\n",
    "    if (i % 60) == 0:\n",
    "        _color = '#' + str(k)\n",
    "        k += 1\n",
    "        folium.Circle(\n",
    "            location = user_coords[i],\n",
    "            radius = 20,\n",
    "            # fill_color = 'Reds'\n",
    "            # color = 'Reds', #'#000000',\n",
    "            tooltip = user.iloc[i, -2:],\n",
    "            fill = 'crimson',\n",
    "        ).add_to(map)\n",
    "map.save('map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "user_id = locationPreprocessor.getUserId(29)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.shape[0])\n",
    "print(user.head(10))\n",
    "# user = user.drop_duplicates(subset=['date', 'time'])\n",
    "user = user.drop_duplicates(subset=['days'])\n",
    "print(user.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = user[['latitude', 'longitude', 'x', 'y', 'days', 'time']].copy()\n",
    "\n",
    "idx_list = []\n",
    "for idx in range(user_df.shape[0]):\n",
    "    if idx % 120 == 0:\n",
    "        idx_list += [idx]\n",
    "len(idx_list)\n",
    "\n",
    "idx_list_partial = idx_list[-50:]\n",
    "user_df_1 = user_df.iloc[idx_list_partial, :].copy()\n",
    "user_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=20)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.set_xlabel('time')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "# axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=10)\n",
    "# axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'], s=10)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'])\n",
    "axes.set_xlabel('time')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')\n",
    "# axes.set_xticklabels(one_hour['datetime'], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.head())\n",
    "user_coords = user[['latitude', 'longitude']].values.tolist()\n",
    "\n",
    "begin_hour = user_sub.iloc[0, -1]\n",
    "end_hour = user_sub.iloc[-1, -1]\n",
    "\n",
    "print('begin_hour:', begin_hour, ', end_hour:', end_hour)\n",
    "count = 1\n",
    "while begin_hour <= end_hour:\n",
    "    condtion = (user_sub['hour'] >= begin_hour) & (user_sub['hour'] <= begin_hour + count)\n",
    "    one_hour = user_sub.loc[condtion, :]\n",
    "    begin_hour = begin_hour + count\n",
    "    if one_hour.shape[0] < 1:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(60, 12))\n",
    "    axes = plt.axes(projection='3d')\n",
    "    axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "    one_hour['time_reg'] = [str(dd.time()) for dd in one_hour['datetime']]\n",
    "    axes.scatter3D(dates.date2num(one_hour['datetime']), one_hour['latitude'], one_hour['longitude'], s=10)\n",
    "    axes.plot3D(dates.date2num(one_hour['datetime']), one_hour['latitude'], one_hour['longitude'])\n",
    "    axes.set_xlabel('time')\n",
    "    axes.set_ylabel('latitude')\n",
    "    axes.set_zlabel('longitude')\n",
    "    axes.set_xticklabels(one_hour['datetime'], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location(Latitude, Logitude) 에 대한 최소, 최대값을 구해야 함.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "min_lat_list = []\n",
    "min_lon_list = []\n",
    "max_lat_list = []\n",
    "max_lon_list = []\n",
    "\n",
    "user_id_list = []\n",
    "for id in range(182):\n",
    "    user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if df.shape[0] < 500:\n",
    "        continue\n",
    "\n",
    "    user0 = df[['days', 'latitude', 'longitude']].copy()\n",
    "    user_id_list += [user_id]\n",
    "    min_lat_list += [user0['latitude'].min()]\n",
    "    max_lat_list += [user0['latitude'].max()]\n",
    "    min_lon_list += [user0['longitude'].min()]\n",
    "    max_lon_list += [user0['longitude'].max()]\n",
    "    \n",
    "    # if user0['latitude'].min() < min_lat:\n",
    "    #     min_lat = user0['latitude'].min()\n",
    "    # if user0['latitude'].max() > max_lat:\n",
    "    #     max_lat = user0['latitude'].max()\n",
    "    # if user0['longitude'].min() < min_lon:\n",
    "    #     min_lon = user0['longitude'].min()\n",
    "    # if user0['longitude'].max() > max_lon:\n",
    "    #     max_lon = user0['longitude'].max()\n",
    "\n",
    "print(f\"min_lat: {min_lat}, min_lon: {min_lon}\")\n",
    "print(f\"max_lat: {max_lat}, max_lon: {max_lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df = pd.DataFrame({'user_id':user_id_list,\n",
    "                                'min_lat':min_lat_list,\n",
    "                                'min_lon':min_lon_list,\n",
    "                                'max_lat':max_lat_list,\n",
    "                                'max_lon':max_lon_list})\n",
    "user_location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df_pre = user_location_df.copy()\n",
    "user_location_df_pre = user_location_df_pre.set_index('user_id', drop=True).copy()\n",
    "\n",
    "X = ['min_lat', 'min_lon', 'max_lat', 'max_lon']\n",
    "q1 = user_location_df_pre[X].quantile(0.25)\n",
    "q3 = user_location_df_pre[X].quantile(0.75)\n",
    "iqr = (q3-q1) * 1.5\n",
    "\n",
    "cond1 = user_location_df_pre[X] >= (q1 - iqr)\n",
    "# cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "\n",
    "user_location_df_pre = user_location_df_pre[cond1].dropna().copy()\n",
    "cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond2].dropna()\n",
    "valid_user_list = user_location_df_pre.index\n",
    "print(f'valid user list: {valid_user_list}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df = pd.DataFrame({'valid_user_list':valid_user_list})\n",
    "df.to_csv('valid_user_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user = pd.read_csv('valid_user_list.csv')\n",
    "valid_user['valid_user_list']\n",
    "\n",
    "# location(Latitude, Logitude) 에 대한 최소, 최대값을 구해야 함.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "for id in valid_user['valid_user_list']:\n",
    "    user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    user0 = pd.read_csv(csv_file)\n",
    "    \n",
    "    if user0['latitude'].min() < min_lat:\n",
    "        min_lat = user0['latitude'].min()\n",
    "    if user0['latitude'].max() > max_lat:\n",
    "        max_lat = user0['latitude'].max()\n",
    "    if user0['longitude'].min() < min_lon:\n",
    "        min_lon = user0['longitude'].min()\n",
    "    if user0['longitude'].max() > max_lon:\n",
    "        max_lon = user0['longitude'].max()\n",
    "\n",
    "print(f\"min_lat: {min_lat}, min_lon: {min_lon}\")\n",
    "print(f\"max_lat: {max_lat}, max_lon: {max_lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_minmax_location import get_minmax_location\n",
    "\n",
    "get_minmax_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_minmax_location import LocationPreprocessor\n",
    "\n",
    "locationPreprocess = LocationPreprocessor()\n",
    "center_locatuon = locationPreprocess.get_center_location()\n",
    "\n",
    "earth_radius = 6371000\n",
    "\n",
    "def convert_coord_for_blender(lat, lon):\n",
    "    delta_lat = lat - center_locatuon[0]\n",
    "    delta_lon = lon - center_locatuon[1]\n",
    "    \n",
    "    x = delta_lon * earth_radius * (np.pi / 180) * np.cos(lat * (np.pi / 180))\n",
    "    y = delta_lat * earth_radius * (np.pi / 180)\n",
    " \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_coord_for_blender(self, lat, lon):\n",
    "    delta_lat = lat - self.center_coord[0]\n",
    "    delta_lon = lon - self.center_coord[1]\n",
    "\n",
    "    x = delta_lon * self.earth_radius * (np.pi / 180) * np.cos(lat * (np.pi / 180))\n",
    "    y = delta_lat * self.earth_radius * (np.pi / 180)\n",
    " \n",
    "    return x, y\n",
    " \n",
    "earth_radius = 6371000\n",
    "lower_left_coord = [self.config['coords']['lower_left']['lat'], self.config['coords']['lower_left']['lon']]\n",
    "upper_right_coord = [self.config['coords']['upper_right']['lat'], self.config['coords']['upper_right']['lon']]\n",
    "center_coord = [\n",
    "    (self.lower_left_coord[0] + self.upper_right_coord[0]) / 2,\n",
    "    (self.lower_left_coord[1] + self.upper_right_coord[1]) / 2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(0).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 은 샘플과 정답(label)을 저장하고, \n",
    "# DataLoader 는 Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
    "# https://wikidocs.net/156998\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "    # 생성자, 데이터를 전처리하는 부분\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 99, 95]]\n",
    "        self.y_data = [[152], \n",
    "                       [185]]\n",
    "    \n",
    "    def __len__(self):\n",
    "    # 데이터셋의 총 길이를 반환하는 부분\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    # idx 에 해당하는 입출력 데이터를 반환한다.\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "    \n",
    "customData = CustomDataset()\n",
    "customData.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "index = 10\n",
    "data_dir = 'Data/'\n",
    "csv_dir = 'csv/'\n",
    "csv_extension = '.csv'\n",
    "user_path_list = os.listdir(data_dir)\n",
    "csv_path = os.path.join(data_dir, user_path_list[index], csv_dir)\n",
    "user_file = csv_path + user_path_list[index] + '.csv'\n",
    "df = pd.read_csv(user_file)\n",
    "df[[\"days\",\"latitude\", \"longitude\"]].head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Data folder 중 숫자가 안되는 User folder는 삭제하고\n",
    "# 남은 User data에서 train-test 폴더로 나눈 후\n",
    "# train_set(dataset), test_set(dataset) 으로 진행 필요\n",
    "\n",
    "class GeoLifeDataSet(Dataset):\n",
    "    def __init__(self, data_dir, user_list, samples_s, samples_q, length, y_timestep):\n",
    "        self.data_dir   = data_dir\n",
    "        self.csv_dir    = 'csv/'\n",
    "        self.user_list  = user_list\n",
    "        # user_list: all user\n",
    "        self.samples_s  = samples_s\n",
    "        # samples_s: the number of support set\n",
    "        self.samples_q  = samples_q\n",
    "        # samples_q: the number of query set\n",
    "        self.length     = length \n",
    "        # length: the length of mini batch of a user\n",
    "        self.y_timestep = y_timestep\n",
    "        # y_time_step: the next time step to be predicted\n",
    "        #              it must be less than length\n",
    "    \n",
    "    def sampleTime(self, dataset):\n",
    "        cur_ds = dataset.copy()\n",
    "        minibatch = []\n",
    "        \n",
    "        max_len = len(cur_ds)\n",
    "        ###############################################\n",
    "        # MAke sure samples from query and support \n",
    "        # do not intersect\n",
    "        ##############################################\n",
    "        # total_data_slice -> lenght 만큼 나눴을 때 총 slice 갯수\n",
    "        total_data_slice = list(range(int(max_len/self.length)))\n",
    "        total_samps = self.samples_q + self.samples_s\n",
    "        \n",
    "        slice_point = int(len(total_data_slice)*(self.samples_s/total_samps))\n",
    "        # print(f\"slice_point: {slice_point}\")\n",
    "\n",
    "        s_s_list = total_data_slice[:slice_point]\n",
    "        q_s_list = total_data_slice[slice_point:]\n",
    "\n",
    "        replace = False\n",
    "        if total_samps > len(total_data_slice):\n",
    "            replace = True\n",
    "\n",
    "        s_s_list = np.random.choice(s_s_list, size=self.samples_s, replace=replace)\n",
    "        q_s_list = np.random.choice(q_s_list, size=self.samples_q, replace=replace)\n",
    "        \n",
    "        # print(f\"s_list:{s_s_list}\")\n",
    "        # print(f\"q_list:{q_s_list}\")\n",
    "        choice_list = np.concatenate([s_s_list, q_s_list])\n",
    "        # #################################################\n",
    "        # print(f\"choice_list: {choice_list}\")\n",
    "        \n",
    "        for idx in choice_list:\n",
    "            start_idx = idx * self.length\n",
    "            if max_len - self.length >= 0:\n",
    "                cur_sample = cur_ds.iloc[start_idx:(start_idx + self.length), :]\n",
    "                minibatch.append(cur_sample)\n",
    "            else:\n",
    "                fill_quota  = np.abs(self.length - max_len)\n",
    "                zeros_r     = np.zeros([fill_quota, cur_ds.shape[1]])\n",
    "                cur_sample  = cur_ds[:, :]\n",
    "                cur_sample  = np.concatenate([zeros_r, cur_sample], axis = 0)\n",
    "                minibatch.append(cur_sample)\n",
    "        return np.array(minibatch)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        csv_path = os.path.join(self.data_dir, self.user_list[index], self.csv_dir)\n",
    "        user_file = csv_path + self.user_list[index] + '.csv'\n",
    "        df = pd.read_csv(user_file)\n",
    "        df = df[['days','latitude', 'longitude']]\n",
    "\n",
    "        samples = self.sampleTime(df)\n",
    "        # print(f\"mini_batch: {samples.shape}\")\n",
    "        # mini_batch: (5, 10, 3)\n",
    "        \n",
    "        sup_x = np.array(samples[:self.samples_s, :-self.y_timestep, :])\n",
    "        sup_y = np.array(samples[:self.samples_s, -self.y_timestep:, -2:])\n",
    "        que_x = np.array(samples[self.samples_s:, :-self.y_timestep, :])\n",
    "        que_y = np.array(samples[self.samples_s:, -self.y_timestep:, -2:])\n",
    "\n",
    "        return (que_x, sup_x, sup_y), que_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        # batch를 구성할 수 있는 총 수\n",
    "        # 이 수에서 batch를 조정할 수 있다.\n",
    "        # 몇 명의 user 로 나눠서 할 지\n",
    "        return len(self.user_list)\n",
    "\n",
    "user_list = os.listdir(data_dir)\n",
    "random.shuffle(user_list)\n",
    "train_size = 0.1\n",
    "train_list = user_list[:(int)(len(user_list)*train_size)]\n",
    "print(f\"train_list: {len(train_list)}\")\n",
    "\n",
    "# dataset = GeoLifeDataSet(\"Data/\", [0, 1, 2, 3], 5, 2, 100, 10)\n",
    "# dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = \"Data/\"#\"data/geolife/Data/\"\n",
    "sample_s = 5\n",
    "sample_q = 3\n",
    "length = 100\n",
    "y_timestep = 10\n",
    "\n",
    "user_list = os.listdir(data_dir)\n",
    "random.shuffle(user_list)\n",
    "train_size = 0.1\n",
    "train_list = user_list[:(int)(len(user_list)*train_size)]\n",
    "test_list  = user_list[(int)(len(user_list)*train_size):]\n",
    "print(f\"train_list: {len(train_list)}\")\n",
    "\n",
    "training_data = GeoLifeDataSet(data_dir, train_list, sample_s, sample_q, length, y_timestep)\n",
    "test_data = GeoLifeDataSet(data_dir, train_list, sample_s, sample_q, length, y_timestep)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=False)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "train_x, train_y = next(iter(train_dataloader))\n",
    "print(f\"support_x: {train_x[0].shape}\")\n",
    "print(f\"support_y: {train_x[1].shape}\")\n",
    "print(f\"query_x: {train_x[2].shape}\")\n",
    "print(f\"query_y: {train_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [1, 2, 3, 4, 5]\n",
    "shape[:-2] + [-1] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # input is TASKS x SAMPLES x FEATURES x TIME x Latent vector\n",
    "        shape = torch._shape_as_tensor(inp)\n",
    "        # (3, 20, 6, 100, 1)\n",
    "        x = torch.reshape(inp, [-1, shape[-2], shape[-1]])\n",
    "        # (300, 100, 1)\n",
    "        x, f = self.gru(x)\n",
    "        # x:(300, 100, 32)\n",
    "        # f:(3, 100, 32)\n",
    "        \n",
    "        if self.final:\n",
    "            new_shape = shape[:-2].tolist() + [-1]\n",
    "            out = torch.reshape(f, new_shape)\n",
    "        else:\n",
    "            new_shape = shape[:-1].tolist() + [-1]\n",
    "            # (3, 20, 6, 100, -1)\n",
    "            out = torch.reshape(x, new_shape)\n",
    "            # (3, 20, 6, 100, 32)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/000/csv/000.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/001/csv/001.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/000/csv/000.csv')\n",
    "df.head(1)\n",
    "df_temp = df[['latitude', 'longitude']].copy()\n",
    "\n",
    "model = KMeans(n_clusters=100, random_state=123)\n",
    "model.fit(df_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['label'] = model.labels_\n",
    "df_temp['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
