{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 114, 39.98715717254236, 117.4918228913047, 1475)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gps_grid_map_creator import GPSGridMapCreator\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "grid_size_meter = 500  # Size of each grid in meters\n",
    "\n",
    "mapCreator = GPSGridMapCreator(grid_size_meter)\n",
    "mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "print(mapCreator.find_grid_number(39.99, 117.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 0\n",
      "54709.416666666664\n",
      "15631.25\n",
      "7815.666666666667\n",
      "0   2008-09-14 13:03:08\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "656512   2009-07-06 08:22:15\n",
      "Name: datetime, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gps_grid_map_creator import GPSGridMapCreator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "user_id_list = []\n",
    "grid_len_list = []\n",
    "gps_len_list = []\n",
    "\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "grid_csv = '_grid.csv'\n",
    "# grid_number = \"grid_number_\" + str(grid_size_meter)\n",
    "grid_list = [50, 100, 500, 1000, 1500, 2000]\n",
    "\n",
    "user_df = pd.DataFrame()\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"user_id: {id}\")\n",
    "    id = 68\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    # csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "    user_df = pd.read_csv(csv_file)\n",
    "    user_df = user_df.drop_duplicates(subset=['days'])\n",
    "    user_df = locationPreprocessor.convert_coord_for_blender_for_user(user_df)\n",
    "   \n",
    "    user_df['datetime'] = pd.to_datetime(user_df['date'] + \" \" + user_df['time'])\n",
    "    user_df['year'] = user_df['datetime'].dt.year\n",
    "    user_df['month'] = user_df['datetime'].dt.month\n",
    "    user_df['week'] = user_df['datetime'].dt.weekday\n",
    "    # user_df['weekend'] = np.where(user_df['week'] < 5, 0, 1)\n",
    "    user_df['hour'] = user_df['datetime'].dt.hour\n",
    "    user_df['day'] = user_df['datetime'].dt.day\n",
    "    \n",
    "    user_df = user_df.drop(columns=['altitude', 'time', 'what'])\n",
    "    # user_df = pd.get_dummies(user_df, columns=['month', 'week', 'hour'], drop_first=True)\n",
    "\n",
    "    for grid_len in grid_list:\n",
    "        mapCreator = GPSGridMapCreator(grid_len)\n",
    "        mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "        grid_row = 'grid_row_' + str(grid_len) + 'm' # row\n",
    "        grid_col = 'grid_col_' + str(grid_len) + 'm' # column\n",
    "        grid_lat = 'grid_lat_' + str(grid_len) + 'm' # lat\n",
    "        grid_lon = 'grid_lon_' + str(grid_len) + 'm' # lon\n",
    "        grid_num = 'grid_num_' + str(grid_len) + 'm' # num\n",
    "        \n",
    "        # user_df[grid_row], user_df[grid_col], user_df[grid_lat], user_df[grid_lon], user_df[grid_num] = mapCreator.find_grid_number(user_df['latitude'], user_df['longitude'])\n",
    "        user_df[grid_row], user_df[grid_col],_,_,_ = mapCreator.find_grid_number(user_df['latitude'], user_df['longitude'])\n",
    "     \n",
    "        # if grid_len == 1000:\n",
    "        #     user_df = pd.get_dummies(user_df, columns=[grid_row, grid_col], drop_first = True)\n",
    "        # print(user_df[grid_number].nunique())\n",
    "    train_len = round(user_df.shape[0] * 0.7)\n",
    "    valid_len = round(user_df.shape[0] * 0.2)\n",
    "    \n",
    "    train_set = user_df.iloc[:train_len, :]\n",
    "    valid_set = user_df.iloc[train_len:train_len + valid_len, :]\n",
    "    test_set = user_df.iloc[train_len + valid_len:, :]\n",
    "    \n",
    "    print(train_set.shape[0]/12)\n",
    "    print(valid_set.shape[0]/12)\n",
    "    print(test_set.shape[0]/12)\n",
    "    print(train_set['datetime'].head(1))\n",
    "    print(train_set['datetime'].tail(1))\n",
    "    # print((train_set['min']).unique())\n",
    "    break\n",
    "    train_file = './Data/' + user_id + '/csv/' + user_id + '_train_set.csv'\n",
    "    valid_file = './Data/' + user_id + '/csv/' + user_id + '_valid_set.csv'\n",
    "    test_file = './Data/' + user_id + '/csv/' + user_id + '_test_set.csv'\n",
    "    \n",
    "    train_set.to_csv(train_file, index=False)\n",
    "    valid_set.to_csv(valid_file, index=False)\n",
    "    test_set.to_csv(test_file, index=False)\n",
    "    break\n",
    "    # print(user_df.head())\n",
    "    # break\n",
    "    # user_id_list += [user_id]\n",
    "    # grid_len_list += [user_df[grid_number].nunique()]\n",
    "    # gps_len_list += [user_df.shape[0]]\n",
    "    # user_df.to_csv(grid_file, index=False)\n",
    "\n",
    "\n",
    "# user_grid_df = pd.DataFrame({'user_id':user_id_list,\n",
    "#                              grid_number:grid_len_list,\n",
    "#                              'gps_len':gps_len_list})\n",
    "# user_grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_395/1645927842.py:16: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>what</th>\n",
       "      <th>altitude</th>\n",
       "      <th>days</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-09-14 13:03:10</td>\n",
       "      <td>39.972909</td>\n",
       "      <td>116.418298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.543872</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-09-14 13:03:20</td>\n",
       "      <td>39.972922</td>\n",
       "      <td>116.418236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.543987</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-14 13:03:30</td>\n",
       "      <td>39.972791</td>\n",
       "      <td>116.418186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.544103</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-09-14 13:03:40</td>\n",
       "      <td>39.972548</td>\n",
       "      <td>116.418203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.544219</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-09-14 13:03:50</td>\n",
       "      <td>39.972287</td>\n",
       "      <td>116.418196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39705.544334</td>\n",
       "      <td>0 days 00:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime   latitude   longitude  what  altitude          days  \\\n",
       "0 2008-09-14 13:03:10  39.972909  116.418298   0.0       0.0  39705.543872   \n",
       "1 2008-09-14 13:03:20  39.972922  116.418236   0.0       0.0  39705.543987   \n",
       "2 2008-09-14 13:03:30  39.972791  116.418186   0.0       0.0  39705.544103   \n",
       "3 2008-09-14 13:03:40  39.972548  116.418203   0.0       0.0  39705.544219   \n",
       "4 2008-09-14 13:03:50  39.972287  116.418196   0.0       0.0  39705.544334   \n",
       "\n",
       "        time_diff  segment  \n",
       "0             NaT        0  \n",
       "1 0 days 00:00:10        0  \n",
       "2 0 days 00:00:10        0  \n",
       "3 0 days 00:00:10        0  \n",
       "4 0 days 00:00:10        0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "id = 68\n",
    "\n",
    "gap = 10\n",
    "round_min = str(gap) + 'min'\n",
    "round_sec = str(gap) + 's'\n",
    "round_time = round_sec\n",
    "\n",
    "user_id = locationPreprocessor.getUserId(id)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "df['datetime'] = pd.to_datetime(df['date'] + \" \" + df['time'])\n",
    "df['datetime'] = df['datetime'].dt.round(round_time)\n",
    "\n",
    "df = df.set_index('datetime').reset_index()\n",
    "user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
    "\n",
    "# 시간 간격 계산\n",
    "user_df['time_diff'] = user_df['datetime'].diff()\n",
    "\n",
    "# 1분 이상인 경우 세그먼트로 분류\n",
    "threshold = pd.Timedelta(minutes=1)\n",
    "user_df['segment'] = (user_df['time_diff'] > threshold).cumsum()\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>time_gap</th>\n",
       "      <th>over_10min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-09-14 13:03:10</td>\n",
       "      <td>2008-09-14 13:13:10</td>\n",
       "      <td>0 days 00:10:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-09-15 02:37:30</td>\n",
       "      <td>2008-09-15 03:18:10</td>\n",
       "      <td>0 days 00:40:40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-09-15 03:48:30</td>\n",
       "      <td>2008-09-15 04:03:00</td>\n",
       "      <td>0 days 00:14:30</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2008-09-15 04:24:30</td>\n",
       "      <td>2008-09-15 04:38:50</td>\n",
       "      <td>0 days 00:14:20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2008-09-15 05:33:30</td>\n",
       "      <td>2008-09-15 05:45:30</td>\n",
       "      <td>0 days 00:12:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>3843</td>\n",
       "      <td>2009-09-13 06:50:50</td>\n",
       "      <td>2009-09-13 07:04:00</td>\n",
       "      <td>0 days 00:13:10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>3844</td>\n",
       "      <td>2009-09-13 08:09:50</td>\n",
       "      <td>2009-09-13 08:24:30</td>\n",
       "      <td>0 days 00:14:40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>3845</td>\n",
       "      <td>2009-09-13 08:26:30</td>\n",
       "      <td>2009-09-13 09:03:40</td>\n",
       "      <td>0 days 00:37:10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3847</th>\n",
       "      <td>3847</td>\n",
       "      <td>2009-09-13 11:52:30</td>\n",
       "      <td>2009-09-13 12:19:40</td>\n",
       "      <td>0 days 00:27:10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>3850</td>\n",
       "      <td>2009-09-13 12:41:00</td>\n",
       "      <td>2009-09-13 12:51:20</td>\n",
       "      <td>0 days 00:10:20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1197 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      segment                 min                 max        time_gap  \\\n",
       "0           0 2008-09-14 13:03:10 2008-09-14 13:13:10 0 days 00:10:00   \n",
       "6           6 2008-09-15 02:37:30 2008-09-15 03:18:10 0 days 00:40:40   \n",
       "8           8 2008-09-15 03:48:30 2008-09-15 04:03:00 0 days 00:14:30   \n",
       "11         11 2008-09-15 04:24:30 2008-09-15 04:38:50 0 days 00:14:20   \n",
       "12         12 2008-09-15 05:33:30 2008-09-15 05:45:30 0 days 00:12:00   \n",
       "...       ...                 ...                 ...             ...   \n",
       "3843     3843 2009-09-13 06:50:50 2009-09-13 07:04:00 0 days 00:13:10   \n",
       "3844     3844 2009-09-13 08:09:50 2009-09-13 08:24:30 0 days 00:14:40   \n",
       "3845     3845 2009-09-13 08:26:30 2009-09-13 09:03:40 0 days 00:37:10   \n",
       "3847     3847 2009-09-13 11:52:30 2009-09-13 12:19:40 0 days 00:27:10   \n",
       "3850     3850 2009-09-13 12:41:00 2009-09-13 12:51:20 0 days 00:10:20   \n",
       "\n",
       "      over_10min  \n",
       "0           True  \n",
       "6           True  \n",
       "8           True  \n",
       "11          True  \n",
       "12          True  \n",
       "...          ...  \n",
       "3843        True  \n",
       "3844        True  \n",
       "3845        True  \n",
       "3847        True  \n",
       "3850        True  \n",
       "\n",
       "[1197 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 세그먼트별 시작 시간과 끝 시간 추출\n",
    "segment_info = user_df.groupby('segment')['datetime'].agg(['min', 'max'])\n",
    "segment_info = segment_info.reset_index()\n",
    "segment_info['time_gap'] = segment_info['max'] - segment_info['min']\n",
    "segment_info['over_10min'] = segment_info['time_gap'] >= pd.Timedelta(minutes=10)\n",
    "segment_info = segment_info.loc[segment_info['over_10min'] == True, :]\n",
    "segment_info\n",
    "# 8분의 data를 input 으로 넣고, 2분의 data를 output 으로 내는 ?\n",
    "# or 5분의 data를 input 으로 넣고, 5분의 data를 output으로 내는?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 0 to 29\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   days       30 non-null     float64\n",
      " 1   latitude   30 non-null     float64\n",
      " 2   longitude  30 non-null     float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 960.0 bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30 entries, 31 to 60\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   latitude   30 non-null     float64\n",
      " 1   longitude  30 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 720.0 bytes\n"
     ]
    }
   ],
   "source": [
    "data = user_df.loc[user_df['segment'] == 0, :'days']\n",
    "time_delta = data['datetime'][0] + pd.Timedelta(minutes=5)\n",
    "input_data = data.loc[data['datetime'] < time_delta, :]\n",
    "output_data = data.loc[data['datetime'] > time_delta, :]\n",
    "\n",
    "input_data = input_data[['days', 'latitude', 'longitude']]\n",
    "output_data = output_data[['latitude', 'longitude']]\n",
    "\n",
    "input_data.info()\n",
    "output_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size: 162\n",
      "output_size: 12\n",
      "target latitude, longitude: tensor([[ 39.9688, 116.4196],\n",
      "        [ 39.9687, 116.4196],\n",
      "        [ 39.9688, 116.4196],\n",
      "        [ 39.9690, 116.4198],\n",
      "        [ 39.9689, 116.4198],\n",
      "        [ 39.9688, 116.4199]])\n",
      "Predicted latitude, longitude: tensor([[ 39.9692, 116.4209],\n",
      "        [ 39.9686, 116.4202],\n",
      "        [ 39.9681, 116.4204],\n",
      "        [ 39.9695, 116.4201],\n",
      "        [ 39.9685, 116.4200],\n",
      "        [ 39.9703, 116.4200]])\n",
      "loss: 4.957073542755097e-07\n"
     ]
    }
   ],
   "source": [
    "data = user_df.loc[user_df['segment'] == 0, :'days']\n",
    "time_delta = data['datetime'][0] + pd.Timedelta(minutes=9)\n",
    "input_data = data.loc[data['datetime'] < time_delta, :]\n",
    "output_data = data.loc[data['datetime'] > time_delta, :]\n",
    "\n",
    "input_data = input_data[['days', 'latitude', 'longitude']].astype(float)\n",
    "output_data = output_data[['latitude', 'longitude']].astype(float)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "input_data = torch.tensor(input_data.values, dtype=torch.float32)\n",
    "target_data = torch.tensor(output_data.values, dtype=torch.float32)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_shape = input_shape[0] * input_shape[1]\n",
    "        \n",
    "        self.final_shape = output_shape\n",
    "        self.output_shape = output_shape[0] * output_shape[1]\n",
    "        print(f\"input_size: {self.input_shape}\")\n",
    "        print(f\"output_size: {self.output_shape}\")\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_shape, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, self.output_shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_shape_new = [-1]\n",
    "        x = torch.reshape(x, in_shape_new)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # out_shape = torch._shape_as_tensor(x)\n",
    "        # out_shape_new = out_shape[:-1].tolist() + [-1] + [self.output_shape[1]]\n",
    "        out = torch.reshape(x, self.final_shape)\n",
    "        return out\n",
    "\n",
    "model = MLP([input_data.shape[0], input_data.shape[1]], [target_data.shape[0], target_data.shape[1]])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input_data)\n",
    "    loss = criterion(output, target_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "# 예측\n",
    "with torch.no_grad():\n",
    "    predicted = model(input_data)\n",
    "    loss = mse(y_true=target_data, y_pred=predicted)\n",
    "    print(\"target latitude, longitude:\", target_data)\n",
    "    print(\"Predicted latitude, longitude:\", predicted)\n",
    "    print(f'loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "segment  what\n",
       "0        0.0      True\n",
       "182      0.0     False\n",
       "193      0.0     False\n",
       "200      0.0     False\n",
       "207      0.0     False\n",
       "                 ...  \n",
       "980204   0.0     False\n",
       "980214   0.0      True\n",
       "980218   0.0     False\n",
       "980228   0.0      True\n",
       "980229   0.0      True\n",
       "Name: what, Length: 4041, dtype: bool"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment = user_df['segment'].unique()\n",
    "user_df.groupby('segment')['what'].value_counts() > 20\n",
    "\n",
    "# user_df.loc[user_df['segment'] == segment[3], :]\n",
    "\n",
    "# 39.968885\t116.419843\n",
    "# 39.969592\t116.418630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = user_df.copy()\n",
    "df = df.fillna(np.nan)\n",
    "if str(df.iloc[11, -2]) == 'nan':\n",
    "    print('true')\n",
    "else:\n",
    "    print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 0\n",
      "(173870, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 1\n",
      "(108607, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 3\n",
      "(485226, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 4\n",
      "(439397, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 5\n",
      "(109046, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 6\n",
      "(31830, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 7\n",
      "(87217, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 8\n",
      "(77910, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 9\n",
      "(84616, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 11\n",
      "(90803, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 13\n",
      "(291182, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 14\n",
      "(388213, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 15\n",
      "(87736, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 16\n",
      "(89272, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 18\n",
      "(47279, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 19\n",
      "(47824, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 21\n",
      "(2385, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 24\n",
      "(263482, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 26\n",
      "(148411, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 27\n",
      "(15508, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 29\n",
      "(83844, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 30\n",
      "(615948, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 31\n",
      "(20412, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 32\n",
      "(26468, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 33\n",
      "(69974, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 34\n",
      "(166670, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 35\n",
      "(312042, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 36\n",
      "(251973, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 37\n",
      "(191324, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 38\n",
      "(250393, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 39\n",
      "(267737, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 40\n",
      "(56013, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 43\n",
      "(96246, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 44\n",
      "(76846, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 45\n",
      "(9743, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 46\n",
      "(21818, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 47\n",
      "(790, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 48\n",
      "(9076, 7)\n",
      "user_id: 49\n",
      "(2614, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 50\n",
      "(336859, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 51\n",
      "(17019, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 54\n",
      "(4780, 7)\n",
      "user_id: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37786, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 56\n",
      "(4004, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 57\n",
      "(2794, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 58\n",
      "(24769, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 59\n",
      "(23606, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 61\n",
      "(2800, 7)\n",
      "user_id: 63\n",
      "(12490, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 64\n",
      "(58754, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 65\n",
      "(426101, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 66\n",
      "(61020, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 67\n",
      "(394329, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 68\n",
      "(937876, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 69\n",
      "(16469, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 70\n",
      "(35311, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 73\n",
      "(43135, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 74\n",
      "(175698, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 75\n",
      "(37549, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 76\n",
      "(961, 7)\n",
      "user_id: 77\n",
      "(3144, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 78\n",
      "(75509, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 79\n",
      "(11243, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 80\n",
      "(711, 7)\n",
      "user_id: 81\n",
      "(44252, 7)\n",
      "user_id: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601871, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 86\n",
      "(561, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 88\n",
      "(27030, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 93\n",
      "(8898, 7)\n",
      "user_id: 94\n",
      "(2794, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 95\n",
      "(45559, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 96\n",
      "(231088, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 97\n",
      "(1554, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 98\n",
      "(813, 7)\n",
      "user_id: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6257, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 101\n",
      "(13738, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 102\n",
      "(6678, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 103\n",
      "(36576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 104\n",
      "(38572, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 105\n",
      "(1977, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 106\n",
      "(1985, 7)\n",
      "user_id: 109\n",
      "(595, 7)\n",
      "user_id: 110\n",
      "(5520, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 112\n",
      "(90565, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 113\n",
      "(24531, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 114\n",
      "(12332, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 116\n",
      "(2514, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 119\n",
      "(103734, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 121\n",
      "(5367, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 122\n",
      "(72115, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 125\n",
      "(96522, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 129\n",
      "(16338, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 130\n",
      "(42640, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 131\n",
      "(57587, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 133\n",
      "(7256, 7)\n",
      "user_id: 134\n",
      "(4158, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 135\n",
      "(84424, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 136\n",
      "(1306, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 137\n",
      "(14245, 7)\n",
      "user_id: 138\n",
      "(2351, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 141\n",
      "(314134, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 143\n",
      "(3021, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 145\n",
      "(9907, 7)\n",
      "user_id: 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33891, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 148\n",
      "(41830, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 149\n",
      "(8448, 7)\n",
      "user_id: 150\n",
      "(2794, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 151\n",
      "(1322, 7)\n",
      "user_id: 152\n",
      "(9784, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 154\n",
      "(2928, 7)\n",
      "user_id: 155\n",
      "(41591, 7)\n",
      "user_id: 156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16277, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 157\n",
      "(2500, 7)\n",
      "user_id: 158\n",
      "(6010, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 159\n",
      "(38744, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 161\n",
      "(799, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 165\n",
      "(130890, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 166\n",
      "(1360, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 169\n",
      "(48321, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 170\n",
      "(4377, 7)\n",
      "user_id: 173\n",
      "(970, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 174\n",
      "(7305, 7)\n",
      "user_id: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2955, 7)\n",
      "user_id: 179\n",
      "(169396, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 180\n",
      "(47166, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
      "/tmp/ipykernel_688/246536034.py:50: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 181\n",
      "(687, 7)\n"
     ]
    }
   ],
   "source": [
    "# csv 파일 5분 단위로 전처리하기 (rounded)\n",
    "# round_min 을 조절하여 round_min 간격으로 data를 전처리\n",
    "\n",
    "from convert_minmax_location import LocationPreprocessor\n",
    "from gps_grid_map_creator import GPSGridMapCreator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "\n",
    "days_min = 0.000696\n",
    "gap = 10\n",
    "round_min = str(gap) + 'min'\n",
    "\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "\n",
    "# origin_grid_10min = just add grid in original csv file\n",
    "# grid_10min        = from begin to end full data with fillna(ffill)\n",
    "round_csv = '_origin_round_' + round_min + '.csv'\n",
    "grid_csv = '_origin_grid_' + round_min + '.csv'\n",
    "grid_list = [50, 100, 500, 1000, 1500, 2000, 3000]\n",
    "\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"user_id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    rounded_file = './Data/' + user_id + '/csv/' + user_id + round_csv\n",
    "    grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(df.shape)\n",
    "    df['datetime'] = pd.to_datetime(df['date'] + \" \" + df['time'])\n",
    "    df['datetime'] = df['datetime'].dt.round(round_min)\n",
    "\n",
    "    df = df.set_index('datetime').reset_index()\n",
    "    user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
    "    user_df = locationPreprocessor.convert_coord_for_blender_for_user(user_df)\n",
    "\n",
    "    user_df['datetime'] = pd.to_datetime(user_df['datetime'])\n",
    "    \n",
    "    # begin = user_df['datetime'][0]\n",
    "    # end = user_df['datetime'][user_df.shape[0]-1]\n",
    "\n",
    "    # print(f'begin: {begin}')\n",
    "    # print(f'end: {end}')\n",
    "\n",
    "    # date_df = pd.DataFrame({'datetime':pd.date_range(begin, end, freq=round_min)})\n",
    "    # user_df = pd.merge(date_df, user_df, how='outer', on='datetime')\n",
    "    \n",
    "    # # add days \n",
    "    # start_days = user_df['days'][0]\n",
    "    # end_days = start_days + (date_df.shape[0] * (days_min * gap))\n",
    "    # days_list = np.arange(start_days, end_days, (days_min * gap))\n",
    "\n",
    "    # user_df['days'] = days_list[:user_df.shape[0]]\n",
    "    user_df['year'] = user_df['datetime'].dt.year\n",
    "    user_df['month'] = user_df['datetime'].dt.month\n",
    "    user_df['week'] = user_df['datetime'].dt.weekday\n",
    "    user_df['weekend'] = np.where(user_df['week'] < 5, 0, 1)\n",
    "    user_df['hour'] = user_df['datetime'].dt.hour\n",
    "    user_df['day'] = user_df['datetime'].dt.day\n",
    "    # user_df = user_df.fillna(method='ffill')\n",
    "\n",
    "    # save rounded file\n",
    "    user_df.to_csv(rounded_file, index=False)\n",
    "\n",
    "    # grid process\n",
    "    user_df = user_df.drop(columns=['datetime', 'altitude', 'what'])\n",
    "    for grid_len in grid_list:\n",
    "        mapCreator = GPSGridMapCreator(grid_len)\n",
    "        mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "        grid_row = 'grid_row_' + str(grid_len) + 'm' # row\n",
    "        grid_col = 'grid_col_' + str(grid_len) + 'm' # column\n",
    "        grid_lat = 'grid_lat_' + str(grid_len) + 'm' # lat\n",
    "        grid_lon = 'grid_lon_' + str(grid_len) + 'm' # lon\n",
    "        grid_num = 'grid_num_' + str(grid_len) + 'm' # num      \n",
    "        user_df[grid_row], user_df[grid_col],_,_,_ = mapCreator.find_grid_number(user_df['latitude'], user_df['longitude'])\n",
    "    # save grid file\n",
    "    user_df.to_csv(grid_file, index=False)\n",
    "    \n",
    "    # process one single user train, validation\n",
    "    # train_len = round(user_df.shape[0] * 0.7)\n",
    "    # valid_len = round(user_df.shape[0] * 0.3)\n",
    "    \n",
    "    # train_set = user_df.iloc[:train_len, :]\n",
    "    # valid_set = user_df.iloc[train_len:, :]\n",
    "    # # test_set = user_df.iloc[train_len + valid_len:, :]\n",
    "    \n",
    "    # train_file = './Data/' + user_id + '/csv/' + user_id + '_origin_train_set.csv'\n",
    "    # valid_file = './Data/' + user_id + '/csv/' + user_id + '_origin_valid_set.csv'\n",
    "    # # test_file = './Data/' + user_id + '/csv/' + user_id + '_test_set.csv'\n",
    "    \n",
    "    # train_set.to_csv(train_file, index=False)\n",
    "    # valid_set.to_csv(valid_file, index=False)\n",
    "    # # test_set.to_csv(test_file, index=False)\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_row_50m</th>\n",
       "      <th>grid_col_50m</th>\n",
       "      <th>grid_row_100m</th>\n",
       "      <th>grid_col_100m</th>\n",
       "      <th>grid_row_500m</th>\n",
       "      <th>grid_col_500m</th>\n",
       "      <th>grid_row_1000m</th>\n",
       "      <th>grid_col_1000m</th>\n",
       "      <th>grid_row_1500m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>139</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>134</td>\n",
       "      <td>12</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>147</td>\n",
       "      <td>17</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>163</td>\n",
       "      <td>32</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>171</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>170</td>\n",
       "      <td>32</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>160</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>149</td>\n",
       "      <td>8</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>145</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid_row_50m  grid_col_50m  grid_row_100m  grid_col_100m  grid_row_500m  \\\n",
       "0            17           139              8             69              1   \n",
       "1            25           134             12             67              2   \n",
       "2            25           134             12             67              2   \n",
       "3            34           147             17             73              3   \n",
       "4            65           163             32             81              6   \n",
       "5            64           171             32             85              6   \n",
       "6            64           170             32             85              6   \n",
       "7            60           160             30             80              6   \n",
       "8            17           149              8             74              1   \n",
       "9            20           145             10             72              2   \n",
       "\n",
       "   grid_col_500m  grid_row_1000m  grid_col_1000m  grid_row_1500m  \n",
       "0             13               0               6               0  \n",
       "1             13               1               6               0  \n",
       "2             13               1               6               0  \n",
       "3             14               1               7               1  \n",
       "4             16               3               8               2  \n",
       "5             17               3               8               2  \n",
       "6             17               3               8               2  \n",
       "7             16               3               8               2  \n",
       "8             14               0               7               0  \n",
       "9             14               1               7               0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = '035'\n",
    "grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "\n",
    "df = pd.read_csv(grid_file)\n",
    "df.iloc[:10, 11:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.csv 파일의 column 확인 코드\n",
    "import pandas as pd\n",
    "\n",
    "user_id = '067'\n",
    "\n",
    "gap = 10\n",
    "round_min = str(gap) + 'min'\n",
    "grid_csv = '_grid_' + round_min + '.csv'\n",
    "grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "\n",
    "train_file = './Data/' + user_id + '/csv/' + user_id + '_train_set.csv'\n",
    "valid_file = './Data/' + user_id + '/csv/' + user_id + '_valid_set.csv'\n",
    "test_file = './Data/' + user_id + '/csv/' + user_id + '_test_set.csv'\n",
    "\n",
    "df = pd.read_csv(grid_file)\n",
    "print(df.info())\n",
    "# print(df.tail())\n",
    "\n",
    "# columns = df.loc[:, :'grid_col_50m'].columns.to_list() #df.columns[:'grid_col_50m'].to_list() #+ df.columns[58:60].to_list()\n",
    "columns = df.columns[2:11].to_list() #+ df.columns[15:17].to_list()\n",
    "df_1 = df[columns].copy()\n",
    "df_1 = pd.get_dummies(df_1, columns=['hour'], drop_first=True)\n",
    "df_1 = pd.concat([df_1, df.iloc[:, 15:17]], axis=1)\n",
    "print(df_1.columns)\n",
    "print(df_1.tail())\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_valid = pd.read_csv(valid_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "print(f\"train: {df_train.shape[0]}\")\n",
    "print(f\"valid: {df_valid.shape[0]}\")\n",
    "print(f\"test: {df_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 0\n",
      "user_id: 1\n",
      "user_id: 3\n",
      "user_id: 4\n",
      "user_id: 5\n",
      "user_id: 6\n",
      "user_id: 7\n",
      "user_id: 8\n",
      "user_id: 9\n",
      "user_id: 11\n",
      "user_id: 13\n",
      "user_id: 14\n",
      "user_id: 15\n",
      "user_id: 16\n",
      "user_id: 18\n",
      "user_id: 19\n",
      "user_id: 21\n",
      "user_id: 24\n",
      "user_id: 26\n",
      "user_id: 27\n",
      "user_id: 29\n",
      "user_id: 30\n",
      "user_id: 31\n",
      "user_id: 32\n",
      "user_id: 33\n",
      "user_id: 34\n",
      "user_id: 35\n",
      "user_id: 36\n",
      "user_id: 37\n",
      "user_id: 38\n",
      "user_id: 39\n",
      "user_id: 40\n",
      "user_id: 43\n",
      "user_id: 44\n",
      "user_id: 45\n",
      "user_id: 46\n",
      "user_id: 47\n",
      "user_id: 48\n",
      "user_id: 49\n",
      "user_id: 50\n",
      "user_id: 51\n",
      "user_id: 54\n",
      "user_id: 55\n",
      "user_id: 56\n",
      "user_id: 57\n",
      "user_id: 58\n",
      "user_id: 59\n",
      "user_id: 61\n",
      "user_id: 63\n",
      "user_id: 64\n",
      "user_id: 65\n",
      "user_id: 66\n",
      "user_id: 67\n",
      "user_id: 68\n",
      "user_id: 69\n",
      "user_id: 70\n",
      "user_id: 73\n",
      "user_id: 74\n",
      "user_id: 75\n",
      "user_id: 76\n",
      "user_id: 77\n",
      "user_id: 78\n",
      "user_id: 79\n",
      "user_id: 80\n",
      "user_id: 81\n",
      "user_id: 85\n",
      "user_id: 86\n",
      "user_id: 88\n",
      "user_id: 93\n",
      "user_id: 94\n",
      "user_id: 95\n",
      "user_id: 96\n",
      "user_id: 97\n",
      "user_id: 98\n",
      "user_id: 100\n",
      "user_id: 101\n",
      "user_id: 102\n",
      "user_id: 103\n",
      "user_id: 104\n",
      "user_id: 105\n",
      "user_id: 106\n",
      "user_id: 109\n",
      "user_id: 110\n",
      "user_id: 112\n",
      "user_id: 113\n",
      "user_id: 114\n",
      "user_id: 116\n",
      "user_id: 119\n",
      "user_id: 121\n",
      "user_id: 122\n",
      "user_id: 125\n",
      "user_id: 129\n",
      "user_id: 130\n",
      "user_id: 131\n",
      "user_id: 133\n",
      "user_id: 134\n",
      "user_id: 135\n",
      "user_id: 136\n",
      "user_id: 137\n",
      "user_id: 138\n",
      "user_id: 141\n",
      "user_id: 143\n",
      "user_id: 145\n",
      "user_id: 147\n",
      "user_id: 148\n",
      "user_id: 149\n",
      "user_id: 150\n",
      "user_id: 151\n",
      "user_id: 152\n",
      "user_id: 154\n",
      "user_id: 155\n",
      "user_id: 156\n",
      "user_id: 157\n",
      "user_id: 158\n",
      "user_id: 159\n",
      "user_id: 161\n",
      "user_id: 165\n",
      "user_id: 166\n",
      "user_id: 169\n",
      "user_id: 170\n",
      "user_id: 173\n",
      "user_id: 174\n",
      "user_id: 177\n",
      "user_id: 179\n",
      "user_id: 180\n",
      "user_id: 181\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>original_len</th>\n",
       "      <th>rounded_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>2008-10-23 02:53:04</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>173870</td>\n",
       "      <td>2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>2008-10-23 05:53:05</td>\n",
       "      <td>2008-12-15 00:31:18</td>\n",
       "      <td>108607</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>2008-10-23 17:58:54</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>485226</td>\n",
       "      <td>5969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>2008-10-23 17:58:52</td>\n",
       "      <td>2009-07-29 06:16:11</td>\n",
       "      <td>439397</td>\n",
       "      <td>5671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>2008-10-24 04:12:30</td>\n",
       "      <td>2009-03-19 05:46:37</td>\n",
       "      <td>109046</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id          begin_date            end_date  original_len  rounded_len\n",
       "0     000 2008-10-23 02:53:04 2009-07-05 07:45:15        173870         2286\n",
       "1     001 2008-10-23 05:53:05 2008-12-15 00:31:18        108607          940\n",
       "2     003 2008-10-23 17:58:54 2009-07-05 07:45:15        485226         5969\n",
       "3     004 2008-10-23 17:58:52 2009-07-29 06:16:11        439397         5671\n",
       "4     005 2008-10-24 04:12:30 2009-03-19 05:46:37        109046         1249"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import numpy as np\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "user_id_list = []\n",
    "df_len_list = []\n",
    "ori_len_list = []\n",
    "begin_day_list = []\n",
    "end_day_list = []\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"user_id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_origin_round_10min.csv'\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    user_df = pd.read_csv(csv_convert_file)\n",
    "    orig_df = pd.read_csv(csv_file)\n",
    "    orig_df['datetime'] = pd.to_datetime(orig_df['date'] + \" \" + orig_df['time'])\n",
    "\n",
    "    user_id_list += [user_id]\n",
    "    df_len_list += [user_df.shape[0]]\n",
    "    ori_len_list += [orig_df.shape[0]]\n",
    "\n",
    "    begin_day_list += [orig_df.iloc[0, -1]]\n",
    "    end_day_list += [orig_df.iloc[-1, -1]]\n",
    "\n",
    "user_df = pd.DataFrame({'user_id':user_id_list,\n",
    "                        'begin_date':begin_day_list,\n",
    "                        'end_date':end_day_list,\n",
    "                        'original_len':ori_len_list,\n",
    "                        'rounded_len':df_len_list})\n",
    "user_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 100 일 이상 좌표 수집한 user 45명\n",
    "# user_df.to_csv('origin_round_10min_user_list.csv', index=False)\n",
    "\n",
    "df_1 = pd.read_csv('origin_round_10min_user_list.csv')\n",
    "df = pd.read_csv('round_10min_user_list.csv')\n",
    "\n",
    "df = df.merge(df_1, how='inner', on = 'user_id')\n",
    "df = df.loc[df['rounded_len_y'] > 2000, :]\n",
    "df['extra_ratio'] = round(df['rounded_len_x'] / df['rounded_len_y'], 1)\n",
    "\n",
    "df = df.sort_values(['extra_ratio'], ascending=True)\n",
    "\n",
    "df = df.rename(columns = {'rounded_len_y':'rounded_10min_len',\n",
    "                          'rounded_len_x':'date_rounded',\n",
    "                          'original_len_x':'original_len'})\n",
    "df = df[['user_id','begin_date','end_date','date_rounded','original_len', 'rounded_10min_len', 'extra_ratio']]\n",
    "df.head()\n",
    "df.to_csv('extra_ratio.csv', index=False)\n",
    "\n",
    "# df = df.loc[df['rounded_len'] >= 14400, :]\n",
    "# df['user_id'].to_list()\n",
    "# df.head(20)\n",
    "# df.sort_values('rounded_len', ascending=False)\n",
    "# ['068', '030', '085', '003', '004']\",\"['065', '067']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>date_rounded</th>\n",
       "      <th>original_len</th>\n",
       "      <th>rounded_10min_len</th>\n",
       "      <th>extra_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>2009-02-09 10:48:38</td>\n",
       "      <td>2009-04-27 06:14:45</td>\n",
       "      <td>11061</td>\n",
       "      <td>312042</td>\n",
       "      <td>3162</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-10-23 17:58:54</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>36660</td>\n",
       "      <td>485226</td>\n",
       "      <td>5969</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>2009-01-13 02:32:22</td>\n",
       "      <td>2009-07-29 01:40:07</td>\n",
       "      <td>28364</td>\n",
       "      <td>615948</td>\n",
       "      <td>4320</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-10-23 17:58:52</td>\n",
       "      <td>2009-07-29 06:16:11</td>\n",
       "      <td>40107</td>\n",
       "      <td>439397</td>\n",
       "      <td>5671</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>2009-02-11 09:59:38</td>\n",
       "      <td>2009-07-15 00:56:11</td>\n",
       "      <td>22123</td>\n",
       "      <td>267737</td>\n",
       "      <td>3098</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>2008-12-16 01:00:33</td>\n",
       "      <td>2009-05-26 10:51:12</td>\n",
       "      <td>23244</td>\n",
       "      <td>263482</td>\n",
       "      <td>2648</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>2008-09-14 13:03:08</td>\n",
       "      <td>2009-09-13 12:51:15</td>\n",
       "      <td>52416</td>\n",
       "      <td>937876</td>\n",
       "      <td>5073</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>2009-02-06 12:11:02</td>\n",
       "      <td>2009-07-23 18:13:12</td>\n",
       "      <td>24085</td>\n",
       "      <td>250393</td>\n",
       "      <td>2069</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>2008-10-20 05:45:00</td>\n",
       "      <td>2009-04-17 01:50:18</td>\n",
       "      <td>25754</td>\n",
       "      <td>388213</td>\n",
       "      <td>2136</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 02:53:04</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>36751</td>\n",
       "      <td>173870</td>\n",
       "      <td>2286</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id           begin_date             end_date  date_rounded  \\\n",
       "0       35  2009-02-09 10:48:38  2009-04-27 06:14:45         11061   \n",
       "1        3  2008-10-23 17:58:54  2009-07-05 07:45:15         36660   \n",
       "2       30  2009-01-13 02:32:22  2009-07-29 01:40:07         28364   \n",
       "3        4  2008-10-23 17:58:52  2009-07-29 06:16:11         40107   \n",
       "4       39  2009-02-11 09:59:38  2009-07-15 00:56:11         22123   \n",
       "5       24  2008-12-16 01:00:33  2009-05-26 10:51:12         23244   \n",
       "6       68  2008-09-14 13:03:08  2009-09-13 12:51:15         52416   \n",
       "7       38  2009-02-06 12:11:02  2009-07-23 18:13:12         24085   \n",
       "8       14  2008-10-20 05:45:00  2009-04-17 01:50:18         25754   \n",
       "9        0  2008-10-23 02:53:04  2009-07-05 07:45:15         36751   \n",
       "\n",
       "   original_len  rounded_10min_len  extra_ratio  \n",
       "0        312042               3162          3.5  \n",
       "1        485226               5969          6.1  \n",
       "2        615948               4320          6.6  \n",
       "3        439397               5671          7.1  \n",
       "4        267737               3098          7.1  \n",
       "5        263482               2648          8.8  \n",
       "6        937876               5073         10.3  \n",
       "7        250393               2069         11.6  \n",
       "8        388213               2136         12.1  \n",
       "9        173870               2286         16.1  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "user = pd.read_csv('extra_ratio.csv')\n",
    "user.head(10)\n",
    "# user = user.sort_values('original_len', ascending=False)\n",
    "# user = user[['user_id', 'original_len', 'extra_rounded', 'rounded_10min', 'extra_ratio']]\n",
    "# user.rename(columns={'extra_rounded':'rounded_10min',\n",
    "#                      'rounded_10min':'rounded_len'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_id = '085'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user_df = pd.read_csv(csv_convert_file)\n",
    "user_df.head(1)\n",
    "\n",
    "# user_df = user_df[['days','month','week','weekend','hour','day','x','y']]\n",
    "# user_df = pd.get_dummies(user_df, columns=['week','month'], drop_first=True)\n",
    "# user_xy = user_df.loc[:, ['x', 'y']]\n",
    "# user_df = user_df.drop(columns=['x', 'y'])\n",
    "# pd.concat([user_df, user_xy], axis=1)\n",
    "\n",
    "df_1 = user_df[['days','month','week','weekend','hour','day','x','y']]\n",
    "df_1 = pd.get_dummies(df_1, columns=['week','month'], drop_first=True)\n",
    "df_xy = df_1.loc[:, ['x', 'y']]\n",
    "df_1 = df_1.drop(columns=['x', 'y'])\n",
    "df_1 = pd.concat([df_1, df_xy], axis=1)\n",
    "df_1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame({\"user_id\":user_id_list,\n",
    "                        \"data_vol\":df_len_list})\n",
    "user_df = user_df.sort_values(['data_vol'], ascending=False)\n",
    "user_df.to_csv('user_data_volumn.csv', index=False)\n",
    "\n",
    "print(user_df.head(5))\n",
    "user_df.iloc[:5, 0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_s = 1\n",
    "sample_q = 1\n",
    "\n",
    "args_epoch = 1200\n",
    "args_patience = 300\n",
    "\n",
    "gap_min = 12 # 1 min\n",
    "gap = gap_min\n",
    "\n",
    "y_timestep = 100 # must be less than length\n",
    "length = 15000\n",
    "\n",
    "train_list      = ['068', '030', '085', '004']#, '085']\n",
    "validation_list = ['067']#, '085']\n",
    "test_list       = ['067']#, '085']\n",
    "\n",
    "conf_df = pd.DataFrame({'sample_s':[sample_s],\n",
    "                        'sample_q':[sample_q],\n",
    "                        'epoch':[args_epoch],\n",
    "                        'patience':[args_patience],\n",
    "                        'gap':[gap],\n",
    "                        'y_timestep':[y_timestep],\n",
    "                        'length':[length],\n",
    "                        'train_list':[train_list],\n",
    "                        'val_list':[validation_list],\n",
    "                        'test_list':[test_list]})\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.loc[user_df['user_id'] == '001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df_pre = user_location_df.copy()\n",
    "user_location_df_pre = user_location_df_pre.set_index('user_id', drop=True).copy()\n",
    "user_location_df_pre.head(2)\n",
    "\n",
    "X = ['min_lat', 'min_lon', 'max_lat', 'max_lon']\n",
    "q1 = user_location_df_pre[X].quantile(0.25)\n",
    "q3 = user_location_df_pre[X].quantile(0.75)\n",
    "iqr = (q3-q1) * 1.5\n",
    "\n",
    "cond1 = user_location_df_pre[X] >= (q1 - iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond1].dropna().copy()\n",
    "print(user_location_df_pre.shape)\n",
    "\n",
    "cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond2].dropna().copy()\n",
    "print(user_location_df_pre.shape)\n",
    "user_location_df_pre.min()\n",
    "user_location_df_pre.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "PI = 3.14159265358979323846\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2, unit):\n",
    "    deg2rad_multiplier = PI / 180\n",
    "    lat1 = lat1 * deg2rad_multiplier\n",
    "    lon1 = lon1 * deg2rad_multiplier\n",
    "    lat2 = lat2 * deg2rad_multiplier\n",
    "    lon2 = lon2 * deg2rad_multiplier\n",
    "\n",
    "    radius = 6378.137  # Earth mean radius defined by WGS84\n",
    "    dlon = lon2 - lon1\n",
    "    distance = math.acos(math.sin(lat1) * math.sin(lat2) + math.cos(lat1) * math.cos(lat2) * math.cos(dlon)) * radius\n",
    "    \n",
    "    # (kilometers, miles, nautical miles)\n",
    "    if unit == 'K':\n",
    "        return distance\n",
    "    elif unit == 'M':\n",
    "        return distance * 0.621371192\n",
    "    elif unit == 'N':\n",
    "        return distance * 0.539956803\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Example usage:\n",
    "result = distance(37.7749, -122.4194, 34.0522, -118.2437, 'K') * 1000\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 39.975300\n",
    "min_lon = 116.452488\n",
    "max_lat = 41.367085\n",
    "max_lon = 122.651456\n",
    "\n",
    "width = round(distance(39.975300, 122.651456, 41.367085, 122.651456, 'K'), 3)\n",
    "height = round(distance(41.367085, 116.452488, 41.367085, 122.651456, 'K'), 3)\n",
    "print(width)\n",
    "print(height)\n",
    "# up_width = 154.933\n",
    "# down_width = 154.933\n",
    "# left_height = 528.706\n",
    "# right_hegith = 517.778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class GPSGridMapCreator():\n",
    "    def __init__(self, grid_size_meter):\n",
    "        self.grid_size_meter = grid_size_meter\n",
    "        self.lat1 = 0\n",
    "        self.lon1 = 0\n",
    "        self.grid_numbers = 0\n",
    "        self.lat_degrees = 0\n",
    "        self.long_degrees = 0\n",
    "        self.num_lat = 0\n",
    "        self.num_lon = 0\n",
    "        \n",
    "    def km_to_degrees(self, latitude, kilometers):\n",
    "        # Earth's radius in kilometers\n",
    "        earth_radius_km = 6371.0\n",
    "\n",
    "        # Convert kilometers to radians\n",
    "        angle_rad = kilometers / earth_radius_km\n",
    "\n",
    "        # Convert radians to degrees\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "        # Correction factor for latitude\n",
    "        lat_correction = np.cos(np.radians(latitude))\n",
    "\n",
    "        # Convert degrees to adjusted degrees\n",
    "        adjusted_degrees = angle_deg / lat_correction\n",
    "\n",
    "        return adjusted_degrees\n",
    "\n",
    "    def meter_to_degrees(self, latitude, meters):\n",
    "        # Convert meters to kilometers\n",
    "        kilometers = meters / 1000\n",
    "\n",
    "        # Convert kilometers to degrees using the km_to_degrees function\n",
    "        degrees = self.km_to_degrees(latitude, kilometers)\n",
    "\n",
    "        return degrees\n",
    "\n",
    "    def create_grid_map(self, lat1, lon1, lat2, lon2):\n",
    "        self.lat1 = lat1\n",
    "        self.lon1 = lon1\n",
    "        # Convert grid size from meters to degrees\n",
    "        self.lat_degrees = self.meter_to_degrees((lat1 + lat2) / 2, self.grid_size_meter)\n",
    "        self.lon_degrees = self.meter_to_degrees((lon1 + lon2) / 2, self.grid_size_meter)\n",
    "\n",
    "        # print(f\"lat_degrees: {self.lat_degrees}, lon_degree: {self.lon_degrees}\")\n",
    "        # Calculate the number of grid points in latitude and longitude directions\n",
    "        self.num_lat = int(np.abs(lat2 - lat1) / np.abs(self.lat_degrees))\n",
    "        self.num_lon = int(np.abs(lon2 - lon1) / np.abs(self.lon_degrees))\n",
    "        # print(f\"lon2 - lon1: {np.abs(lon2 - lon1)}\")\n",
    "        # print(f\"num_lat: {self.num_lat}, num_lon: {self.num_lon}\")\n",
    "\n",
    "        # Generate latitude and longitude grid points\n",
    "        latitudes = np.linspace(lat1, lat2, self.num_lat)\n",
    "        longitudes = np.linspace(lon1, lon2, self.num_lon)\n",
    "\n",
    "        # print(f\"the num of latitudes: {len(latitudes)}\")\n",
    "        # print(f\"the num of longitude: {len(longitudes)}\")\n",
    "        # print(latitudes)\n",
    "        # print(longitudes)\n",
    "        # Create a 2D grid for numbering\n",
    "        self.grid_numbers = np.arange(0, (self.num_lat + 1) * (self.num_lon + 1)).reshape(self.num_lat + 1, self.num_lon + 1)\n",
    "        print(f\"gird_number: {self.grid_numbers.shape[0] * self.grid_numbers.shape[1]}\")\n",
    "\n",
    "    def find_grid_number(self, lat, lon):\n",
    "        grid_lat = int((lat - self.lat1) / np.abs(self.lat_degrees))\n",
    "        grid_lon = int((lon - self.lon1) / np.abs(self.lon_degrees))\n",
    "        gird_number = grid_lat * (self.num_lon + 1) + grid_lon + 1\n",
    "        return gird_number, grid_lat, grid_lon\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "grid_size_meter = 100  # Size of each grid in meters\n",
    "\n",
    "mapCreator = GPSGridMapCreator(grid_size_meter)\n",
    "mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "print(mapCreator.find_grid_number(39.99, 117.5))\n",
    "print(\"done\")\n",
    "# 3991600\n",
    "# 15966400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def km_to_degrees(latitude, kilometers):\n",
    "    # Earth's radius in kilometers\n",
    "    earth_radius_km = 6371.0\n",
    "\n",
    "    # Convert kilometers to radians\n",
    "    angle_rad = kilometers / earth_radius_km\n",
    "\n",
    "    # Convert radians to degrees\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    # Correction factor for latitude\n",
    "    lat_correction = np.cos(np.radians(latitude))\n",
    "\n",
    "    # Convert degrees to adjusted degrees\n",
    "    adjusted_degrees = angle_deg / lat_correction\n",
    "\n",
    "    return adjusted_degrees\n",
    "\n",
    "def meter_to_degrees(latitude, meters):\n",
    "    # Convert meters to kilometers\n",
    "    kilometers = meters / 1000\n",
    "\n",
    "    # Convert kilometers to degrees using the km_to_degrees function\n",
    "    degrees = km_to_degrees(latitude, kilometers)\n",
    "\n",
    "    return degrees\n",
    "\n",
    "def create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter):\n",
    "    # Convert grid size from meters to degrees\n",
    "    lat_degrees = meter_to_degrees((lat1 + lat2) / 2, grid_size_meter)\n",
    "    lon_degrees = meter_to_degrees((lon1 + lon2) / 2, grid_size_meter)\n",
    "\n",
    "    print(f\"lat_degrees: {lat_degrees}, lon_degree: {lon_degrees}\")\n",
    "    # Calculate the number of grid points in latitude and longitude directions\n",
    "    num_lat = int(np.abs(lat2 - lat1) / np.abs(lat_degrees))\n",
    "    num_lon = int(np.abs(lon2 - lon1) / np.abs(lon_degrees))\n",
    "    print(f\"lon2 - lon1: {np.abs(lon2 - lon1)}\")\n",
    "    print(f\"num_lat: {num_lat}, num_lon: {num_lon}\")\n",
    "\n",
    "    # Calculate the latitude and longitude increments\n",
    "    # lat_increment = (lat2 - lat1) / num_lat\n",
    "    # lon_increment = (lon2 - lon1) / num_lon\n",
    "\n",
    "    # Generate latitude and longitude grid points\n",
    "    latitudes = np.linspace(lat1, lat2, num_lat)\n",
    "    longitudes = np.linspace(lon1, lon2, num_lon)\n",
    "\n",
    "    print(f\"the num of latitudes: {len(latitudes)}\")\n",
    "    print(f\"the num of longitude: {len(longitudes)}\")\n",
    "    print(longitudes)\n",
    "    # Create a 2D grid for numbering\n",
    "    grid_numbers = np.arange(0, (num_lat + 1) * (num_lon + 1)).reshape(num_lat + 1, num_lon + 1)\n",
    "\n",
    "    # # Plot the grid lines\n",
    "    # for lat in latitudes:\n",
    "    #     ax.plot([lon1, lon2], [lat, lat], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "    # for lon in longitudes:\n",
    "    #     ax.plot([lon, lon], [lat1, lat2], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Plot the numbers on the grid\n",
    "    # for i in range(num_lat + 1):\n",
    "    #     for j in range(num_lon + 1):\n",
    "    #         ax.text(lon1 + j * lon_increment, lat1 + i * lat_increment, str(grid_numbers[i, j]),\n",
    "    #                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # ax.coastlines()\n",
    "    # plt.show()\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 37.0, -122.0  # Lower-left corner\n",
    "lat2, lon2 = 38.0, -121.0  # Upper-right corner\n",
    "grid_size_meter = 1000  # Size of each grid in meters\n",
    "\n",
    "create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def km_to_degrees(latitude, kilometers):\n",
    "    earth_radius_km = 6371.0\n",
    "    angle_rad = kilometers / earth_radius_km\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    lat_correction = np.cos(np.radians(latitude))\n",
    "    adjusted_degrees = angle_deg / lat_correction\n",
    "    return adjusted_degrees\n",
    "\n",
    "def meter_to_degrees(latitude, meters):\n",
    "    kilometers = meters / 1000\n",
    "    degrees = km_to_degrees(latitude, kilometers)\n",
    "    return degrees\n",
    "\n",
    "def find_grid_number(lat, lon, lat1, lon1, lat_degrees, lon_degrees):\n",
    "    grid_lat = int((lat - lat1) / lat_degrees)\n",
    "    grid_lon = int((lon - lon1) / lon_degrees)\n",
    "    return grid_lat, grid_lon\n",
    "\n",
    "def create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter):\n",
    "    lat_degrees = meter_to_degrees((lat1 + lat2) / 2, grid_size_meter)\n",
    "    lon_degrees = meter_to_degrees((lon1 + lon2) / 2, grid_size_meter)\n",
    "\n",
    "    num_lat = int(np.abs(lat2 - lat1) / lat_degrees)\n",
    "    num_lon = int(np.abs(lon2 - lon1) / lon_degrees)\n",
    "\n",
    "    lat_increment = (lat2 - lat1) / num_lat\n",
    "    lon_increment = (lon2 - lon1) / num_lon\n",
    "\n",
    "    latitudes = np.linspace(lat1, lat2, num_lat)\n",
    "    longitudes = np.linspace(lon1, lon2, num_lon)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.stock_img()\n",
    "\n",
    "    for lat in latitudes:\n",
    "        ax.plot([lon1, lon2], [lat, lat], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "    for lon in longitudes:\n",
    "        ax.plot([lon, lon], [lat1, lat2], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "    for i in range(num_lat + 1):\n",
    "        for j in range(num_lon + 1):\n",
    "            ax.text(lon1 + j * lon_increment, lat1 + i * lat_increment, str(i * (num_lon + 1) + j + 1),\n",
    "                    horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Example input coordinates\n",
    "    input_coordinates = [(37.5, -121.5), (37.3, -122.3), (37.7, -122.7)]\n",
    "    for lat, lon in input_coordinates:\n",
    "        grid_lat, grid_lon = find_grid_number(lat, lon, lat1, lon1, lat_degrees, lon_degrees)\n",
    "        ax.text(lon, lat, f\"{grid_lat * (num_lon + 1) + grid_lon + 1} ({grid_lat},{grid_lon})\",\n",
    "                horizontalalignment='center', verticalalignment='center', color='red', fontsize=8, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 37.0, -122.0  # Lower-left corner\n",
    "lat2, lon2 = 38.0, -121.0  # Upper-right corner\n",
    "grid_size_meter = 1000  # Size of each grid in meters\n",
    "\n",
    "create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user_list = user_location_df_pre.index\n",
    "valid_user_list = pd.DataFrame({'valid_user_list':user_location_df_pre.index})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "X = ['latitude', 'longitude', 'x', 'y']\n",
    "user_min_df = pd.DataFrame(columns=X)\n",
    "user_max_df = pd.DataFrame(columns=X)\n",
    "for user_id in valid_user_list['valid_user_list']:\n",
    "    # user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "    user0 = pd.read_csv(csv_file)\n",
    "    min_df = pd.DataFrame(data=user0[X].min()).transpose()\n",
    "    max_df = pd.DataFrame(data=user0[X].max()).transpose()\n",
    "    \n",
    "    user_min_df = pd.concat([user_min_df, min_df])\n",
    "    user_max_df = pd.concat([user_max_df, max_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_min_df[['x', 'y']].min())\n",
    "print(user_max_df[['x', 'y']].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = pd.DataFrame(user_min_df.min()).transpose()\n",
    "df_max = pd.DataFrame(user_min_df.max()).transpose()\n",
    "df_max_min = pd.DataFrame(user_min_df.max()-user_min_df.min()).transpose()\n",
    "df_diff = pd.concat([df_min, df_max, df_max_min])\n",
    "df_diff['label'] = ['min', 'max', 'max-min']\n",
    "\n",
    "round(df_diff.set_index('label'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "\n",
    "user_df = user[['latitude', 'longitude', 'x', 'y', 'days', 'time']].copy()\n",
    "\n",
    "idx_list = []\n",
    "for idx in range(user_df.shape[0]):\n",
    "    if idx % 60 == 0: # 5 mins\n",
    "        idx_list += [idx]\n",
    "len(idx_list)\n",
    "\n",
    "idx_list_partial = idx_list[-200:]\n",
    "user_df_1 = user_df.iloc[idx_list_partial, :].copy()\n",
    "\n",
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "# axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=20)\n",
    "# axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'], s=20)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'])\n",
    "\n",
    "axes.set_xlabel('time')\n",
    "# axes.set_ylabel('X')\n",
    "# axes.set_zlabel('Y')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')\n",
    "\n",
    "user_df_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df\n",
    "task_X = user_df.copy()\n",
    "task_y = task_X.iloc[-5:, -2:].copy()\n",
    "\n",
    "task_y.iloc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geopandas: https://datascientyst.com/plot-latitude-longitude-pandas-dataframe-python/\n",
    "# pip install geopandas\n",
    "# pip install Shapely\n",
    "\n",
    "# folium: https://aboutnlp.tistory.com/33\n",
    "\n",
    "import pandas as pd\n",
    "from convert_minmax_location import LocationPreprocessor\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folium\n",
    "from branca.element import Figure\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "\n",
    "fig = Figure(width=550, height=350)\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "    user = pd.read_csv(csv_file)\n",
    "    user_location_list = user[['latitude', 'longitude']].values.tolist()\n",
    "    center = user_location_list[0]\n",
    "    \n",
    "    map = folium.Map(location=center,\n",
    "                     zoom_start=10)\n",
    "    fig.add_child(map)\n",
    "    folium.PolyLine(locations = user_location_list,).add_to(map)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://anweh.tistory.com/17\n",
    "\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.head())\n",
    "user_coords = user[['latitude', 'longitude']].values.tolist()\n",
    "lat = user['latitude'].mean()\n",
    "lon = user['longitude'].mean()\n",
    "center = [lat, lon]\n",
    "\n",
    "map = folium.Map(location=center,\n",
    "                    zoom_start=9)\n",
    "k = 0\n",
    "for i in range(len(user_coords)):\n",
    "    if (i % 60) == 0:\n",
    "        _color = '#' + str(k)\n",
    "        k += 1\n",
    "        folium.Circle(\n",
    "            location = user_coords[i],\n",
    "            radius = 20,\n",
    "            # fill_color = 'Reds'\n",
    "            # color = 'Reds', #'#000000',\n",
    "            tooltip = user.iloc[i, -2:],\n",
    "            fill = 'crimson',\n",
    "        ).add_to(map)\n",
    "map.save('map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "user_id = locationPreprocessor.getUserId(29)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.shape[0])\n",
    "print(user.head(10))\n",
    "# user = user.drop_duplicates(subset=['date', 'time'])\n",
    "user = user.drop_duplicates(subset=['days'])\n",
    "print(user.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = user[['latitude', 'longitude', 'x', 'y', 'days', 'time']].copy()\n",
    "\n",
    "idx_list = []\n",
    "for idx in range(user_df.shape[0]):\n",
    "    if idx % 120 == 0:\n",
    "        idx_list += [idx]\n",
    "len(idx_list)\n",
    "\n",
    "idx_list_partial = idx_list[-50:]\n",
    "user_df_1 = user_df.iloc[idx_list_partial, :].copy()\n",
    "user_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=20)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.set_xlabel('time')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "# axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=10)\n",
    "# axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'], s=10)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'])\n",
    "axes.set_xlabel('time')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')\n",
    "# axes.set_xticklabels(one_hour['datetime'], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.head())\n",
    "user_coords = user[['latitude', 'longitude']].values.tolist()\n",
    "\n",
    "begin_hour = user_sub.iloc[0, -1]\n",
    "end_hour = user_sub.iloc[-1, -1]\n",
    "\n",
    "print('begin_hour:', begin_hour, ', end_hour:', end_hour)\n",
    "count = 1\n",
    "while begin_hour <= end_hour:\n",
    "    condtion = (user_sub['hour'] >= begin_hour) & (user_sub['hour'] <= begin_hour + count)\n",
    "    one_hour = user_sub.loc[condtion, :]\n",
    "    begin_hour = begin_hour + count\n",
    "    if one_hour.shape[0] < 1:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(60, 12))\n",
    "    axes = plt.axes(projection='3d')\n",
    "    axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "    one_hour['time_reg'] = [str(dd.time()) for dd in one_hour['datetime']]\n",
    "    axes.scatter3D(dates.date2num(one_hour['datetime']), one_hour['latitude'], one_hour['longitude'], s=10)\n",
    "    axes.plot3D(dates.date2num(one_hour['datetime']), one_hour['latitude'], one_hour['longitude'])\n",
    "    axes.set_xlabel('time')\n",
    "    axes.set_ylabel('latitude')\n",
    "    axes.set_zlabel('longitude')\n",
    "    axes.set_xticklabels(one_hour['datetime'], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location(Latitude, Logitude) 에 대한 최소, 최대값을 구해야 함.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "min_lat_list = []\n",
    "min_lon_list = []\n",
    "max_lat_list = []\n",
    "max_lon_list = []\n",
    "\n",
    "user_id_list = []\n",
    "for id in range(182):\n",
    "    user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if df.shape[0] < 500:\n",
    "        continue\n",
    "\n",
    "    user0 = df[['days', 'latitude', 'longitude']].copy()\n",
    "    user_id_list += [user_id]\n",
    "    min_lat_list += [user0['latitude'].min()]\n",
    "    max_lat_list += [user0['latitude'].max()]\n",
    "    min_lon_list += [user0['longitude'].min()]\n",
    "    max_lon_list += [user0['longitude'].max()]\n",
    "    \n",
    "    # if user0['latitude'].min() < min_lat:\n",
    "    #     min_lat = user0['latitude'].min()\n",
    "    # if user0['latitude'].max() > max_lat:\n",
    "    #     max_lat = user0['latitude'].max()\n",
    "    # if user0['longitude'].min() < min_lon:\n",
    "    #     min_lon = user0['longitude'].min()\n",
    "    # if user0['longitude'].max() > max_lon:\n",
    "    #     max_lon = user0['longitude'].max()\n",
    "\n",
    "print(f\"min_lat: {min_lat}, min_lon: {min_lon}\")\n",
    "print(f\"max_lat: {max_lat}, max_lon: {max_lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df = pd.DataFrame({'user_id':user_id_list,\n",
    "                                'min_lat':min_lat_list,\n",
    "                                'min_lon':min_lon_list,\n",
    "                                'max_lat':max_lat_list,\n",
    "                                'max_lon':max_lon_list})\n",
    "user_location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df_pre = user_location_df.copy()\n",
    "user_location_df_pre = user_location_df_pre.set_index('user_id', drop=True).copy()\n",
    "\n",
    "X = ['min_lat', 'min_lon', 'max_lat', 'max_lon']\n",
    "q1 = user_location_df_pre[X].quantile(0.25)\n",
    "q3 = user_location_df_pre[X].quantile(0.75)\n",
    "iqr = (q3-q1) * 1.5\n",
    "\n",
    "cond1 = user_location_df_pre[X] >= (q1 - iqr)\n",
    "# cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "\n",
    "user_location_df_pre = user_location_df_pre[cond1].dropna().copy()\n",
    "cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond2].dropna()\n",
    "valid_user_list = user_location_df_pre.index\n",
    "print(f'valid user list: {valid_user_list}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df = pd.DataFrame({'valid_user_list':valid_user_list})\n",
    "df.to_csv('valid_user_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user = pd.read_csv('valid_user_list.csv')\n",
    "valid_user['valid_user_list']\n",
    "\n",
    "# location(Latitude, Logitude) 에 대한 최소, 최대값을 구해야 함.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "for id in valid_user['valid_user_list']:\n",
    "    user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    user0 = pd.read_csv(csv_file)\n",
    "    \n",
    "    if user0['latitude'].min() < min_lat:\n",
    "        min_lat = user0['latitude'].min()\n",
    "    if user0['latitude'].max() > max_lat:\n",
    "        max_lat = user0['latitude'].max()\n",
    "    if user0['longitude'].min() < min_lon:\n",
    "        min_lon = user0['longitude'].min()\n",
    "    if user0['longitude'].max() > max_lon:\n",
    "        max_lon = user0['longitude'].max()\n",
    "\n",
    "print(f\"min_lat: {min_lat}, min_lon: {min_lon}\")\n",
    "print(f\"max_lat: {max_lat}, max_lon: {max_lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_minmax_location import get_minmax_location\n",
    "\n",
    "get_minmax_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_minmax_location import LocationPreprocessor\n",
    "\n",
    "locationPreprocess = LocationPreprocessor()\n",
    "center_locatuon = locationPreprocess.get_center_location()\n",
    "\n",
    "earth_radius = 6371000\n",
    "\n",
    "def convert_coord_for_blender(lat, lon):\n",
    "    delta_lat = lat - center_locatuon[0]\n",
    "    delta_lon = lon - center_locatuon[1]\n",
    "    \n",
    "    x = delta_lon * earth_radius * (np.pi / 180) * np.cos(lat * (np.pi / 180))\n",
    "    y = delta_lat * earth_radius * (np.pi / 180)\n",
    " \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_coord_for_blender(self, lat, lon):\n",
    "    delta_lat = lat - self.center_coord[0]\n",
    "    delta_lon = lon - self.center_coord[1]\n",
    "\n",
    "    x = delta_lon * self.earth_radius * (np.pi / 180) * np.cos(lat * (np.pi / 180))\n",
    "    y = delta_lat * self.earth_radius * (np.pi / 180)\n",
    " \n",
    "    return x, y\n",
    " \n",
    "earth_radius = 6371000\n",
    "lower_left_coord = [self.config['coords']['lower_left']['lat'], self.config['coords']['lower_left']['lon']]\n",
    "upper_right_coord = [self.config['coords']['upper_right']['lat'], self.config['coords']['upper_right']['lon']]\n",
    "center_coord = [\n",
    "    (self.lower_left_coord[0] + self.upper_right_coord[0]) / 2,\n",
    "    (self.lower_left_coord[1] + self.upper_right_coord[1]) / 2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(0).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 은 샘플과 정답(label)을 저장하고, \n",
    "# DataLoader 는 Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
    "# https://wikidocs.net/156998\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "    # 생성자, 데이터를 전처리하는 부분\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 99, 95]]\n",
    "        self.y_data = [[152], \n",
    "                       [185]]\n",
    "    \n",
    "    def __len__(self):\n",
    "    # 데이터셋의 총 길이를 반환하는 부분\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    # idx 에 해당하는 입출력 데이터를 반환한다.\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "    \n",
    "customData = CustomDataset()\n",
    "customData.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "index = 10\n",
    "data_dir = 'Data/'\n",
    "csv_dir = 'csv/'\n",
    "csv_extension = '.csv'\n",
    "user_path_list = os.listdir(data_dir)\n",
    "csv_path = os.path.join(data_dir, user_path_list[index], csv_dir)\n",
    "user_file = csv_path + user_path_list[index] + '.csv'\n",
    "df = pd.read_csv(user_file)\n",
    "df[[\"days\",\"latitude\", \"longitude\"]].head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Data folder 중 숫자가 안되는 User folder는 삭제하고\n",
    "# 남은 User data에서 train-test 폴더로 나눈 후\n",
    "# train_set(dataset), test_set(dataset) 으로 진행 필요\n",
    "\n",
    "class GeoLifeDataSet(Dataset):\n",
    "    def __init__(self, data_dir, user_list, samples_s, samples_q, length, y_timestep):\n",
    "        self.data_dir   = data_dir\n",
    "        self.csv_dir    = 'csv/'\n",
    "        self.user_list  = user_list\n",
    "        # user_list: all user\n",
    "        self.samples_s  = samples_s\n",
    "        # samples_s: the number of support set\n",
    "        self.samples_q  = samples_q\n",
    "        # samples_q: the number of query set\n",
    "        self.length     = length \n",
    "        # length: the length of mini batch of a user\n",
    "        self.y_timestep = y_timestep\n",
    "        # y_time_step: the next time step to be predicted\n",
    "        #              it must be less than length\n",
    "    \n",
    "    def sampleTime(self, dataset):\n",
    "        cur_ds = dataset.copy()\n",
    "        minibatch = []\n",
    "        \n",
    "        max_len = len(cur_ds)\n",
    "        ###############################################\n",
    "        # MAke sure samples from query and support \n",
    "        # do not intersect\n",
    "        ##############################################\n",
    "        # total_data_slice -> lenght 만큼 나눴을 때 총 slice 갯수\n",
    "        total_data_slice = list(range(int(max_len/self.length)))\n",
    "        total_samps = self.samples_q + self.samples_s\n",
    "        \n",
    "        slice_point = int(len(total_data_slice)*(self.samples_s/total_samps))\n",
    "        # print(f\"slice_point: {slice_point}\")\n",
    "\n",
    "        s_s_list = total_data_slice[:slice_point]\n",
    "        q_s_list = total_data_slice[slice_point:]\n",
    "\n",
    "        replace = False\n",
    "        if total_samps > len(total_data_slice):\n",
    "            replace = True\n",
    "\n",
    "        s_s_list = np.random.choice(s_s_list, size=self.samples_s, replace=replace)\n",
    "        q_s_list = np.random.choice(q_s_list, size=self.samples_q, replace=replace)\n",
    "        \n",
    "        # print(f\"s_list:{s_s_list}\")\n",
    "        # print(f\"q_list:{q_s_list}\")\n",
    "        choice_list = np.concatenate([s_s_list, q_s_list])\n",
    "        # #################################################\n",
    "        # print(f\"choice_list: {choice_list}\")\n",
    "        \n",
    "        for idx in choice_list:\n",
    "            start_idx = idx * self.length\n",
    "            if max_len - self.length >= 0:\n",
    "                cur_sample = cur_ds.iloc[start_idx:(start_idx + self.length), :]\n",
    "                minibatch.append(cur_sample)\n",
    "            else:\n",
    "                fill_quota  = np.abs(self.length - max_len)\n",
    "                zeros_r     = np.zeros([fill_quota, cur_ds.shape[1]])\n",
    "                cur_sample  = cur_ds[:, :]\n",
    "                cur_sample  = np.concatenate([zeros_r, cur_sample], axis = 0)\n",
    "                minibatch.append(cur_sample)\n",
    "        return np.array(minibatch)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        csv_path = os.path.join(self.data_dir, self.user_list[index], self.csv_dir)\n",
    "        user_file = csv_path + self.user_list[index] + '.csv'\n",
    "        df = pd.read_csv(user_file)\n",
    "        df = df[['days','latitude', 'longitude']]\n",
    "\n",
    "        samples = self.sampleTime(df)\n",
    "        # print(f\"mini_batch: {samples.shape}\")\n",
    "        # mini_batch: (5, 10, 3)\n",
    "        \n",
    "        sup_x = np.array(samples[:self.samples_s, :-self.y_timestep, :])\n",
    "        sup_y = np.array(samples[:self.samples_s, -self.y_timestep:, -2:])\n",
    "        que_x = np.array(samples[self.samples_s:, :-self.y_timestep, :])\n",
    "        que_y = np.array(samples[self.samples_s:, -self.y_timestep:, -2:])\n",
    "\n",
    "        return (que_x, sup_x, sup_y), que_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        # batch를 구성할 수 있는 총 수\n",
    "        # 이 수에서 batch를 조정할 수 있다.\n",
    "        # 몇 명의 user 로 나눠서 할 지\n",
    "        return len(self.user_list)\n",
    "\n",
    "user_list = os.listdir(data_dir)\n",
    "random.shuffle(user_list)\n",
    "train_size = 0.1\n",
    "train_list = user_list[:(int)(len(user_list)*train_size)]\n",
    "print(f\"train_list: {len(train_list)}\")\n",
    "\n",
    "# dataset = GeoLifeDataSet(\"Data/\", [0, 1, 2, 3], 5, 2, 100, 10)\n",
    "# dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = \"Data/\"#\"data/geolife/Data/\"\n",
    "sample_s = 5\n",
    "sample_q = 3\n",
    "length = 100\n",
    "y_timestep = 10\n",
    "\n",
    "user_list = os.listdir(data_dir)\n",
    "random.shuffle(user_list)\n",
    "train_size = 0.1\n",
    "train_list = user_list[:(int)(len(user_list)*train_size)]\n",
    "test_list  = user_list[(int)(len(user_list)*train_size):]\n",
    "print(f\"train_list: {len(train_list)}\")\n",
    "\n",
    "training_data = GeoLifeDataSet(data_dir, train_list, sample_s, sample_q, length, y_timestep)\n",
    "test_data = GeoLifeDataSet(data_dir, train_list, sample_s, sample_q, length, y_timestep)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=False)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "train_x, train_y = next(iter(train_dataloader))\n",
    "print(f\"support_x: {train_x[0].shape}\")\n",
    "print(f\"support_y: {train_x[1].shape}\")\n",
    "print(f\"query_x: {train_x[2].shape}\")\n",
    "print(f\"query_y: {train_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [1, 2, 3, 4, 5]\n",
    "shape[:-2] + [-1] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # input is TASKS x SAMPLES x FEATURES x TIME x Latent vector\n",
    "        shape = torch._shape_as_tensor(inp)\n",
    "        # (3, 20, 6, 100, 1)\n",
    "        x = torch.reshape(inp, [-1, shape[-2], shape[-1]])\n",
    "        # (300, 100, 1)\n",
    "        x, f = self.gru(x)\n",
    "        # x:(300, 100, 32)\n",
    "        # f:(3, 100, 32)\n",
    "        \n",
    "        if self.final:\n",
    "            new_shape = shape[:-2].tolist() + [-1]\n",
    "            out = torch.reshape(f, new_shape)\n",
    "        else:\n",
    "            new_shape = shape[:-1].tolist() + [-1]\n",
    "            # (3, 20, 6, 100, -1)\n",
    "            out = torch.reshape(x, new_shape)\n",
    "            # (3, 20, 6, 100, 32)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/000/csv/000.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/001/csv/001.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/000/csv/000.csv')\n",
    "df.head(1)\n",
    "df_temp = df[['latitude', 'longitude']].copy()\n",
    "\n",
    "model = KMeans(n_clusters=100, random_state=123)\n",
    "model.fit(df_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['label'] = model.labels_\n",
    "df_temp['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
