{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 114, 39.98715717254236, 117.4918228913047, 1475)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gps_grid_map_creator import GPSGridMapCreator\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "grid_size_meter = 500  # Size of each grid in meters\n",
    "\n",
    "mapCreator = GPSGridMapCreator(grid_size_meter)\n",
    "mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "print(mapCreator.find_grid_number(39.99, 117.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid user list: Index(['000', '001', '003', '004', '005', '006', '007', '008', '009', '011',\n",
      "       ...\n",
      "       '165', '166', '169', '170', '173', '174', '177', '179', '180', '181'],\n",
      "      dtype='object', name='user_id', length=126)\n"
     ]
    }
   ],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "locationPreprocessor.set_valid_user_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 0\n",
      "user_id: 1\n",
      "user_id: 3\n",
      "user_id: 4\n",
      "user_id: 5\n",
      "user_id: 6\n",
      "user_id: 7\n",
      "user_id: 8\n",
      "user_id: 9\n",
      "user_id: 11\n",
      "user_id: 13\n",
      "user_id: 14\n",
      "user_id: 15\n",
      "user_id: 16\n",
      "user_id: 18\n",
      "user_id: 19\n",
      "user_id: 21\n",
      "user_id: 24\n",
      "user_id: 26\n",
      "user_id: 27\n",
      "user_id: 29\n",
      "user_id: 30\n",
      "user_id: 31\n",
      "user_id: 32\n",
      "user_id: 33\n",
      "user_id: 34\n",
      "user_id: 35\n",
      "user_id: 36\n",
      "user_id: 37\n",
      "user_id: 38\n",
      "user_id: 39\n",
      "user_id: 40\n",
      "user_id: 43\n",
      "user_id: 44\n",
      "user_id: 45\n",
      "user_id: 46\n",
      "user_id: 47\n",
      "user_id: 48\n",
      "user_id: 49\n",
      "user_id: 50\n",
      "user_id: 51\n",
      "user_id: 54\n",
      "user_id: 55\n",
      "user_id: 56\n",
      "user_id: 57\n",
      "user_id: 58\n",
      "user_id: 59\n",
      "user_id: 61\n",
      "user_id: 63\n",
      "user_id: 64\n",
      "user_id: 65\n",
      "user_id: 66\n",
      "user_id: 67\n",
      "user_id: 68\n",
      "user_id: 69\n",
      "user_id: 70\n",
      "user_id: 73\n",
      "user_id: 74\n",
      "user_id: 75\n",
      "user_id: 76\n",
      "user_id: 77\n",
      "user_id: 78\n",
      "user_id: 79\n",
      "user_id: 80\n",
      "user_id: 81\n",
      "user_id: 85\n",
      "user_id: 86\n",
      "user_id: 88\n",
      "user_id: 93\n",
      "user_id: 94\n",
      "user_id: 95\n",
      "user_id: 96\n",
      "user_id: 97\n",
      "user_id: 98\n",
      "user_id: 100\n",
      "user_id: 101\n",
      "user_id: 102\n",
      "user_id: 103\n",
      "user_id: 104\n",
      "user_id: 105\n",
      "user_id: 106\n",
      "user_id: 109\n",
      "user_id: 110\n",
      "user_id: 112\n",
      "user_id: 113\n",
      "user_id: 114\n",
      "user_id: 116\n",
      "user_id: 119\n",
      "user_id: 121\n",
      "user_id: 122\n",
      "user_id: 125\n",
      "user_id: 129\n",
      "user_id: 130\n",
      "user_id: 131\n",
      "user_id: 133\n",
      "user_id: 134\n",
      "user_id: 135\n",
      "user_id: 136\n",
      "user_id: 137\n",
      "user_id: 138\n",
      "user_id: 141\n",
      "user_id: 143\n",
      "user_id: 145\n",
      "user_id: 147\n",
      "user_id: 148\n",
      "user_id: 149\n",
      "user_id: 150\n",
      "user_id: 151\n",
      "user_id: 152\n",
      "user_id: 154\n",
      "user_id: 155\n",
      "user_id: 156\n",
      "user_id: 157\n",
      "user_id: 158\n",
      "user_id: 159\n",
      "user_id: 161\n",
      "user_id: 165\n",
      "user_id: 166\n",
      "user_id: 169\n",
      "user_id: 170\n",
      "user_id: 173\n",
      "user_id: 174\n",
      "user_id: 177\n",
      "user_id: 179\n",
      "user_id: 180\n",
      "user_id: 181\n"
     ]
    }
   ],
   "source": [
    "# csv 파일 5분 단위로 전처리하기 (rounded)\n",
    "# round_min 을 조절하여 round_min 간격으로 data를 전처리\n",
    "\n",
    "from convert_minmax_location import LocationPreprocessor\n",
    "from gps_grid_map_creator import GPSGridMapCreator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "\n",
    "days_min = 0.000696\n",
    "gap = 1\n",
    "round_min = str(gap) + 'min'\n",
    "\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "\n",
    "# origin_grid_10min = just add grid in original csv file\n",
    "# grid_10min        = from begin to end full data with fillna(ffill)\n",
    "round_csv = '_origin_round_' + round_min + '.csv'\n",
    "grid_csv = '_origin_grid_' + round_min + '.csv'\n",
    "grid_list = [50, 100, 500, 1000, 1500, 2000, 3000]\n",
    "\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"user_id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    rounded_file = './Data/' + user_id + '/csv/' + user_id + round_csv\n",
    "    grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['datetime'] = pd.to_datetime(df['date'] + \" \" + df['time'])\n",
    "    df['datetime'] = df['datetime'].dt.round(round_min)\n",
    "\n",
    "    df = df.set_index('datetime').reset_index()\n",
    "    user_df = df.groupby('datetime')[df.columns[1:].to_list()].mean().reset_index()\n",
    "    user_df = locationPreprocessor.convert_coord_for_blender_for_user(user_df)\n",
    "\n",
    "    user_df['datetime'] = pd.to_datetime(user_df['datetime'])\n",
    "\n",
    "    user_df['year'] = user_df['datetime'].dt.year\n",
    "    user_df['month'] = user_df['datetime'].dt.month\n",
    "    user_df['week'] = user_df['datetime'].dt.weekday\n",
    "    user_df['weekend'] = np.where(user_df['week'] < 5, 0, 1)\n",
    "    user_df['hour'] = user_df['datetime'].dt.hour\n",
    "    user_df['day'] = user_df['datetime'].dt.day\n",
    "\n",
    "    # save rounded file\n",
    "    # user_df.to_csv(rounded_file, index=False)\n",
    "\n",
    "    # grid process\n",
    "    user_df = user_df.drop(columns=['datetime', 'altitude', 'what'])\n",
    "    for grid_len in grid_list:\n",
    "        mapCreator = GPSGridMapCreator(grid_len)\n",
    "        mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "        grid_row = 'grid_row_' + str(grid_len) + 'm' # row\n",
    "        grid_col = 'grid_col_' + str(grid_len) + 'm' # column\n",
    "        grid_lat = 'grid_lat_' + str(grid_len) + 'm' # lat\n",
    "        grid_lon = 'grid_lon_' + str(grid_len) + 'm' # lon\n",
    "        grid_num = 'grid_num_' + str(grid_len) + 'm' # num      \n",
    "        user_df[grid_row], user_df[grid_col],_,_,_ = mapCreator.find_grid_number(user_df['latitude'], user_df['longitude'])\n",
    "    # save grid file\n",
    "    user_df.to_csv(grid_file, index=False)\n",
    "    \n",
    "    # process one single user train, validation\n",
    "    # train_len = round(user_df.shape[0] * 0.7)\n",
    "    # valid_len = round(user_df.shape[0] * 0.3)\n",
    "    \n",
    "    # train_set = user_df.iloc[:train_len, :]\n",
    "    # valid_set = user_df.iloc[train_len:, :]\n",
    "    # # test_set = user_df.iloc[train_len + valid_len:, :]\n",
    "    \n",
    "    # train_file = './Data/' + user_id + '/csv/' + user_id + '_origin_train_set.csv'\n",
    "    # valid_file = './Data/' + user_id + '/csv/' + user_id + '_origin_valid_set.csv'\n",
    "    # # test_file = './Data/' + user_id + '/csv/' + user_id + '_test_set.csv'\n",
    "    \n",
    "    # train_set.to_csv(train_file, index=False)\n",
    "    # valid_set.to_csv(valid_file, index=False)\n",
    "    # # test_set.to_csv(test_file, index=False)\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '035'\n",
    "grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.csv 파일의 column 확인 코드\n",
    "import pandas as pd\n",
    "\n",
    "user_id = '067'\n",
    "\n",
    "gap = 10\n",
    "round_min = str(gap) + 'min'\n",
    "grid_csv = '_grid_' + round_min + '.csv'\n",
    "grid_file = './Data/' + user_id + '/csv/' + user_id + grid_csv\n",
    "\n",
    "train_file = './Data/' + user_id + '/csv/' + user_id + '_train_set.csv'\n",
    "valid_file = './Data/' + user_id + '/csv/' + user_id + '_valid_set.csv'\n",
    "test_file = './Data/' + user_id + '/csv/' + user_id + '_test_set.csv'\n",
    "\n",
    "df = pd.read_csv(grid_file)\n",
    "print(df.info())\n",
    "# print(df.tail())\n",
    "\n",
    "# columns = df.loc[:, :'grid_col_50m'].columns.to_list() #df.columns[:'grid_col_50m'].to_list() #+ df.columns[58:60].to_list()\n",
    "columns = df.columns[2:11].to_list() #+ df.columns[15:17].to_list()\n",
    "df_1 = df[columns].copy()\n",
    "df_1 = pd.get_dummies(df_1, columns=['hour'], drop_first=True)\n",
    "df_1 = pd.concat([df_1, df.iloc[:, 15:17]], axis=1)\n",
    "print(df_1.columns)\n",
    "print(df_1.tail())\n",
    "\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_valid = pd.read_csv(valid_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "print(f\"train: {df_train.shape[0]}\")\n",
    "print(f\"valid: {df_valid.shape[0]}\")\n",
    "print(f\"test: {df_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 0\n",
      "user_id: 1\n",
      "user_id: 3\n",
      "user_id: 4\n",
      "user_id: 5\n",
      "user_id: 6\n",
      "user_id: 7\n",
      "user_id: 8\n",
      "user_id: 9\n",
      "user_id: 11\n",
      "user_id: 13\n",
      "user_id: 14\n",
      "user_id: 15\n",
      "user_id: 16\n",
      "user_id: 18\n",
      "user_id: 19\n",
      "user_id: 21\n",
      "user_id: 24\n",
      "user_id: 26\n",
      "user_id: 27\n",
      "user_id: 29\n",
      "user_id: 30\n",
      "user_id: 31\n",
      "user_id: 32\n",
      "user_id: 33\n",
      "user_id: 34\n",
      "user_id: 35\n",
      "user_id: 36\n",
      "user_id: 37\n",
      "user_id: 38\n",
      "user_id: 39\n",
      "user_id: 40\n",
      "user_id: 43\n",
      "user_id: 44\n",
      "user_id: 45\n",
      "user_id: 46\n",
      "user_id: 47\n",
      "user_id: 48\n",
      "user_id: 49\n",
      "user_id: 50\n",
      "user_id: 51\n",
      "user_id: 54\n",
      "user_id: 55\n",
      "user_id: 56\n",
      "user_id: 57\n",
      "user_id: 58\n",
      "user_id: 59\n",
      "user_id: 61\n",
      "user_id: 63\n",
      "user_id: 64\n",
      "user_id: 65\n",
      "user_id: 66\n",
      "user_id: 67\n",
      "user_id: 68\n",
      "user_id: 69\n",
      "user_id: 70\n",
      "user_id: 73\n",
      "user_id: 74\n",
      "user_id: 75\n",
      "user_id: 76\n",
      "user_id: 77\n",
      "user_id: 78\n",
      "user_id: 79\n",
      "user_id: 80\n",
      "user_id: 81\n",
      "user_id: 85\n",
      "user_id: 86\n",
      "user_id: 88\n",
      "user_id: 93\n",
      "user_id: 94\n",
      "user_id: 95\n",
      "user_id: 96\n",
      "user_id: 97\n",
      "user_id: 98\n",
      "user_id: 100\n",
      "user_id: 101\n",
      "user_id: 102\n",
      "user_id: 103\n",
      "user_id: 104\n",
      "user_id: 105\n",
      "user_id: 106\n",
      "user_id: 109\n",
      "user_id: 110\n",
      "user_id: 112\n",
      "user_id: 113\n",
      "user_id: 114\n",
      "user_id: 116\n",
      "user_id: 119\n",
      "user_id: 121\n",
      "user_id: 122\n",
      "user_id: 125\n",
      "user_id: 129\n",
      "user_id: 130\n",
      "user_id: 131\n",
      "user_id: 133\n",
      "user_id: 134\n",
      "user_id: 135\n",
      "user_id: 136\n",
      "user_id: 137\n",
      "user_id: 138\n",
      "user_id: 141\n",
      "user_id: 143\n",
      "user_id: 145\n",
      "user_id: 147\n",
      "user_id: 148\n",
      "user_id: 149\n",
      "user_id: 150\n",
      "user_id: 151\n",
      "user_id: 152\n",
      "user_id: 154\n",
      "user_id: 155\n",
      "user_id: 156\n",
      "user_id: 157\n",
      "user_id: 158\n",
      "user_id: 159\n",
      "user_id: 161\n",
      "user_id: 165\n",
      "user_id: 166\n",
      "user_id: 169\n",
      "user_id: 170\n",
      "user_id: 173\n",
      "user_id: 174\n",
      "user_id: 177\n",
      "user_id: 179\n",
      "user_id: 180\n",
      "user_id: 181\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>rounded_len</th>\n",
       "      <th>ori_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>2008-10-23 02:53:04</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>15133</td>\n",
       "      <td>173870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>2008-10-23 05:53:05</td>\n",
       "      <td>2008-12-15 00:31:18</td>\n",
       "      <td>6904</td>\n",
       "      <td>108607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003</td>\n",
       "      <td>2008-10-23 17:58:54</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>41807</td>\n",
       "      <td>485226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004</td>\n",
       "      <td>2008-10-23 17:58:52</td>\n",
       "      <td>2009-07-29 06:16:11</td>\n",
       "      <td>38021</td>\n",
       "      <td>439397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005</td>\n",
       "      <td>2008-10-24 04:12:30</td>\n",
       "      <td>2009-03-19 05:46:37</td>\n",
       "      <td>8731</td>\n",
       "      <td>109046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id          begin_date            end_date  rounded_len  ori_len\n",
       "0     000 2008-10-23 02:53:04 2009-07-05 07:45:15        15133   173870\n",
       "1     001 2008-10-23 05:53:05 2008-12-15 00:31:18         6904   108607\n",
       "2     003 2008-10-23 17:58:54 2009-07-05 07:45:15        41807   485226\n",
       "3     004 2008-10-23 17:58:52 2009-07-29 06:16:11        38021   439397\n",
       "4     005 2008-10-24 04:12:30 2009-03-19 05:46:37         8731   109046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import numpy as np\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "\n",
    "user_id_list = []\n",
    "begin_day_list = []\n",
    "end_day_list = []\n",
    "df_len_list = []\n",
    "ori_len_list = []\n",
    "\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"user_id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_origin_grid_1min.csv'\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    user_df = pd.read_csv(csv_convert_file)\n",
    "    orig_df = pd.read_csv(csv_file)\n",
    "    orig_df['datetime'] = pd.to_datetime(orig_df['date'] + \" \" + orig_df['time'])\n",
    "\n",
    "    user_id_list += [user_id]\n",
    "    df_len_list += [user_df.shape[0]]\n",
    "    ori_len_list += [orig_df.shape[0]]\n",
    "\n",
    "    begin_day_list += [orig_df.iloc[0, -1]]\n",
    "    end_day_list += [orig_df.iloc[-1, -1]]\n",
    "\n",
    "user_df = pd.DataFrame({'user_id':user_id_list,\n",
    "                        'begin_date':begin_day_list,\n",
    "                        'end_date':end_day_list,\n",
    "                        'rounded_len':df_len_list,\n",
    "                        'ori_len':ori_len_list})\n",
    "user_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()\n",
    "user_df = user_df.sort_values('rounded_len', ascending=False)\n",
    "user_df.to_csv('grid_user_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>rounded_len</th>\n",
       "      <th>ori_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 02:53:04</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>15133</td>\n",
       "      <td>173870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-10-23 05:53:05</td>\n",
       "      <td>2008-12-15 00:31:18</td>\n",
       "      <td>6904</td>\n",
       "      <td>108607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-10-23 17:58:54</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>41807</td>\n",
       "      <td>485226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-10-23 17:58:52</td>\n",
       "      <td>2009-07-29 06:16:11</td>\n",
       "      <td>38021</td>\n",
       "      <td>439397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-10-24 04:12:30</td>\n",
       "      <td>2009-03-19 05:46:37</td>\n",
       "      <td>8731</td>\n",
       "      <td>109046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id           begin_date             end_date  rounded_len  ori_len\n",
       "0        0  2008-10-23 02:53:04  2009-07-05 07:45:15        15133   173870\n",
       "1        1  2008-10-23 05:53:05  2008-12-15 00:31:18         6904   108607\n",
       "2        3  2008-10-23 17:58:54  2009-07-05 07:45:15        41807   485226\n",
       "3        4  2008-10-23 17:58:52  2009-07-29 06:16:11        38021   439397\n",
       "4        5  2008-10-24 04:12:30  2009-03-19 05:46:37         8731   109046"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('grid_user_list.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 100 일 이상 좌표 수집한 user 45명\n",
    "# user_df.to_csv('origin_round_10min_user_list.csv', index=False)\n",
    "\n",
    "df_1 = pd.read_csv('origin_round_10min_user_list.csv')\n",
    "df = pd.read_csv('round_10min_user_list.csv')\n",
    "\n",
    "df = df.merge(df_1, how='inner', on = 'user_id')\n",
    "df = df.loc[df['rounded_len_y'] > 2000, :]\n",
    "df['extra_ratio'] = round(df['rounded_len_x'] / df['rounded_len_y'], 1)\n",
    "\n",
    "df = df.sort_values(['extra_ratio'], ascending=True)\n",
    "\n",
    "df = df.rename(columns = {'rounded_len_y':'rounded_10min_len',\n",
    "                          'rounded_len_x':'date_rounded',\n",
    "                          'original_len_x':'original_len'})\n",
    "df = df[['user_id','begin_date','end_date','date_rounded','original_len', 'rounded_10min_len', 'extra_ratio']]\n",
    "df.head()\n",
    "df.to_csv('extra_ratio.csv', index=False)\n",
    "\n",
    "# df = df.loc[df['rounded_len'] >= 14400, :]\n",
    "# df['user_id'].to_list()\n",
    "# df.head(20)\n",
    "# df.sort_values('rounded_len', ascending=False)\n",
    "# ['068', '030', '085', '003', '004']\",\"['065', '067']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>begin_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>date_rounded</th>\n",
       "      <th>original_len</th>\n",
       "      <th>rounded_10min_len</th>\n",
       "      <th>extra_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>2009-02-09 10:48:38</td>\n",
       "      <td>2009-04-27 06:14:45</td>\n",
       "      <td>11061</td>\n",
       "      <td>312042</td>\n",
       "      <td>3162</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-10-23 17:58:54</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>36660</td>\n",
       "      <td>485226</td>\n",
       "      <td>5969</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>2009-01-13 02:32:22</td>\n",
       "      <td>2009-07-29 01:40:07</td>\n",
       "      <td>28364</td>\n",
       "      <td>615948</td>\n",
       "      <td>4320</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-10-23 17:58:52</td>\n",
       "      <td>2009-07-29 06:16:11</td>\n",
       "      <td>40107</td>\n",
       "      <td>439397</td>\n",
       "      <td>5671</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>2009-02-11 09:59:38</td>\n",
       "      <td>2009-07-15 00:56:11</td>\n",
       "      <td>22123</td>\n",
       "      <td>267737</td>\n",
       "      <td>3098</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>2008-12-16 01:00:33</td>\n",
       "      <td>2009-05-26 10:51:12</td>\n",
       "      <td>23244</td>\n",
       "      <td>263482</td>\n",
       "      <td>2648</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>2008-09-14 13:03:08</td>\n",
       "      <td>2009-09-13 12:51:15</td>\n",
       "      <td>52416</td>\n",
       "      <td>937876</td>\n",
       "      <td>5073</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38</td>\n",
       "      <td>2009-02-06 12:11:02</td>\n",
       "      <td>2009-07-23 18:13:12</td>\n",
       "      <td>24085</td>\n",
       "      <td>250393</td>\n",
       "      <td>2069</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>2008-10-20 05:45:00</td>\n",
       "      <td>2009-04-17 01:50:18</td>\n",
       "      <td>25754</td>\n",
       "      <td>388213</td>\n",
       "      <td>2136</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 02:53:04</td>\n",
       "      <td>2009-07-05 07:45:15</td>\n",
       "      <td>36751</td>\n",
       "      <td>173870</td>\n",
       "      <td>2286</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id           begin_date             end_date  date_rounded  \\\n",
       "0       35  2009-02-09 10:48:38  2009-04-27 06:14:45         11061   \n",
       "1        3  2008-10-23 17:58:54  2009-07-05 07:45:15         36660   \n",
       "2       30  2009-01-13 02:32:22  2009-07-29 01:40:07         28364   \n",
       "3        4  2008-10-23 17:58:52  2009-07-29 06:16:11         40107   \n",
       "4       39  2009-02-11 09:59:38  2009-07-15 00:56:11         22123   \n",
       "5       24  2008-12-16 01:00:33  2009-05-26 10:51:12         23244   \n",
       "6       68  2008-09-14 13:03:08  2009-09-13 12:51:15         52416   \n",
       "7       38  2009-02-06 12:11:02  2009-07-23 18:13:12         24085   \n",
       "8       14  2008-10-20 05:45:00  2009-04-17 01:50:18         25754   \n",
       "9        0  2008-10-23 02:53:04  2009-07-05 07:45:15         36751   \n",
       "\n",
       "   original_len  rounded_10min_len  extra_ratio  \n",
       "0        312042               3162          3.5  \n",
       "1        485226               5969          6.1  \n",
       "2        615948               4320          6.6  \n",
       "3        439397               5671          7.1  \n",
       "4        267737               3098          7.1  \n",
       "5        263482               2648          8.8  \n",
       "6        937876               5073         10.3  \n",
       "7        250393               2069         11.6  \n",
       "8        388213               2136         12.1  \n",
       "9        173870               2286         16.1  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "user = pd.read_csv('extra_ratio.csv')\n",
    "user.head(10)\n",
    "# user = user.sort_values('original_len', ascending=False)\n",
    "# user = user[['user_id', 'original_len', 'extra_rounded', 'rounded_10min', 'extra_ratio']]\n",
    "# user.rename(columns={'extra_rounded':'rounded_10min',\n",
    "#                      'rounded_10min':'rounded_len'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "user_id = '085'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user_df = pd.read_csv(csv_convert_file)\n",
    "user_df.head(1)\n",
    "\n",
    "# user_df = user_df[['days','month','week','weekend','hour','day','x','y']]\n",
    "# user_df = pd.get_dummies(user_df, columns=['week','month'], drop_first=True)\n",
    "# user_xy = user_df.loc[:, ['x', 'y']]\n",
    "# user_df = user_df.drop(columns=['x', 'y'])\n",
    "# pd.concat([user_df, user_xy], axis=1)\n",
    "\n",
    "df_1 = user_df[['days','month','week','weekend','hour','day','x','y']]\n",
    "df_1 = pd.get_dummies(df_1, columns=['week','month'], drop_first=True)\n",
    "df_xy = df_1.loc[:, ['x', 'y']]\n",
    "df_1 = df_1.drop(columns=['x', 'y'])\n",
    "df_1 = pd.concat([df_1, df_xy], axis=1)\n",
    "df_1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame({\"user_id\":user_id_list,\n",
    "                        \"data_vol\":df_len_list})\n",
    "user_df = user_df.sort_values(['data_vol'], ascending=False)\n",
    "user_df.to_csv('user_data_volumn.csv', index=False)\n",
    "\n",
    "print(user_df.head(5))\n",
    "user_df.iloc[:5, 0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_s = 1\n",
    "sample_q = 1\n",
    "\n",
    "args_epoch = 1200\n",
    "args_patience = 300\n",
    "\n",
    "gap_min = 12 # 1 min\n",
    "gap = gap_min\n",
    "\n",
    "y_timestep = 100 # must be less than length\n",
    "length = 15000\n",
    "\n",
    "train_list      = ['068', '030', '085', '004']#, '085']\n",
    "validation_list = ['067']#, '085']\n",
    "test_list       = ['067']#, '085']\n",
    "\n",
    "conf_df = pd.DataFrame({'sample_s':[sample_s],\n",
    "                        'sample_q':[sample_q],\n",
    "                        'epoch':[args_epoch],\n",
    "                        'patience':[args_patience],\n",
    "                        'gap':[gap],\n",
    "                        'y_timestep':[y_timestep],\n",
    "                        'length':[length],\n",
    "                        'train_list':[train_list],\n",
    "                        'val_list':[validation_list],\n",
    "                        'test_list':[test_list]})\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.loc[user_df['user_id'] == '001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df_pre = user_location_df.copy()\n",
    "user_location_df_pre = user_location_df_pre.set_index('user_id', drop=True).copy()\n",
    "user_location_df_pre.head(2)\n",
    "\n",
    "X = ['min_lat', 'min_lon', 'max_lat', 'max_lon']\n",
    "q1 = user_location_df_pre[X].quantile(0.25)\n",
    "q3 = user_location_df_pre[X].quantile(0.75)\n",
    "iqr = (q3-q1) * 1.5\n",
    "\n",
    "cond1 = user_location_df_pre[X] >= (q1 - iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond1].dropna().copy()\n",
    "print(user_location_df_pre.shape)\n",
    "\n",
    "cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond2].dropna().copy()\n",
    "print(user_location_df_pre.shape)\n",
    "user_location_df_pre.min()\n",
    "user_location_df_pre.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "PI = 3.14159265358979323846\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2, unit):\n",
    "    deg2rad_multiplier = PI / 180\n",
    "    lat1 = lat1 * deg2rad_multiplier\n",
    "    lon1 = lon1 * deg2rad_multiplier\n",
    "    lat2 = lat2 * deg2rad_multiplier\n",
    "    lon2 = lon2 * deg2rad_multiplier\n",
    "\n",
    "    radius = 6378.137  # Earth mean radius defined by WGS84\n",
    "    dlon = lon2 - lon1\n",
    "    distance = math.acos(math.sin(lat1) * math.sin(lat2) + math.cos(lat1) * math.cos(lat2) * math.cos(dlon)) * radius\n",
    "    \n",
    "    # (kilometers, miles, nautical miles)\n",
    "    if unit == 'K':\n",
    "        return distance\n",
    "    elif unit == 'M':\n",
    "        return distance * 0.621371192\n",
    "    elif unit == 'N':\n",
    "        return distance * 0.539956803\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Example usage:\n",
    "result = distance(37.7749, -122.4194, 34.0522, -118.2437, 'K') * 1000\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 39.975300\n",
    "min_lon = 116.452488\n",
    "max_lat = 41.367085\n",
    "max_lon = 122.651456\n",
    "\n",
    "width = round(distance(39.975300, 122.651456, 41.367085, 122.651456, 'K'), 3)\n",
    "height = round(distance(41.367085, 116.452488, 41.367085, 122.651456, 'K'), 3)\n",
    "print(width)\n",
    "print(height)\n",
    "# up_width = 154.933\n",
    "# down_width = 154.933\n",
    "# left_height = 528.706\n",
    "# right_hegith = 517.778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class GPSGridMapCreator():\n",
    "    def __init__(self, grid_size_meter):\n",
    "        self.grid_size_meter = grid_size_meter\n",
    "        self.lat1 = 0\n",
    "        self.lon1 = 0\n",
    "        self.grid_numbers = 0\n",
    "        self.lat_degrees = 0\n",
    "        self.long_degrees = 0\n",
    "        self.num_lat = 0\n",
    "        self.num_lon = 0\n",
    "        \n",
    "    def km_to_degrees(self, latitude, kilometers):\n",
    "        # Earth's radius in kilometers\n",
    "        earth_radius_km = 6371.0\n",
    "\n",
    "        # Convert kilometers to radians\n",
    "        angle_rad = kilometers / earth_radius_km\n",
    "\n",
    "        # Convert radians to degrees\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "        # Correction factor for latitude\n",
    "        lat_correction = np.cos(np.radians(latitude))\n",
    "\n",
    "        # Convert degrees to adjusted degrees\n",
    "        adjusted_degrees = angle_deg / lat_correction\n",
    "\n",
    "        return adjusted_degrees\n",
    "\n",
    "    def meter_to_degrees(self, latitude, meters):\n",
    "        # Convert meters to kilometers\n",
    "        kilometers = meters / 1000\n",
    "\n",
    "        # Convert kilometers to degrees using the km_to_degrees function\n",
    "        degrees = self.km_to_degrees(latitude, kilometers)\n",
    "\n",
    "        return degrees\n",
    "\n",
    "    def create_grid_map(self, lat1, lon1, lat2, lon2):\n",
    "        self.lat1 = lat1\n",
    "        self.lon1 = lon1\n",
    "        # Convert grid size from meters to degrees\n",
    "        self.lat_degrees = self.meter_to_degrees((lat1 + lat2) / 2, self.grid_size_meter)\n",
    "        self.lon_degrees = self.meter_to_degrees((lon1 + lon2) / 2, self.grid_size_meter)\n",
    "\n",
    "        # print(f\"lat_degrees: {self.lat_degrees}, lon_degree: {self.lon_degrees}\")\n",
    "        # Calculate the number of grid points in latitude and longitude directions\n",
    "        self.num_lat = int(np.abs(lat2 - lat1) / np.abs(self.lat_degrees))\n",
    "        self.num_lon = int(np.abs(lon2 - lon1) / np.abs(self.lon_degrees))\n",
    "        # print(f\"lon2 - lon1: {np.abs(lon2 - lon1)}\")\n",
    "        # print(f\"num_lat: {self.num_lat}, num_lon: {self.num_lon}\")\n",
    "\n",
    "        # Generate latitude and longitude grid points\n",
    "        latitudes = np.linspace(lat1, lat2, self.num_lat)\n",
    "        longitudes = np.linspace(lon1, lon2, self.num_lon)\n",
    "\n",
    "        # print(f\"the num of latitudes: {len(latitudes)}\")\n",
    "        # print(f\"the num of longitude: {len(longitudes)}\")\n",
    "        # print(latitudes)\n",
    "        # print(longitudes)\n",
    "        # Create a 2D grid for numbering\n",
    "        self.grid_numbers = np.arange(0, (self.num_lat + 1) * (self.num_lon + 1)).reshape(self.num_lat + 1, self.num_lon + 1)\n",
    "        print(f\"gird_number: {self.grid_numbers.shape[0] * self.grid_numbers.shape[1]}\")\n",
    "\n",
    "    def find_grid_number(self, lat, lon):\n",
    "        grid_lat = int((lat - self.lat1) / np.abs(self.lat_degrees))\n",
    "        grid_lon = int((lon - self.lon1) / np.abs(self.lon_degrees))\n",
    "        gird_number = grid_lat * (self.num_lon + 1) + grid_lon + 1\n",
    "        return gird_number, grid_lat, grid_lon\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 39.975300, 116.452488  # Lower-left corner\n",
    "lat2, lon2 = 41.367085, 122.651456  # Upper-right corner\n",
    "grid_size_meter = 100  # Size of each grid in meters\n",
    "\n",
    "mapCreator = GPSGridMapCreator(grid_size_meter)\n",
    "mapCreator.create_grid_map(lat1, lon1, lat2, lon2)\n",
    "print(mapCreator.find_grid_number(39.99, 117.5))\n",
    "print(\"done\")\n",
    "# 3991600\n",
    "# 15966400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def km_to_degrees(latitude, kilometers):\n",
    "    # Earth's radius in kilometers\n",
    "    earth_radius_km = 6371.0\n",
    "\n",
    "    # Convert kilometers to radians\n",
    "    angle_rad = kilometers / earth_radius_km\n",
    "\n",
    "    # Convert radians to degrees\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "    # Correction factor for latitude\n",
    "    lat_correction = np.cos(np.radians(latitude))\n",
    "\n",
    "    # Convert degrees to adjusted degrees\n",
    "    adjusted_degrees = angle_deg / lat_correction\n",
    "\n",
    "    return adjusted_degrees\n",
    "\n",
    "def meter_to_degrees(latitude, meters):\n",
    "    # Convert meters to kilometers\n",
    "    kilometers = meters / 1000\n",
    "\n",
    "    # Convert kilometers to degrees using the km_to_degrees function\n",
    "    degrees = km_to_degrees(latitude, kilometers)\n",
    "\n",
    "    return degrees\n",
    "\n",
    "def create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter):\n",
    "    # Convert grid size from meters to degrees\n",
    "    lat_degrees = meter_to_degrees((lat1 + lat2) / 2, grid_size_meter)\n",
    "    lon_degrees = meter_to_degrees((lon1 + lon2) / 2, grid_size_meter)\n",
    "\n",
    "    print(f\"lat_degrees: {lat_degrees}, lon_degree: {lon_degrees}\")\n",
    "    # Calculate the number of grid points in latitude and longitude directions\n",
    "    num_lat = int(np.abs(lat2 - lat1) / np.abs(lat_degrees))\n",
    "    num_lon = int(np.abs(lon2 - lon1) / np.abs(lon_degrees))\n",
    "    print(f\"lon2 - lon1: {np.abs(lon2 - lon1)}\")\n",
    "    print(f\"num_lat: {num_lat}, num_lon: {num_lon}\")\n",
    "\n",
    "    # Calculate the latitude and longitude increments\n",
    "    # lat_increment = (lat2 - lat1) / num_lat\n",
    "    # lon_increment = (lon2 - lon1) / num_lon\n",
    "\n",
    "    # Generate latitude and longitude grid points\n",
    "    latitudes = np.linspace(lat1, lat2, num_lat)\n",
    "    longitudes = np.linspace(lon1, lon2, num_lon)\n",
    "\n",
    "    print(f\"the num of latitudes: {len(latitudes)}\")\n",
    "    print(f\"the num of longitude: {len(longitudes)}\")\n",
    "    print(longitudes)\n",
    "    # Create a 2D grid for numbering\n",
    "    grid_numbers = np.arange(0, (num_lat + 1) * (num_lon + 1)).reshape(num_lat + 1, num_lon + 1)\n",
    "\n",
    "    # # Plot the grid lines\n",
    "    # for lat in latitudes:\n",
    "    #     ax.plot([lon1, lon2], [lat, lat], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "    # for lon in longitudes:\n",
    "    #     ax.plot([lon, lon], [lat1, lat2], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Plot the numbers on the grid\n",
    "    # for i in range(num_lat + 1):\n",
    "    #     for j in range(num_lon + 1):\n",
    "    #         ax.text(lon1 + j * lon_increment, lat1 + i * lat_increment, str(grid_numbers[i, j]),\n",
    "    #                 horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # ax.coastlines()\n",
    "    # plt.show()\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 37.0, -122.0  # Lower-left corner\n",
    "lat2, lon2 = 38.0, -121.0  # Upper-right corner\n",
    "grid_size_meter = 1000  # Size of each grid in meters\n",
    "\n",
    "create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "def km_to_degrees(latitude, kilometers):\n",
    "    earth_radius_km = 6371.0\n",
    "    angle_rad = kilometers / earth_radius_km\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    lat_correction = np.cos(np.radians(latitude))\n",
    "    adjusted_degrees = angle_deg / lat_correction\n",
    "    return adjusted_degrees\n",
    "\n",
    "def meter_to_degrees(latitude, meters):\n",
    "    kilometers = meters / 1000\n",
    "    degrees = km_to_degrees(latitude, kilometers)\n",
    "    return degrees\n",
    "\n",
    "def find_grid_number(lat, lon, lat1, lon1, lat_degrees, lon_degrees):\n",
    "    grid_lat = int((lat - lat1) / lat_degrees)\n",
    "    grid_lon = int((lon - lon1) / lon_degrees)\n",
    "    return grid_lat, grid_lon\n",
    "\n",
    "def create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter):\n",
    "    lat_degrees = meter_to_degrees((lat1 + lat2) / 2, grid_size_meter)\n",
    "    lon_degrees = meter_to_degrees((lon1 + lon2) / 2, grid_size_meter)\n",
    "\n",
    "    num_lat = int(np.abs(lat2 - lat1) / lat_degrees)\n",
    "    num_lon = int(np.abs(lon2 - lon1) / lon_degrees)\n",
    "\n",
    "    lat_increment = (lat2 - lat1) / num_lat\n",
    "    lon_increment = (lon2 - lon1) / num_lon\n",
    "\n",
    "    latitudes = np.linspace(lat1, lat2, num_lat)\n",
    "    longitudes = np.linspace(lon1, lon2, num_lon)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_global()\n",
    "    ax.stock_img()\n",
    "\n",
    "    for lat in latitudes:\n",
    "        ax.plot([lon1, lon2], [lat, lat], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "    for lon in longitudes:\n",
    "        ax.plot([lon, lon], [lat1, lat2], color='black', linewidth=0.5, transform=ccrs.PlateCarree())\n",
    "\n",
    "    for i in range(num_lat + 1):\n",
    "        for j in range(num_lon + 1):\n",
    "            ax.text(lon1 + j * lon_increment, lat1 + i * lat_increment, str(i * (num_lon + 1) + j + 1),\n",
    "                    horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Example input coordinates\n",
    "    input_coordinates = [(37.5, -121.5), (37.3, -122.3), (37.7, -122.7)]\n",
    "    for lat, lon in input_coordinates:\n",
    "        grid_lat, grid_lon = find_grid_number(lat, lon, lat1, lon1, lat_degrees, lon_degrees)\n",
    "        ax.text(lon, lat, f\"{grid_lat * (num_lon + 1) + grid_lon + 1} ({grid_lat},{grid_lon})\",\n",
    "                horizontalalignment='center', verticalalignment='center', color='red', fontsize=8, transform=ccrs.PlateCarree())\n",
    "\n",
    "    ax.coastlines()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example coordinates\n",
    "lat1, lon1 = 37.0, -122.0  # Lower-left corner\n",
    "lat2, lon2 = 38.0, -121.0  # Upper-right corner\n",
    "grid_size_meter = 1000  # Size of each grid in meters\n",
    "\n",
    "create_grid_map(lat1, lon1, lat2, lon2, grid_size_meter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user_list = user_location_df_pre.index\n",
    "valid_user_list = pd.DataFrame({'valid_user_list':user_location_df_pre.index})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "X = ['latitude', 'longitude', 'x', 'y']\n",
    "user_min_df = pd.DataFrame(columns=X)\n",
    "user_max_df = pd.DataFrame(columns=X)\n",
    "for user_id in valid_user_list['valid_user_list']:\n",
    "    # user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "    user0 = pd.read_csv(csv_file)\n",
    "    min_df = pd.DataFrame(data=user0[X].min()).transpose()\n",
    "    max_df = pd.DataFrame(data=user0[X].max()).transpose()\n",
    "    \n",
    "    user_min_df = pd.concat([user_min_df, min_df])\n",
    "    user_max_df = pd.concat([user_max_df, max_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_min_df[['x', 'y']].min())\n",
    "print(user_max_df[['x', 'y']].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = pd.DataFrame(user_min_df.min()).transpose()\n",
    "df_max = pd.DataFrame(user_min_df.max()).transpose()\n",
    "df_max_min = pd.DataFrame(user_min_df.max()-user_min_df.min()).transpose()\n",
    "df_diff = pd.concat([df_min, df_max, df_max_min])\n",
    "df_diff['label'] = ['min', 'max', 'max-min']\n",
    "\n",
    "round(df_diff.set_index('label'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "\n",
    "user_df = user[['latitude', 'longitude', 'x', 'y', 'days', 'time']].copy()\n",
    "\n",
    "idx_list = []\n",
    "for idx in range(user_df.shape[0]):\n",
    "    if idx % 60 == 0: # 5 mins\n",
    "        idx_list += [idx]\n",
    "len(idx_list)\n",
    "\n",
    "idx_list_partial = idx_list[-200:]\n",
    "user_df_1 = user_df.iloc[idx_list_partial, :].copy()\n",
    "\n",
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "# axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=20)\n",
    "# axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'], s=20)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'])\n",
    "\n",
    "axes.set_xlabel('time')\n",
    "# axes.set_ylabel('X')\n",
    "# axes.set_zlabel('Y')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')\n",
    "\n",
    "user_df_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df\n",
    "task_X = user_df.copy()\n",
    "task_y = task_X.iloc[-5:, -2:].copy()\n",
    "\n",
    "task_y.iloc[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geopandas: https://datascientyst.com/plot-latitude-longitude-pandas-dataframe-python/\n",
    "# pip install geopandas\n",
    "# pip install Shapely\n",
    "\n",
    "# folium: https://aboutnlp.tistory.com/33\n",
    "\n",
    "import pandas as pd\n",
    "from convert_minmax_location import LocationPreprocessor\n",
    "\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import folium\n",
    "from branca.element import Figure\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "\n",
    "valid_user_list = locationPreprocessor.get_valid_user_list()\n",
    "\n",
    "fig = Figure(width=550, height=350)\n",
    "for id in valid_user_list['valid_user_list']:\n",
    "    print(f\"id: {id}\")\n",
    "    user_id = locationPreprocessor.getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "    user = pd.read_csv(csv_file)\n",
    "    user_location_list = user[['latitude', 'longitude']].values.tolist()\n",
    "    center = user_location_list[0]\n",
    "    \n",
    "    map = folium.Map(location=center,\n",
    "                     zoom_start=10)\n",
    "    fig.add_child(map)\n",
    "    folium.PolyLine(locations = user_location_list,).add_to(map)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://anweh.tistory.com/17\n",
    "\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.head())\n",
    "user_coords = user[['latitude', 'longitude']].values.tolist()\n",
    "lat = user['latitude'].mean()\n",
    "lon = user['longitude'].mean()\n",
    "center = [lat, lon]\n",
    "\n",
    "map = folium.Map(location=center,\n",
    "                    zoom_start=9)\n",
    "k = 0\n",
    "for i in range(len(user_coords)):\n",
    "    if (i % 60) == 0:\n",
    "        _color = '#' + str(k)\n",
    "        k += 1\n",
    "        folium.Circle(\n",
    "            location = user_coords[i],\n",
    "            radius = 20,\n",
    "            # fill_color = 'Reds'\n",
    "            # color = 'Reds', #'#000000',\n",
    "            tooltip = user.iloc[i, -2:],\n",
    "            fill = 'crimson',\n",
    "        ).add_to(map)\n",
    "map.save('map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_minmax_location import LocationPreprocessor\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "locationPreprocessor = LocationPreprocessor()\n",
    "user_id = locationPreprocessor.getUserId(29)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.shape[0])\n",
    "print(user.head(10))\n",
    "# user = user.drop_duplicates(subset=['date', 'time'])\n",
    "user = user.drop_duplicates(subset=['days'])\n",
    "print(user.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = user[['latitude', 'longitude', 'x', 'y', 'days', 'time']].copy()\n",
    "\n",
    "idx_list = []\n",
    "for idx in range(user_df.shape[0]):\n",
    "    if idx % 120 == 0:\n",
    "        idx_list += [idx]\n",
    "len(idx_list)\n",
    "\n",
    "idx_list_partial = idx_list[-50:]\n",
    "user_df_1 = user_df.iloc[idx_list_partial, :].copy()\n",
    "user_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=20)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.set_xlabel('time')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(60, 12))\n",
    "axes = plt.axes(projection='3d')\n",
    "axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "# axes.scatter3D(user_df_1['days'], user_df_1['x'], user_df_1['y'], s=10)\n",
    "# axes.plot3D(user_df_1['days'], user_df_1['x'], user_df_1['y'])\n",
    "axes.scatter3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'], s=10)\n",
    "axes.plot3D(user_df_1['days'], user_df_1['latitude'], user_df_1['longitude'])\n",
    "axes.set_xlabel('time')\n",
    "axes.set_ylabel('latitude')\n",
    "axes.set_zlabel('longitude')\n",
    "# axes.set_xticklabels(one_hour['datetime'], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as seaborn\n",
    "\n",
    "import matplotlib.dates as dates\n",
    "import datetime as dt\n",
    "\n",
    "user_id = locationPreprocessor.getUserId(1)\n",
    "csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "csv_convert_file = './Data/' + user_id + '/csv/' + user_id + '_converted.csv'\n",
    "user = pd.read_csv(csv_convert_file)\n",
    "print(user.head())\n",
    "user_coords = user[['latitude', 'longitude']].values.tolist()\n",
    "\n",
    "begin_hour = user_sub.iloc[0, -1]\n",
    "end_hour = user_sub.iloc[-1, -1]\n",
    "\n",
    "print('begin_hour:', begin_hour, ', end_hour:', end_hour)\n",
    "count = 1\n",
    "while begin_hour <= end_hour:\n",
    "    condtion = (user_sub['hour'] >= begin_hour) & (user_sub['hour'] <= begin_hour + count)\n",
    "    one_hour = user_sub.loc[condtion, :]\n",
    "    begin_hour = begin_hour + count\n",
    "    if one_hour.shape[0] < 1:\n",
    "        continue\n",
    "\n",
    "    plt.figure(figsize=(60, 12))\n",
    "    axes = plt.axes(projection='3d')\n",
    "    axes.view_init(elev=10, azim=-80)\n",
    "\n",
    "    one_hour['time_reg'] = [str(dd.time()) for dd in one_hour['datetime']]\n",
    "    axes.scatter3D(dates.date2num(one_hour['datetime']), one_hour['latitude'], one_hour['longitude'], s=10)\n",
    "    axes.plot3D(dates.date2num(one_hour['datetime']), one_hour['latitude'], one_hour['longitude'])\n",
    "    axes.set_xlabel('time')\n",
    "    axes.set_ylabel('latitude')\n",
    "    axes.set_zlabel('longitude')\n",
    "    axes.set_xticklabels(one_hour['datetime'], rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location(Latitude, Logitude) 에 대한 최소, 최대값을 구해야 함.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "min_lat_list = []\n",
    "min_lon_list = []\n",
    "max_lat_list = []\n",
    "max_lon_list = []\n",
    "\n",
    "user_id_list = []\n",
    "for id in range(182):\n",
    "    user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if df.shape[0] < 500:\n",
    "        continue\n",
    "\n",
    "    user0 = df[['days', 'latitude', 'longitude']].copy()\n",
    "    user_id_list += [user_id]\n",
    "    min_lat_list += [user0['latitude'].min()]\n",
    "    max_lat_list += [user0['latitude'].max()]\n",
    "    min_lon_list += [user0['longitude'].min()]\n",
    "    max_lon_list += [user0['longitude'].max()]\n",
    "    \n",
    "    # if user0['latitude'].min() < min_lat:\n",
    "    #     min_lat = user0['latitude'].min()\n",
    "    # if user0['latitude'].max() > max_lat:\n",
    "    #     max_lat = user0['latitude'].max()\n",
    "    # if user0['longitude'].min() < min_lon:\n",
    "    #     min_lon = user0['longitude'].min()\n",
    "    # if user0['longitude'].max() > max_lon:\n",
    "    #     max_lon = user0['longitude'].max()\n",
    "\n",
    "print(f\"min_lat: {min_lat}, min_lon: {min_lon}\")\n",
    "print(f\"max_lat: {max_lat}, max_lon: {max_lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df = pd.DataFrame({'user_id':user_id_list,\n",
    "                                'min_lat':min_lat_list,\n",
    "                                'min_lon':min_lon_list,\n",
    "                                'max_lat':max_lat_list,\n",
    "                                'max_lon':max_lon_list})\n",
    "user_location_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_location_df_pre = user_location_df.copy()\n",
    "user_location_df_pre = user_location_df_pre.set_index('user_id', drop=True).copy()\n",
    "\n",
    "X = ['min_lat', 'min_lon', 'max_lat', 'max_lon']\n",
    "q1 = user_location_df_pre[X].quantile(0.25)\n",
    "q3 = user_location_df_pre[X].quantile(0.75)\n",
    "iqr = (q3-q1) * 1.5\n",
    "\n",
    "cond1 = user_location_df_pre[X] >= (q1 - iqr)\n",
    "# cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "\n",
    "user_location_df_pre = user_location_df_pre[cond1].dropna().copy()\n",
    "cond2 = user_location_df_pre[X] <= (q3 + iqr)\n",
    "user_location_df_pre = user_location_df_pre[cond2].dropna()\n",
    "valid_user_list = user_location_df_pre.index\n",
    "print(f'valid user list: {valid_user_list}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df = pd.DataFrame({'valid_user_list':valid_user_list})\n",
    "df.to_csv('valid_user_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_user = pd.read_csv('valid_user_list.csv')\n",
    "valid_user['valid_user_list']\n",
    "\n",
    "# location(Latitude, Logitude) 에 대한 최소, 최대값을 구해야 함.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def getUserId(id):\n",
    "    val = \"\"\n",
    "    if id < 10:\n",
    "        val += \"00\"\n",
    "        val += str(id)\n",
    "    elif id < 100:\n",
    "        val += \"0\"\n",
    "        val += str(id)\n",
    "    else:\n",
    "        val = str(id)\n",
    "    return val\n",
    "\n",
    "min_lat = 1000000 \n",
    "min_lon = 1000000\n",
    "max_lat = 0\n",
    "max_lon = 0\n",
    "\n",
    "for id in valid_user['valid_user_list']:\n",
    "    user_id = getUserId(id)\n",
    "    csv_file = './Data/' + user_id + '/csv/' + user_id + '.csv'\n",
    "    user0 = pd.read_csv(csv_file)\n",
    "    \n",
    "    if user0['latitude'].min() < min_lat:\n",
    "        min_lat = user0['latitude'].min()\n",
    "    if user0['latitude'].max() > max_lat:\n",
    "        max_lat = user0['latitude'].max()\n",
    "    if user0['longitude'].min() < min_lon:\n",
    "        min_lon = user0['longitude'].min()\n",
    "    if user0['longitude'].max() > max_lon:\n",
    "        max_lon = user0['longitude'].max()\n",
    "\n",
    "print(f\"min_lat: {min_lat}, min_lon: {min_lon}\")\n",
    "print(f\"max_lat: {max_lat}, max_lon: {max_lon}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_minmax_location import get_minmax_location\n",
    "\n",
    "get_minmax_location()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_minmax_location import LocationPreprocessor\n",
    "\n",
    "locationPreprocess = LocationPreprocessor()\n",
    "center_locatuon = locationPreprocess.get_center_location()\n",
    "\n",
    "earth_radius = 6371000\n",
    "\n",
    "def convert_coord_for_blender(lat, lon):\n",
    "    delta_lat = lat - center_locatuon[0]\n",
    "    delta_lon = lon - center_locatuon[1]\n",
    "    \n",
    "    x = delta_lon * earth_radius * (np.pi / 180) * np.cos(lat * (np.pi / 180))\n",
    "    y = delta_lat * earth_radius * (np.pi / 180)\n",
    " \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_coord_for_blender(self, lat, lon):\n",
    "    delta_lat = lat - self.center_coord[0]\n",
    "    delta_lon = lon - self.center_coord[1]\n",
    "\n",
    "    x = delta_lon * self.earth_radius * (np.pi / 180) * np.cos(lat * (np.pi / 180))\n",
    "    y = delta_lat * self.earth_radius * (np.pi / 180)\n",
    " \n",
    "    return x, y\n",
    " \n",
    "earth_radius = 6371000\n",
    "lower_left_coord = [self.config['coords']['lower_left']['lat'], self.config['coords']['lower_left']['lon']]\n",
    "upper_right_coord = [self.config['coords']['upper_right']['lat'], self.config['coords']['upper_right']['lon']]\n",
    "center_coord = [\n",
    "    (self.lower_left_coord[0] + self.upper_right_coord[0]) / 2,\n",
    "    (self.lower_left_coord[1] + self.upper_right_coord[1]) / 2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(0).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 은 샘플과 정답(label)을 저장하고, \n",
    "# DataLoader 는 Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다.\n",
    "# https://wikidocs.net/156998\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "    # 생성자, 데이터를 전처리하는 부분\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 99, 95]]\n",
    "        self.y_data = [[152], \n",
    "                       [185]]\n",
    "    \n",
    "    def __len__(self):\n",
    "    # 데이터셋의 총 길이를 반환하는 부분\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    # idx 에 해당하는 입출력 데이터를 반환한다.\n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y\n",
    "    \n",
    "customData = CustomDataset()\n",
    "customData.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "index = 10\n",
    "data_dir = 'Data/'\n",
    "csv_dir = 'csv/'\n",
    "csv_extension = '.csv'\n",
    "user_path_list = os.listdir(data_dir)\n",
    "csv_path = os.path.join(data_dir, user_path_list[index], csv_dir)\n",
    "user_file = csv_path + user_path_list[index] + '.csv'\n",
    "df = pd.read_csv(user_file)\n",
    "df[[\"days\",\"latitude\", \"longitude\"]].head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Data folder 중 숫자가 안되는 User folder는 삭제하고\n",
    "# 남은 User data에서 train-test 폴더로 나눈 후\n",
    "# train_set(dataset), test_set(dataset) 으로 진행 필요\n",
    "\n",
    "class GeoLifeDataSet(Dataset):\n",
    "    def __init__(self, data_dir, user_list, samples_s, samples_q, length, y_timestep):\n",
    "        self.data_dir   = data_dir\n",
    "        self.csv_dir    = 'csv/'\n",
    "        self.user_list  = user_list\n",
    "        # user_list: all user\n",
    "        self.samples_s  = samples_s\n",
    "        # samples_s: the number of support set\n",
    "        self.samples_q  = samples_q\n",
    "        # samples_q: the number of query set\n",
    "        self.length     = length \n",
    "        # length: the length of mini batch of a user\n",
    "        self.y_timestep = y_timestep\n",
    "        # y_time_step: the next time step to be predicted\n",
    "        #              it must be less than length\n",
    "    \n",
    "    def sampleTime(self, dataset):\n",
    "        cur_ds = dataset.copy()\n",
    "        minibatch = []\n",
    "        \n",
    "        max_len = len(cur_ds)\n",
    "        ###############################################\n",
    "        # MAke sure samples from query and support \n",
    "        # do not intersect\n",
    "        ##############################################\n",
    "        # total_data_slice -> lenght 만큼 나눴을 때 총 slice 갯수\n",
    "        total_data_slice = list(range(int(max_len/self.length)))\n",
    "        total_samps = self.samples_q + self.samples_s\n",
    "        \n",
    "        slice_point = int(len(total_data_slice)*(self.samples_s/total_samps))\n",
    "        # print(f\"slice_point: {slice_point}\")\n",
    "\n",
    "        s_s_list = total_data_slice[:slice_point]\n",
    "        q_s_list = total_data_slice[slice_point:]\n",
    "\n",
    "        replace = False\n",
    "        if total_samps > len(total_data_slice):\n",
    "            replace = True\n",
    "\n",
    "        s_s_list = np.random.choice(s_s_list, size=self.samples_s, replace=replace)\n",
    "        q_s_list = np.random.choice(q_s_list, size=self.samples_q, replace=replace)\n",
    "        \n",
    "        # print(f\"s_list:{s_s_list}\")\n",
    "        # print(f\"q_list:{q_s_list}\")\n",
    "        choice_list = np.concatenate([s_s_list, q_s_list])\n",
    "        # #################################################\n",
    "        # print(f\"choice_list: {choice_list}\")\n",
    "        \n",
    "        for idx in choice_list:\n",
    "            start_idx = idx * self.length\n",
    "            if max_len - self.length >= 0:\n",
    "                cur_sample = cur_ds.iloc[start_idx:(start_idx + self.length), :]\n",
    "                minibatch.append(cur_sample)\n",
    "            else:\n",
    "                fill_quota  = np.abs(self.length - max_len)\n",
    "                zeros_r     = np.zeros([fill_quota, cur_ds.shape[1]])\n",
    "                cur_sample  = cur_ds[:, :]\n",
    "                cur_sample  = np.concatenate([zeros_r, cur_sample], axis = 0)\n",
    "                minibatch.append(cur_sample)\n",
    "        return np.array(minibatch)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        csv_path = os.path.join(self.data_dir, self.user_list[index], self.csv_dir)\n",
    "        user_file = csv_path + self.user_list[index] + '.csv'\n",
    "        df = pd.read_csv(user_file)\n",
    "        df = df[['days','latitude', 'longitude']]\n",
    "\n",
    "        samples = self.sampleTime(df)\n",
    "        # print(f\"mini_batch: {samples.shape}\")\n",
    "        # mini_batch: (5, 10, 3)\n",
    "        \n",
    "        sup_x = np.array(samples[:self.samples_s, :-self.y_timestep, :])\n",
    "        sup_y = np.array(samples[:self.samples_s, -self.y_timestep:, -2:])\n",
    "        que_x = np.array(samples[self.samples_s:, :-self.y_timestep, :])\n",
    "        que_y = np.array(samples[self.samples_s:, -self.y_timestep:, -2:])\n",
    "\n",
    "        return (que_x, sup_x, sup_y), que_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        # batch를 구성할 수 있는 총 수\n",
    "        # 이 수에서 batch를 조정할 수 있다.\n",
    "        # 몇 명의 user 로 나눠서 할 지\n",
    "        return len(self.user_list)\n",
    "\n",
    "user_list = os.listdir(data_dir)\n",
    "random.shuffle(user_list)\n",
    "train_size = 0.1\n",
    "train_list = user_list[:(int)(len(user_list)*train_size)]\n",
    "print(f\"train_list: {len(train_list)}\")\n",
    "\n",
    "# dataset = GeoLifeDataSet(\"Data/\", [0, 1, 2, 3], 5, 2, 100, 10)\n",
    "# dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = \"Data/\"#\"data/geolife/Data/\"\n",
    "sample_s = 5\n",
    "sample_q = 3\n",
    "length = 100\n",
    "y_timestep = 10\n",
    "\n",
    "user_list = os.listdir(data_dir)\n",
    "random.shuffle(user_list)\n",
    "train_size = 0.1\n",
    "train_list = user_list[:(int)(len(user_list)*train_size)]\n",
    "test_list  = user_list[(int)(len(user_list)*train_size):]\n",
    "print(f\"train_list: {len(train_list)}\")\n",
    "\n",
    "training_data = GeoLifeDataSet(data_dir, train_list, sample_s, sample_q, length, y_timestep)\n",
    "test_data = GeoLifeDataSet(data_dir, train_list, sample_s, sample_q, length, y_timestep)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=False)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "train_x, train_y = next(iter(train_dataloader))\n",
    "print(f\"support_x: {train_x[0].shape}\")\n",
    "print(f\"support_y: {train_x[1].shape}\")\n",
    "print(f\"query_x: {train_x[2].shape}\")\n",
    "print(f\"query_y: {train_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [1, 2, 3, 4, 5]\n",
    "shape[:-2] + [-1] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # input is TASKS x SAMPLES x FEATURES x TIME x Latent vector\n",
    "        shape = torch._shape_as_tensor(inp)\n",
    "        # (3, 20, 6, 100, 1)\n",
    "        x = torch.reshape(inp, [-1, shape[-2], shape[-1]])\n",
    "        # (300, 100, 1)\n",
    "        x, f = self.gru(x)\n",
    "        # x:(300, 100, 32)\n",
    "        # f:(3, 100, 32)\n",
    "        \n",
    "        if self.final:\n",
    "            new_shape = shape[:-2].tolist() + [-1]\n",
    "            out = torch.reshape(f, new_shape)\n",
    "        else:\n",
    "            new_shape = shape[:-1].tolist() + [-1]\n",
    "            # (3, 20, 6, 100, -1)\n",
    "            out = torch.reshape(x, new_shape)\n",
    "            # (3, 20, 6, 100, 32)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 2,\n",
    "    shuffle = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/000/csv/000.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/001/csv/001.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('Data/000/csv/000.csv')\n",
    "df.head(1)\n",
    "df_temp = df[['latitude', 'longitude']].copy()\n",
    "\n",
    "model = KMeans(n_clusters=100, random_state=123)\n",
    "model.fit(df_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['label'] = model.labels_\n",
    "df_temp['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "13eb1e7808dc700eaf366b56d9345c6c96b25367df344880a9b9d51f7e3cf7ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
